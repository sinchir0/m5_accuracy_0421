{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_CASE = \"case17\"\n",
    "CASE = \"case23\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from local_para import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c49c3307f674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    144\u001b[0m         f, fh = _get_handle(path, 'rb',\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl'"
     ]
    }
   ],
   "source": [
    "test = pd.read_pickle(\"ml-competition-template-titanic/model_logs/case1/oof_pred_case1_0.8363718190436625_20200317220324.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed固定\n",
    "import os, sys, gc, warnings, random, datetime\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "SEED = 2020\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/input/train.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_ORG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/input/test.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ORG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_ORG_PATH)\n",
    "test = pd.read_csv(TEST_ORG_PATH)\n",
    "\n",
    "SAME_PATH = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/\"\n",
    "category = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/input/category.csv\")\n",
    "jan = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/input/jan.csv\")\n",
    "meta = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/input/meta.csv\")\n",
    "purchase_log = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/input/purchase_log.csv\")\n",
    "sample_submission = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FqBfZgvrWVNMsCqGmZMdv3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYE5JJ4y6zJBipkCKobwVg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tC5JqjsVxsKxQ8Ykk9S7fg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pigjc37smwP2E3Z4VtKinB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YCHTGgFS6shv3GCMB7sB5j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nQsjoHBDtiJvKNUxzUoR4d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LXdStjW5USNHWpcXHd4E5j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9qw6QFmtqjjbPS9pMrwi7S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e6qaQuMJ3xsZJ96QmgCnxN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123  130125  130129  130131  140307  140313  \\\n",
       "0  njibeyLPrsnu4HCopjBihW       0       0       0       0       0       0   \n",
       "1  FqBfZgvrWVNMsCqGmZMdv3       0       0       1       0       0       0   \n",
       "2  KYE5JJ4y6zJBipkCKobwVg       0       0       0       0       0       0   \n",
       "3  tC5JqjsVxsKxQ8Ykk9S7fg       0       0       0       1       0       0   \n",
       "4  Pigjc37smwP2E3Z4VtKinB       0       0       0       0       0       0   \n",
       "5  YCHTGgFS6shv3GCMB7sB5j       0       0       0       1       0       0   \n",
       "6  nQsjoHBDtiJvKNUxzUoR4d       0       0       0       0       0       0   \n",
       "7  LXdStjW5USNHWpcXHd4E5j       0       0       0       0       0       0   \n",
       "8  9qw6QFmtqjjbPS9pMrwi7S       0       0       1       0       0       0   \n",
       "9  e6qaQuMJ3xsZJ96QmgCnxN       0       0       0       0       0       0   \n",
       "\n",
       "   140316  140317  140321  140501  140505  140641  140691  \n",
       "0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0       0  \n",
       "4       0       0       0       0       1       0       0  \n",
       "5       0       0       0       0       0       0       0  \n",
       "6       0       0       0       0       0       0       0  \n",
       "7       1       0       0       0       0       0       0  \n",
       "8       0       0       0       0       0       0       0  \n",
       "9       0       0       0       0       0       0       0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3rcdjjRyw9qSh6NcZMKSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y56uzwqQzynHYZ4bDfLPp5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xDMdFERmC7CD9yFvyvKJnh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzZENdjz7SvUQkGZV45afF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zFWkhHbLYJ9Fh5kUvCrx4g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id\n",
       "0  C3rcdjjRyw9qSh6NcZMKSX\n",
       "1  Y56uzwqQzynHYZ4bDfLPp5\n",
       "2  xDMdFERmC7CD9yFvyvKJnh\n",
       "3  zzZENdjz7SvUQkGZV45afF\n",
       "4  zFWkhHbLYJ9Fh5kUvCrx4g"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccl_category_cd1</th>\n",
       "      <th>ccl_category_cd2</th>\n",
       "      <th>ccl_category_cd3</th>\n",
       "      <th>ccl_category_cd4</th>\n",
       "      <th>ccl_category_name1</th>\n",
       "      <th>ccl_category_name2</th>\n",
       "      <th>ccl_category_name3</th>\n",
       "      <th>ccl_category_name4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110100</td>\n",
       "      <td>110101</td>\n",
       "      <td>食品</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>調味料</td>\n",
       "      <td>醤油</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110100</td>\n",
       "      <td>110103</td>\n",
       "      <td>食品</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>調味料</td>\n",
       "      <td>砂糖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110100</td>\n",
       "      <td>110105</td>\n",
       "      <td>食品</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>調味料</td>\n",
       "      <td>低カロリー甘味料</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110100</td>\n",
       "      <td>110107</td>\n",
       "      <td>食品</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>調味料</td>\n",
       "      <td>味噌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110100</td>\n",
       "      <td>110109</td>\n",
       "      <td>食品</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>調味料</td>\n",
       "      <td>食塩</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ccl_category_cd1  ccl_category_cd2  ccl_category_cd3  ccl_category_cd4  \\\n",
       "0            100000            110000            110100            110101   \n",
       "1            100000            110000            110100            110103   \n",
       "2            100000            110000            110100            110105   \n",
       "3            100000            110000            110100            110107   \n",
       "4            100000            110000            110100            110109   \n",
       "\n",
       "  ccl_category_name1 ccl_category_name2 ccl_category_name3 ccl_category_name4  \n",
       "0                 食品               加工食品                調味料                 醤油  \n",
       "1                 食品               加工食品                調味料                 砂糖  \n",
       "2                 食品               加工食品                調味料           低カロリー甘味料  \n",
       "3                 食品               加工食品                調味料                 味噌  \n",
       "4                 食品               加工食品                調味料                 食塩  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccl_category_cd4</th>\n",
       "      <th>ccl_jan</th>\n",
       "      <th>jan_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110101</td>\n",
       "      <td>49241822</td>\n",
       "      <td>チョーコー醤油 さしみしょうゆ １７０ｍｌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110101</td>\n",
       "      <td>49645255</td>\n",
       "      <td>キッコーマン 丸大豆しょうゆ 特選 １５０ｍｌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110101</td>\n",
       "      <td>49645422</td>\n",
       "      <td>キッコーマン 特選丸大豆しょうゆ １００ｍｌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110101</td>\n",
       "      <td>49673418</td>\n",
       "      <td>きぢ醤油 醇 ９００ｍｌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110101</td>\n",
       "      <td>49788105</td>\n",
       "      <td>フンドーキン醤油 さしみあまくち ３６０ｍｌ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ccl_category_cd4   ccl_jan                 jan_name\n",
       "0            110101  49241822    チョーコー醤油 さしみしょうゆ １７０ｍｌ\n",
       "1            110101  49645255  キッコーマン 丸大豆しょうゆ 特選 １５０ｍｌ\n",
       "2            110101  49645422   キッコーマン 特選丸大豆しょうゆ １００ｍｌ\n",
       "3            110101  49673418             きぢ醤油 醇 ９００ｍｌ\n",
       "4            110101  49788105   フンドーキン醤油 さしみあまくち ３６０ｍｌ"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>DLj7i4lM9EhfMk9rkY/bUcfff/o=</td>\n",
       "      <td>KJMF2FRtpETcoKjoTBpfWH</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2URfPYrtxz44sZYHDPxo7P</td>\n",
       "      <td>nvf/Ciad9Av8232uopdomjo7rkc=</td>\n",
       "      <td>ACLYkSBTX3JpNA7dxtu8DP</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2eVryJkgvFKAZLYkakDhAi</td>\n",
       "      <td>kBjyyEAW5RSiRwrMa89SK7Cgg1c=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2fR7VszHfjsyT9vGkzx3dX</td>\n",
       "      <td>WUKHZcZlY7VC9HTcJzveN6bJ5So=</td>\n",
       "      <td>z8hDrDvStZJb83bJWQdG9Y</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2mZ87Fgespch6sFVjcTy3N</td>\n",
       "      <td>ODVtm9U/CqoPGvivS5ODHOTI9ZM=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id                          mpno  \\\n",
       "0  22iPQE77jgjFqaX68kYXH5  DLj7i4lM9EhfMk9rkY/bUcfff/o=   \n",
       "1  2URfPYrtxz44sZYHDPxo7P  nvf/Ciad9Av8232uopdomjo7rkc=   \n",
       "2  2eVryJkgvFKAZLYkakDhAi  kBjyyEAW5RSiRwrMa89SK7Cgg1c=   \n",
       "3  2fR7VszHfjsyT9vGkzx3dX  WUKHZcZlY7VC9HTcJzveN6bJ5So=   \n",
       "4  2mZ87Fgespch6sFVjcTy3N  ODVtm9U/CqoPGvivS5ODHOTI9ZM=   \n",
       "\n",
       "                     mstr      p_date  p_time  \n",
       "0  KJMF2FRtpETcoKjoTBpfWH  2017-01-02       9  \n",
       "1  ACLYkSBTX3JpNA7dxtu8DP  2017-01-02      19  \n",
       "2  nTq4zA7dqePmgkhebPgdjR  2017-01-02      14  \n",
       "3  z8hDrDvStZJb83bJWQdG9Y  2017-01-02      19  \n",
       "4  2rQSaktE9DDZe46wJuDCDC  2017-01-02      18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>ccl_category_cd4</th>\n",
       "      <th>ccl_jan</th>\n",
       "      <th>amount</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>610124</td>\n",
       "      <td>610124</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>110725</td>\n",
       "      <td>4902130336959</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>630301</td>\n",
       "      <td>630301</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>610101</td>\n",
       "      <td>610101</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22iPQE77jgjFqaX68kYXH5</td>\n",
       "      <td>610703</td>\n",
       "      <td>610703</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  ccl_category_cd4        ccl_jan  amount  total\n",
       "0  22iPQE77jgjFqaX68kYXH5            610124         610124      29      1\n",
       "1  22iPQE77jgjFqaX68kYXH5            110725  4902130336959     298      1\n",
       "2  22iPQE77jgjFqaX68kYXH5            630301         630301     190      1\n",
       "3  22iPQE77jgjFqaX68kYXH5            610101         610101     128      1\n",
       "4  22iPQE77jgjFqaX68kYXH5            610703         610703      98      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545722</td>\n",
       "      <td>0.779715</td>\n",
       "      <td>0.512064</td>\n",
       "      <td>0.244230</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.238047</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.501806</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>0.073702</td>\n",
       "      <td>0.907708</td>\n",
       "      <td>0.916160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304127</td>\n",
       "      <td>0.785770</td>\n",
       "      <td>0.305915</td>\n",
       "      <td>0.980362</td>\n",
       "      <td>0.842909</td>\n",
       "      <td>0.719729</td>\n",
       "      <td>0.315182</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.046440</td>\n",
       "      <td>0.439256</td>\n",
       "      <td>0.502953</td>\n",
       "      <td>0.918038</td>\n",
       "      <td>0.213597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560296</td>\n",
       "      <td>0.083835</td>\n",
       "      <td>0.915986</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.360869</td>\n",
       "      <td>0.131223</td>\n",
       "      <td>0.412567</td>\n",
       "      <td>0.878897</td>\n",
       "      <td>0.572075</td>\n",
       "      <td>0.946727</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.961992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.905986</td>\n",
       "      <td>0.671904</td>\n",
       "      <td>0.891369</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.435208</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.589366</td>\n",
       "      <td>0.580375</td>\n",
       "      <td>0.771987</td>\n",
       "      <td>0.602004</td>\n",
       "      <td>0.362559</td>\n",
       "      <td>0.769341</td>\n",
       "      <td>0.121267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231401</td>\n",
       "      <td>0.111733</td>\n",
       "      <td>0.153284</td>\n",
       "      <td>0.263199</td>\n",
       "      <td>0.313765</td>\n",
       "      <td>0.865778</td>\n",
       "      <td>0.347703</td>\n",
       "      <td>0.151014</td>\n",
       "      <td>0.583931</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.925505</td>\n",
       "      <td>0.125222</td>\n",
       "      <td>0.177780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     130123    130125    130129    130131    140307    140313    140316  \\\n",
       "0  0.545722  0.779715  0.512064  0.244230  0.619048  0.238047  0.016861   \n",
       "1  0.304127  0.785770  0.305915  0.980362  0.842909  0.719729  0.315182   \n",
       "2  0.560296  0.083835  0.915986  0.655833  0.308700  0.360869  0.131223   \n",
       "3  0.905986  0.671904  0.891369  0.155640  0.435208  0.994250  0.589366   \n",
       "4  0.231401  0.111733  0.153284  0.263199  0.313765  0.865778  0.347703   \n",
       "\n",
       "     140317    140321    140501    140505    140641    140691  \n",
       "0  0.364235  0.501806  0.056501  0.073702  0.907708  0.916160  \n",
       "1  0.827451  0.046440  0.439256  0.502953  0.918038  0.213597  \n",
       "2  0.412567  0.878897  0.572075  0.946727  0.005869  0.961992  \n",
       "3  0.580375  0.771987  0.602004  0.362559  0.769341  0.121267  \n",
       "4  0.151014  0.583931  0.048625  0.925505  0.125222  0.177780  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = train.copy()\n",
    "test_tmp = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128376, 14)\n",
      "(96505, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_tmp.shape)\n",
    "print(test_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pickle_train = [\n",
    "    'FE_train_after_orginal.pkl',\n",
    "    'FE_train_after_purchase_id_agg.pkl',\n",
    "    'FE_train_after_date_agg.pkl',\n",
    "    #'FE_train_after_mpno_agg.pkl',\n",
    "    'FE_train_after_mstr_agg.pkl',\n",
    "    'FE_train_after_mpno_div_1_2_3.pkl'\n",
    "]\n",
    "\n",
    "use_pickle_test = [\n",
    "    'FE_test_after_orginal.pkl',\n",
    "    'FE_test_after_purchase_id_agg.pkl',\n",
    "    'FE_test_after_date_agg.pkl',\n",
    "    #'FE_test_after_mpno_agg.pkl',\n",
    "    'FE_test_after_mstr_agg.pkl',\n",
    "    'FE_test_after_mpno_div_1_2_3.pkl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in use_pickle_train:\n",
    "    df = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/{df}\")\n",
    "    train_tmp = pd.merge(train_tmp,df,on=\"purchase_id\", how='left')\n",
    "    \n",
    "for df in use_pickle_test:\n",
    "    df = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/{df}\")\n",
    "    test_tmp = pd.merge(test_tmp,df,on=\"purchase_id\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_target_per_min_max = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/month_per_min_max_df.pkl\").add_suffix(\"_per_months\")\n",
    "day_target_per_min_max = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/day_per_min_max_df.pkl\").add_suffix(\"_per_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>スナック_per_months</th>\n",
       "      <th>チョコレート_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>コーヒードリンク_per_months</th>\n",
       "      <th>米菓_per_months</th>\n",
       "      <th>新ジャンル_per_months</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_months</th>\n",
       "      <th>ビール_per_months</th>\n",
       "      <th>発泡酒_per_months</th>\n",
       "      <th>チューインガム_per_months</th>\n",
       "      <th>水_per_months</th>\n",
       "      <th>その他茶ドリンク_per_months</th>\n",
       "      <th>炭酸水_per_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.430260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.018580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.754691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886637</td>\n",
       "      <td>0.517630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189315</td>\n",
       "      <td>0.175762</td>\n",
       "      <td>0.157159</td>\n",
       "      <td>0.077859</td>\n",
       "      <td>0.222124</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.626955</td>\n",
       "      <td>0.506733</td>\n",
       "      <td>0.404150</td>\n",
       "      <td>0.088989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708028</td>\n",
       "      <td>0.431775</td>\n",
       "      <td>0.575860</td>\n",
       "      <td>0.212208</td>\n",
       "      <td>0.378681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165016</td>\n",
       "      <td>0.091367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.078425</td>\n",
       "      <td>0.243080</td>\n",
       "      <td>0.523541</td>\n",
       "      <td>0.522735</td>\n",
       "      <td>0.387490</td>\n",
       "      <td>0.904890</td>\n",
       "      <td>0.538690</td>\n",
       "      <td>0.884929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.730982</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_per_months  スナック_per_months  チョコレート_per_months  RTD_per_months  \\\n",
       "0                  1         0.638197           0.556225        0.099330   \n",
       "1                  2         0.754691           1.000000        0.255688   \n",
       "2                  3         0.626955           0.506733        0.404150   \n",
       "3                  4         0.876234           0.453102        0.367034   \n",
       "4                  5         0.078425           0.243080        0.523541   \n",
       "\n",
       "   コーヒードリンク_per_months  米菓_per_months  新ジャンル_per_months  \\\n",
       "0             0.031246       0.430260          0.000000   \n",
       "1             0.000000       0.886637          0.517630   \n",
       "2             0.088989       1.000000          0.708028   \n",
       "3             0.278157       0.410407          0.711879   \n",
       "4             0.522735       0.387490          0.904890   \n",
       "\n",
       "   日本茶・麦茶ドリンク_per_months  ビール_per_months  発泡酒_per_months  チューインガム_per_months  \\\n",
       "0               0.041853        0.000000        0.000000            0.125129   \n",
       "1               0.000000        0.189315        0.175762            0.157159   \n",
       "2               0.431775        0.575860        0.212208            0.378681   \n",
       "3               0.325582        0.873317        0.868953            0.557202   \n",
       "4               0.538690        0.884929        1.000000            0.000000   \n",
       "\n",
       "   水_per_months  その他茶ドリンク_per_months  炭酸水_per_months  \n",
       "0      0.018580             0.000000        0.078538  \n",
       "1      0.077859             0.222124        0.000000  \n",
       "2      0.000000             0.165016        0.091367  \n",
       "3      0.072100             0.195202        0.344214  \n",
       "4      0.396753             0.730982        1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_target_per_min_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = pd.merge(train_tmp,month_target_per_min_max, left_on = \"months\",right_on=\"months_per_months\")\n",
    "test_tmp = pd.merge(test_tmp,month_target_per_min_max, left_on = \"months\",right_on=\"months_per_months\")\n",
    "\n",
    "train_tmp = pd.merge(train_tmp,day_target_per_min_max, left_on = \"days\",right_on=\"days_per_days\")\n",
    "test_tmp = pd.merge(test_tmp,day_target_per_min_max, left_on = \"days\", right_on=\"days_per_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list.append(\"months_per_months\")\n",
    "remove_list.append(\"days_per_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128376, 394)\n",
      "(96505, 381)\n"
     ]
    }
   ],
   "source": [
    "print(train_tmp.shape)\n",
    "print(test_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr_target_per_min_max = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/case13_mstr_per.pkl\").add_suffix(\"_per_mstr\").reset_index().rename(columns={\"index\":\"mstr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mstr</th>\n",
       "      <th>スナック_per_mstr</th>\n",
       "      <th>チョコレート_per_mstr</th>\n",
       "      <th>コーヒードリンク_per_mstr</th>\n",
       "      <th>新ジャンル_per_mstr</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_mstr</th>\n",
       "      <th>水_per_mstr</th>\n",
       "      <th>発泡酒_per_mstr</th>\n",
       "      <th>その他茶ドリンク_per_mstr</th>\n",
       "      <th>炭酸水_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KJMF2FRtpETcoKjoTBpfWH</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z8hDrDvStZJb83bJWQdG9Y</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>St5HMaEiyGsawVUstrn7A8</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.011294</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wnd6wz8ZUa5zgPW5Z92BJS</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACLYkSBTX3JpNA7dxtu8DP</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mstr  スナック_per_mstr  チョコレート_per_mstr  コーヒードリンク_per_mstr  \\\n",
       "0  KJMF2FRtpETcoKjoTBpfWH       0.015394         0.010016           0.006916   \n",
       "1  z8hDrDvStZJb83bJWQdG9Y       0.012218         0.007659           0.004864   \n",
       "2  St5HMaEiyGsawVUstrn7A8       0.012557         0.011294           0.005436   \n",
       "3  2rQSaktE9DDZe46wJuDCDC       0.013318         0.008498           0.005858   \n",
       "4  wnd6wz8ZUa5zgPW5Z92BJS       0.009401         0.008290           0.004957   \n",
       "5  nTq4zA7dqePmgkhebPgdjR       0.009488         0.008556           0.004323   \n",
       "6  ACLYkSBTX3JpNA7dxtu8DP       0.014075         0.009090           0.005801   \n",
       "\n",
       "   新ジャンル_per_mstr  日本茶・麦茶ドリンク_per_mstr  水_per_mstr  発泡酒_per_mstr  \\\n",
       "0        0.003328             0.003171    0.001599      0.001405   \n",
       "1        0.003263             0.002489    0.000521      0.001212   \n",
       "2        0.001990             0.002668    0.000934      0.000992   \n",
       "3        0.003332             0.002102    0.001044      0.001785   \n",
       "4        0.001562             0.003086    0.000776      0.001540   \n",
       "5        0.002058             0.002409    0.000629      0.001461   \n",
       "6        0.002974             0.002949    0.000723      0.001895   \n",
       "\n",
       "   その他茶ドリンク_per_mstr  炭酸水_per_mstr  \n",
       "0           0.001281      0.000428  \n",
       "1           0.000635      0.000142  \n",
       "2           0.000825      0.000304  \n",
       "3           0.000948      0.000720  \n",
       "4           0.001039      0.000319  \n",
       "5           0.000657      0.000967  \n",
       "6           0.000948      0.000887  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mstr_target_per_min_max#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tmp = pd.merge(train_tmp,mstr_target_per_min_max, on=\"mstr\")\n",
    "test_tmp = pd.merge(test_tmp,mstr_target_per_min_max, on=\"mstr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128376, 394)\n",
      "(96505, 381)\n"
     ]
    }
   ],
   "source": [
    "print(train_tmp.shape)\n",
    "print(test_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "      <th>purchase_id_amount_sum</th>\n",
       "      <th>purchase_id_amount_max</th>\n",
       "      <th>purchase_id_amount_min</th>\n",
       "      <th>purchase_id_amount_mean</th>\n",
       "      <th>purchase_id_amount_std</th>\n",
       "      <th>purchase_id_amount_median</th>\n",
       "      <th>purchase_id_total_sum</th>\n",
       "      <th>purchase_id_total_max</th>\n",
       "      <th>purchase_id_total_min</th>\n",
       "      <th>purchase_id_total_mean</th>\n",
       "      <th>purchase_id_total_std</th>\n",
       "      <th>purchase_id_total_median</th>\n",
       "      <th>purchase_id_p_time_sum</th>\n",
       "      <th>purchase_id_p_time_max</th>\n",
       "      <th>purchase_id_p_time_min</th>\n",
       "      <th>purchase_id_p_time_mean</th>\n",
       "      <th>purchase_id_p_time_std</th>\n",
       "      <th>purchase_id_p_time_median</th>\n",
       "      <th>purchase_id_ccl_category_cd4_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd4_nunique</th>\n",
       "      <th>purchase_id_ccl_jan_mode</th>\n",
       "      <th>purchase_id_ccl_jan_nunique</th>\n",
       "      <th>purchase_id_jan_name_mode</th>\n",
       "      <th>purchase_id_jan_name_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd1_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd2_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd3_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name1_mode</th>\n",
       "      <th>purchase_id_ccl_category_name1_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_category_name3_menrui_ammount_div</th>\n",
       "      <th>ccl_category_name3_tataki_ammount_div</th>\n",
       "      <th>ccl_category_name3_pan.shiriarurui_ammount_div</th>\n",
       "      <th>ccl_category_name3_nimono_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokanoyasairui_ammount_div</th>\n",
       "      <th>ccl_category_name3_kattofuruutsu_ammount_div</th>\n",
       "      <th>ccl_category_name3_konarui_ammount_div</th>\n",
       "      <th>ccl_category_name3_sengyosonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sunakku_ammount_div</th>\n",
       "      <th>ccl_category_name3_men.pasuta_ammount_div</th>\n",
       "      <th>ccl_category_name3_bentousonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokakakoushokuhin_ammount_div</th>\n",
       "      <th>ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div</th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>スナック_per_months</th>\n",
       "      <th>チョコレート_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>コーヒードリンク_per_months</th>\n",
       "      <th>米菓_per_months</th>\n",
       "      <th>新ジャンル_per_months</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_months</th>\n",
       "      <th>ビール_per_months</th>\n",
       "      <th>発泡酒_per_months</th>\n",
       "      <th>チューインガム_per_months</th>\n",
       "      <th>水_per_months</th>\n",
       "      <th>その他茶ドリンク_per_months</th>\n",
       "      <th>炭酸水_per_months</th>\n",
       "      <th>days_per_days</th>\n",
       "      <th>スナック_per_days</th>\n",
       "      <th>チョコレート_per_days</th>\n",
       "      <th>RTD_per_days</th>\n",
       "      <th>コーヒードリンク_per_days</th>\n",
       "      <th>米菓_per_days</th>\n",
       "      <th>新ジャンル_per_days</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_days</th>\n",
       "      <th>ビール_per_days</th>\n",
       "      <th>発泡酒_per_days</th>\n",
       "      <th>その他茶ドリンク_per_days</th>\n",
       "      <th>チューインガム_per_days</th>\n",
       "      <th>水_per_days</th>\n",
       "      <th>炭酸水_per_days</th>\n",
       "      <th>スナック_per_mstr</th>\n",
       "      <th>チョコレート_per_mstr</th>\n",
       "      <th>コーヒードリンク_per_mstr</th>\n",
       "      <th>新ジャンル_per_mstr</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_mstr</th>\n",
       "      <th>水_per_mstr</th>\n",
       "      <th>発泡酒_per_mstr</th>\n",
       "      <th>その他茶ドリンク_per_mstr</th>\n",
       "      <th>炭酸水_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7ph4WbHqqe5y56C4jd6FZEYhits=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>4671.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>359.307692</td>\n",
       "      <td>491.775929</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>110131.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>610104.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>13.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nQsjoHBDtiJvKNUxzUoR4d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fjh/JffZa97gbQC02s6dvnxBt3k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>305.800000</td>\n",
       "      <td>113.247811</td>\n",
       "      <td>305.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110121.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>630201.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ほんだし 小袋 ８ｇ×２０</td>\n",
       "      <td>10.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>720100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>惣菜</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9qw6QFmtqjjbPS9pMrwi7S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xsff30jxW8NWlTO4wtmhKSVqoyo=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>23</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>223.555556</td>\n",
       "      <td>106.693616</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130401.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>610107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JocGnYfx4qYadKzeaPctLc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gWIikBeY29ACfcC2K86DlXa+P3o=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>17</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>280.526316</td>\n",
       "      <td>341.616967</td>\n",
       "      <td>158.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.501460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110507.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610102.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>おいしい牛乳 パック ５００ｍｌ</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62ubQAVp2p6UqUSA6Udxk2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ReeIrDXm95KKD/mOty0eD+1q33k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>423.500000</td>\n",
       "      <td>487.433219</td>\n",
       "      <td>199.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>130137.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>730497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>オールド ７００ｍｌ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123  130125  130129  130131  140307  140313  \\\n",
       "0  njibeyLPrsnu4HCopjBihW       0       0       0       0       0       0   \n",
       "1  nQsjoHBDtiJvKNUxzUoR4d       0       0       0       0       0       0   \n",
       "2  9qw6QFmtqjjbPS9pMrwi7S       0       0       1       0       0       0   \n",
       "3  JocGnYfx4qYadKzeaPctLc       0       0       0       1       0       0   \n",
       "4  62ubQAVp2p6UqUSA6Udxk2       1       0       0       1       1       0   \n",
       "\n",
       "   140316  140317  140321  140501  140505  140641  140691  \\\n",
       "0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       1       0   \n",
       "4       0       0       0       0       0       0       0   \n",
       "\n",
       "                           mpno                    mstr     p_date  p_time  \\\n",
       "0  7ph4WbHqqe5y56C4jd6FZEYhits=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "1  fjh/JffZa97gbQC02s6dvnxBt3k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      11   \n",
       "2  xsff30jxW8NWlTO4wtmhKSVqoyo=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      23   \n",
       "3  gWIikBeY29ACfcC2K86DlXa+P3o=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      17   \n",
       "4  ReeIrDXm95KKD/mOty0eD+1q33k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "\n",
       "   purchase_id_amount_sum  purchase_id_amount_max  purchase_id_amount_min  \\\n",
       "0                  4671.0                  1980.0                   108.0   \n",
       "1                  3058.0                   470.0                   134.0   \n",
       "2                  2012.0                   478.0                    96.0   \n",
       "3                  5330.0                  1580.0                    84.0   \n",
       "4                  3388.0                  1580.0                   138.0   \n",
       "\n",
       "   purchase_id_amount_mean  purchase_id_amount_std  purchase_id_amount_median  \\\n",
       "0               359.307692              491.775929                      198.0   \n",
       "1               305.800000              113.247811                      305.5   \n",
       "2               223.555556              106.693616                      198.0   \n",
       "3               280.526316              341.616967                      158.0   \n",
       "4               423.500000              487.433219                      199.0   \n",
       "\n",
       "   purchase_id_total_sum  purchase_id_total_max  purchase_id_total_min  \\\n",
       "0                   15.0                    2.0                    1.0   \n",
       "1                   14.0                    2.0                    1.0   \n",
       "2                    9.0                    1.0                    1.0   \n",
       "3                   22.0                    3.0                    1.0   \n",
       "4                   13.0                    4.0                    1.0   \n",
       "\n",
       "   purchase_id_total_mean  purchase_id_total_std  purchase_id_total_median  \\\n",
       "0                1.153846               0.375534                       1.0   \n",
       "1                1.400000               0.516398                       1.0   \n",
       "2                1.000000               0.000000                       1.0   \n",
       "3                1.157895               0.501460                       1.0   \n",
       "4                1.625000               1.060660                       1.0   \n",
       "\n",
       "   purchase_id_p_time_sum  purchase_id_p_time_max  purchase_id_p_time_min  \\\n",
       "0                   182.0                    14.0                    14.0   \n",
       "1                   110.0                    11.0                    11.0   \n",
       "2                   207.0                    23.0                    23.0   \n",
       "3                   323.0                    17.0                    17.0   \n",
       "4                   112.0                    14.0                    14.0   \n",
       "\n",
       "   purchase_id_p_time_mean  purchase_id_p_time_std  purchase_id_p_time_median  \\\n",
       "0                     14.0                     0.0                       14.0   \n",
       "1                     11.0                     0.0                       11.0   \n",
       "2                     23.0                     0.0                       23.0   \n",
       "3                     17.0                     0.0                       17.0   \n",
       "4                     14.0                     0.0                       14.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd4_mode  purchase_id_ccl_category_cd4_nunique  \\\n",
       "0                           110131.0                                  13.0   \n",
       "1                           110121.0                                  10.0   \n",
       "2                           130401.0                                   7.0   \n",
       "3                           110507.0                                  18.0   \n",
       "4                           130137.0                                   7.0   \n",
       "\n",
       "   purchase_id_ccl_jan_mode  purchase_id_ccl_jan_nunique  \\\n",
       "0                  610104.0                         13.0   \n",
       "1                  630201.0                         10.0   \n",
       "2                  610107.0                          9.0   \n",
       "3                  610102.0                         19.0   \n",
       "4                  730497.0                          8.0   \n",
       "\n",
       "  purchase_id_jan_name_mode  purchase_id_jan_name_nunique  \\\n",
       "0                 きのこ類_しめじ茸                          13.0   \n",
       "1             ほんだし 小袋 ８ｇ×２０                          10.0   \n",
       "2                 きのこ類_しめじ茸                           9.0   \n",
       "3          おいしい牛乳 パック ５００ｍｌ                          19.0   \n",
       "4                オールド ７００ｍｌ                           8.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd1_mode  purchase_id_ccl_category_cd1_nunique  \\\n",
       "0                           600000.0                                   2.0   \n",
       "1                           700000.0                                   3.0   \n",
       "2                           100000.0                                   3.0   \n",
       "3                           100000.0                                   3.0   \n",
       "4                           100000.0                                   2.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd2_mode  purchase_id_ccl_category_cd2_nunique  \\\n",
       "0                           610000.0                                   6.0   \n",
       "1                           720000.0                                   4.0   \n",
       "2                           130000.0                                   6.0   \n",
       "3                           110000.0                                   8.0   \n",
       "4                           130000.0                                   3.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd3_mode  purchase_id_ccl_category_cd3_nunique  \\\n",
       "0                           610100.0                                  11.0   \n",
       "1                           720100.0                                   9.0   \n",
       "2                           130400.0                                   7.0   \n",
       "3                           610100.0                                  15.0   \n",
       "4                           130100.0                                   6.0   \n",
       "\n",
       "  purchase_id_ccl_category_name1_mode  purchase_id_ccl_category_name1_nunique  \\\n",
       "0                                  生鮮                                     2.0   \n",
       "1                                  惣菜                                     3.0   \n",
       "2                                  生鮮                                     3.0   \n",
       "3                                  食品                                     3.0   \n",
       "4                                  食品                                     2.0   \n",
       "\n",
       "       ...      ccl_category_name3_menrui_ammount_div  \\\n",
       "0      ...                                   0.024029   \n",
       "1      ...                                   0.036537   \n",
       "2      ...                                   0.008176   \n",
       "3      ...                                   0.010804   \n",
       "4      ...                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_tataki_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.003151   \n",
       "4                               0.000000   \n",
       "\n",
       "  ccl_category_name3_pan.shiriarurui_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_nimono_ammount_div  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "  ccl_category_name3_sonohokanoyasairui_ammount_div  \\\n",
       "0                                          0.007678   \n",
       "1                                          0.000756   \n",
       "2                                          0.000000   \n",
       "3                                          0.000000   \n",
       "4                                          0.000000   \n",
       "\n",
       "   ccl_category_name3_kattofuruutsu_ammount_div  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.001359   \n",
       "2                                      0.000000   \n",
       "3                                      0.001619   \n",
       "4                                      0.000000   \n",
       "\n",
       "  ccl_category_name3_konarui_ammount_div  \\\n",
       "0                               0.008242   \n",
       "1                               0.002821   \n",
       "2                               0.000000   \n",
       "3                               0.001184   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_sengyosonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "  ccl_category_name3_sunakku_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.013893   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_men.pasuta_ammount_div  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.007337   \n",
       "2                                   0.000000   \n",
       "3                                   0.002575   \n",
       "4                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_bentousonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokakakoushokuhin_ammount_div  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   months_per_months  スナック_per_months  チョコレート_per_months  RTD_per_months  \\\n",
       "0                  1         0.638197           0.556225         0.09933   \n",
       "1                  1         0.638197           0.556225         0.09933   \n",
       "2                  1         0.638197           0.556225         0.09933   \n",
       "3                  1         0.638197           0.556225         0.09933   \n",
       "4                  1         0.638197           0.556225         0.09933   \n",
       "\n",
       "   コーヒードリンク_per_months  米菓_per_months  新ジャンル_per_months  \\\n",
       "0             0.031246        0.43026               0.0   \n",
       "1             0.031246        0.43026               0.0   \n",
       "2             0.031246        0.43026               0.0   \n",
       "3             0.031246        0.43026               0.0   \n",
       "4             0.031246        0.43026               0.0   \n",
       "\n",
       "   日本茶・麦茶ドリンク_per_months  ビール_per_months  発泡酒_per_months  チューインガム_per_months  \\\n",
       "0               0.041853             0.0             0.0            0.125129   \n",
       "1               0.041853             0.0             0.0            0.125129   \n",
       "2               0.041853             0.0             0.0            0.125129   \n",
       "3               0.041853             0.0             0.0            0.125129   \n",
       "4               0.041853             0.0             0.0            0.125129   \n",
       "\n",
       "   水_per_months  その他茶ドリンク_per_months  炭酸水_per_months  days_per_days  \\\n",
       "0       0.01858                  0.0        0.078538              2   \n",
       "1       0.01858                  0.0        0.078538              2   \n",
       "2       0.01858                  0.0        0.078538              2   \n",
       "3       0.01858                  0.0        0.078538              2   \n",
       "4       0.01858                  0.0        0.078538              2   \n",
       "\n",
       "   スナック_per_days  チョコレート_per_days  RTD_per_days  コーヒードリンク_per_days  \\\n",
       "0            0.0         0.306292      0.569746           0.309674   \n",
       "1            0.0         0.306292      0.569746           0.309674   \n",
       "2            0.0         0.306292      0.569746           0.309674   \n",
       "3            0.0         0.306292      0.569746           0.309674   \n",
       "4            0.0         0.306292      0.569746           0.309674   \n",
       "\n",
       "   米菓_per_days  新ジャンル_per_days  日本茶・麦茶ドリンク_per_days  ビール_per_days  \\\n",
       "0     0.312486             1.0             0.641796           1.0   \n",
       "1     0.312486             1.0             0.641796           1.0   \n",
       "2     0.312486             1.0             0.641796           1.0   \n",
       "3     0.312486             1.0             0.641796           1.0   \n",
       "4     0.312486             1.0             0.641796           1.0   \n",
       "\n",
       "   発泡酒_per_days  その他茶ドリンク_per_days  チューインガム_per_days  水_per_days  \\\n",
       "0      0.799642           0.895045          0.093191    0.765309   \n",
       "1      0.799642           0.895045          0.093191    0.765309   \n",
       "2      0.799642           0.895045          0.093191    0.765309   \n",
       "3      0.799642           0.895045          0.093191    0.765309   \n",
       "4      0.799642           0.895045          0.093191    0.765309   \n",
       "\n",
       "   炭酸水_per_days  スナック_per_mstr  チョコレート_per_mstr  コーヒードリンク_per_mstr  \\\n",
       "0      0.105463       0.013318         0.008498           0.005858   \n",
       "1      0.105463       0.013318         0.008498           0.005858   \n",
       "2      0.105463       0.013318         0.008498           0.005858   \n",
       "3      0.105463       0.013318         0.008498           0.005858   \n",
       "4      0.105463       0.013318         0.008498           0.005858   \n",
       "\n",
       "   新ジャンル_per_mstr  日本茶・麦茶ドリンク_per_mstr  水_per_mstr  発泡酒_per_mstr  \\\n",
       "0        0.003332             0.002102    0.001044      0.001785   \n",
       "1        0.003332             0.002102    0.001044      0.001785   \n",
       "2        0.003332             0.002102    0.001044      0.001785   \n",
       "3        0.003332             0.002102    0.001044      0.001785   \n",
       "4        0.003332             0.002102    0.001044      0.001785   \n",
       "\n",
       "   その他茶ドリンク_per_mstr  炭酸水_per_mstr  \n",
       "0           0.000948       0.00072  \n",
       "1           0.000948       0.00072  \n",
       "2           0.000948       0.00072  \n",
       "3           0.000948       0.00072  \n",
       "4           0.000948       0.00072  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['purchase_id',\n",
       " '130123',\n",
       " '130125',\n",
       " '130129',\n",
       " '130131',\n",
       " '140307',\n",
       " '140313',\n",
       " '140316',\n",
       " '140317',\n",
       " '140321',\n",
       " '140501',\n",
       " '140505',\n",
       " '140641',\n",
       " '140691',\n",
       " 'mpno',\n",
       " 'mstr',\n",
       " 'p_date',\n",
       " 'p_time',\n",
       " 'purchase_id_amount_sum',\n",
       " 'purchase_id_amount_max',\n",
       " 'purchase_id_amount_min',\n",
       " 'purchase_id_amount_mean',\n",
       " 'purchase_id_amount_std',\n",
       " 'purchase_id_amount_median',\n",
       " 'purchase_id_total_sum',\n",
       " 'purchase_id_total_max',\n",
       " 'purchase_id_total_min',\n",
       " 'purchase_id_total_mean',\n",
       " 'purchase_id_total_std',\n",
       " 'purchase_id_total_median',\n",
       " 'purchase_id_p_time_sum',\n",
       " 'purchase_id_p_time_max',\n",
       " 'purchase_id_p_time_min',\n",
       " 'purchase_id_p_time_mean',\n",
       " 'purchase_id_p_time_std',\n",
       " 'purchase_id_p_time_median',\n",
       " 'purchase_id_ccl_category_cd4_mode',\n",
       " 'purchase_id_ccl_category_cd4_nunique',\n",
       " 'purchase_id_ccl_jan_mode',\n",
       " 'purchase_id_ccl_jan_nunique',\n",
       " 'purchase_id_jan_name_mode',\n",
       " 'purchase_id_jan_name_nunique',\n",
       " 'purchase_id_ccl_category_cd1_mode',\n",
       " 'purchase_id_ccl_category_cd1_nunique',\n",
       " 'purchase_id_ccl_category_cd2_mode',\n",
       " 'purchase_id_ccl_category_cd2_nunique',\n",
       " 'purchase_id_ccl_category_cd3_mode',\n",
       " 'purchase_id_ccl_category_cd3_nunique',\n",
       " 'purchase_id_ccl_category_name1_mode',\n",
       " 'purchase_id_ccl_category_name1_nunique',\n",
       " 'purchase_id_ccl_category_name2_mode',\n",
       " 'purchase_id_ccl_category_name2_nunique',\n",
       " 'purchase_id_ccl_category_name3_mode',\n",
       " 'purchase_id_ccl_category_name3_nunique',\n",
       " 'purchase_id_ccl_category_name4_mode',\n",
       " 'purchase_id_ccl_category_name4_nunique',\n",
       " 'purchase_id_mpno_mode',\n",
       " 'purchase_id_mpno_nunique',\n",
       " 'purchase_id_mstr_mode',\n",
       " 'purchase_id_mstr_nunique',\n",
       " 'years',\n",
       " 'months',\n",
       " 'days',\n",
       " 'weekdays',\n",
       " 'holiday_flg',\n",
       " 'satsun_flg',\n",
       " 'special_flg',\n",
       " 'End_Start_year_flg',\n",
       " 'GW_flg',\n",
       " 'Halloween_flg',\n",
       " 'Valentine_flg',\n",
       " 'Whiteday_flg',\n",
       " 'Christmas_flg',\n",
       " 'months_amount_sum',\n",
       " 'months_amount_max',\n",
       " 'months_amount_min',\n",
       " 'months_amount_mean',\n",
       " 'months_amount_std',\n",
       " 'months_amount_median',\n",
       " 'months_total_sum',\n",
       " 'months_total_max',\n",
       " 'months_total_min',\n",
       " 'months_total_mean',\n",
       " 'months_total_std',\n",
       " 'months_total_median',\n",
       " 'months_p_time_sum',\n",
       " 'months_p_time_max',\n",
       " 'months_p_time_min',\n",
       " 'months_p_time_mean',\n",
       " 'months_p_time_std',\n",
       " 'months_p_time_median',\n",
       " 'weekdays_amount_sum',\n",
       " 'weekdays_amount_max',\n",
       " 'weekdays_amount_min',\n",
       " 'weekdays_amount_mean',\n",
       " 'weekdays_amount_std',\n",
       " 'weekdays_amount_median',\n",
       " 'weekdays_total_sum',\n",
       " 'weekdays_total_max',\n",
       " 'weekdays_total_min',\n",
       " 'weekdays_total_mean',\n",
       " 'weekdays_total_std',\n",
       " 'weekdays_total_median',\n",
       " 'weekdays_p_time_sum',\n",
       " 'weekdays_p_time_max',\n",
       " 'weekdays_p_time_min',\n",
       " 'weekdays_p_time_mean',\n",
       " 'weekdays_p_time_std',\n",
       " 'weekdays_p_time_median',\n",
       " 'days_amount_sum',\n",
       " 'days_amount_max',\n",
       " 'days_amount_min',\n",
       " 'days_amount_mean',\n",
       " 'days_amount_std',\n",
       " 'days_amount_median',\n",
       " 'days_total_sum',\n",
       " 'days_total_max',\n",
       " 'days_total_min',\n",
       " 'days_total_mean',\n",
       " 'days_total_std',\n",
       " 'days_total_median',\n",
       " 'days_p_time_sum',\n",
       " 'days_p_time_max',\n",
       " 'days_p_time_min',\n",
       " 'days_p_time_mean',\n",
       " 'days_p_time_std',\n",
       " 'days_p_time_median',\n",
       " 'holiday_flg_amount_sum',\n",
       " 'holiday_flg_amount_max',\n",
       " 'holiday_flg_amount_min',\n",
       " 'holiday_flg_amount_mean',\n",
       " 'holiday_flg_amount_std',\n",
       " 'holiday_flg_amount_median',\n",
       " 'holiday_flg_total_sum',\n",
       " 'holiday_flg_total_max',\n",
       " 'holiday_flg_total_min',\n",
       " 'holiday_flg_total_mean',\n",
       " 'holiday_flg_total_std',\n",
       " 'holiday_flg_total_median',\n",
       " 'holiday_flg_p_time_sum',\n",
       " 'holiday_flg_p_time_max',\n",
       " 'holiday_flg_p_time_min',\n",
       " 'holiday_flg_p_time_mean',\n",
       " 'holiday_flg_p_time_std',\n",
       " 'holiday_flg_p_time_median',\n",
       " 'mstr_amount_sum',\n",
       " 'mstr_amount_max',\n",
       " 'mstr_amount_min',\n",
       " 'mstr_amount_mean',\n",
       " 'mstr_amount_std',\n",
       " 'mstr_amount_median',\n",
       " 'mstr_total_sum',\n",
       " 'mstr_total_max',\n",
       " 'mstr_total_min',\n",
       " 'mstr_total_mean',\n",
       " 'mstr_total_std',\n",
       " 'mstr_total_median',\n",
       " 'mstr_p_time_sum',\n",
       " 'mstr_p_time_max',\n",
       " 'mstr_p_time_min',\n",
       " 'mstr_p_time_mean',\n",
       " 'mstr_p_time_std',\n",
       " 'mstr_p_time_median',\n",
       " 'mstr_ccl_category_cd4_mode',\n",
       " 'mstr_ccl_category_cd4_nunique',\n",
       " 'mstr_ccl_jan_mode',\n",
       " 'mstr_ccl_jan_nunique',\n",
       " 'mstr_jan_name_mode',\n",
       " 'mstr_jan_name_nunique',\n",
       " 'mstr_ccl_category_cd1_mode',\n",
       " 'mstr_ccl_category_cd1_nunique',\n",
       " 'mstr_ccl_category_cd2_mode',\n",
       " 'mstr_ccl_category_cd2_nunique',\n",
       " 'mstr_ccl_category_cd3_mode',\n",
       " 'mstr_ccl_category_cd3_nunique',\n",
       " 'mstr_ccl_category_name1_mode',\n",
       " 'mstr_ccl_category_name1_nunique',\n",
       " 'mstr_ccl_category_name2_mode',\n",
       " 'mstr_ccl_category_name2_nunique',\n",
       " 'mstr_ccl_category_name3_mode',\n",
       " 'mstr_ccl_category_name3_nunique',\n",
       " 'mstr_ccl_category_name4_mode',\n",
       " 'mstr_ccl_category_name4_nunique',\n",
       " 'ccl_category_name1_souzai_div',\n",
       " 'ccl_category_name1_seisen_div',\n",
       " 'ccl_category_name1_shokuhin_div',\n",
       " 'ccl_category_name2_kakoushokuhin_div',\n",
       " 'ccl_category_name2_hanchourihin_div',\n",
       " 'ccl_category_name2_tamago_div',\n",
       " 'ccl_category_name2_bentou_div',\n",
       " 'ccl_category_name2_kajitsu_div',\n",
       " 'ccl_category_name2_seiniku_div',\n",
       " 'ccl_category_name2_kashirui_div',\n",
       " 'ccl_category_name2_chourizumi_div',\n",
       " 'ccl_category_name2_yasai_div',\n",
       " 'ccl_category_name2_inryou.sakerui_div',\n",
       " 'ccl_category_name2_sengyo_div',\n",
       " 'ccl_category_name3_kinokorui_div',\n",
       " 'ccl_category_name3_sonohoka_div',\n",
       " 'ccl_category_name3_sonohokanokudamono_div',\n",
       " 'ccl_category_name3_sonohokasouzai_div',\n",
       " 'ccl_category_name3_sonohokaseinikurui_div',\n",
       " 'ccl_category_name3_aisukuriimurui_div',\n",
       " 'ccl_category_name3_arukooruinryou_div',\n",
       " 'ccl_category_name3_kattoyasai_div',\n",
       " 'ccl_category_name3_supureddorui_div',\n",
       " 'ccl_category_name3_suupu_div',\n",
       " 'ccl_category_name3_dezaato.yooguruto_div',\n",
       " 'ccl_category_name3_pan_div',\n",
       " 'ccl_category_name3_hoomumeekinguzairyou_div',\n",
       " 'ccl_category_name3_chuukasouzai_div',\n",
       " 'ccl_category_name3_marumono_div',\n",
       " 'ccl_category_name3_nyuuseihin_div',\n",
       " 'ccl_category_name3_chichiinryou_div',\n",
       " 'ccl_category_name3_hitoshikarui_div',\n",
       " 'ccl_category_name3_satsurui_div',\n",
       " 'ccl_category_name3_reitoushokuhin_div',\n",
       " 'ccl_category_name3_kirimi_div',\n",
       " 'ccl_category_name3_sashimi_div',\n",
       " 'ccl_category_name3_kakousuisan_div',\n",
       " 'ccl_category_name3_kakounikurui_div',\n",
       " 'ccl_category_name3_wafuusouzai_div',\n",
       " 'ccl_category_name3_shikouinryou_div',\n",
       " 'ccl_category_name3_tsuchimonorui_div',\n",
       " 'ccl_category_name3_sushi_div',\n",
       " 'ccl_category_name3_souzairui_div',\n",
       " 'ccl_category_name3_youmono_div',\n",
       " 'ccl_category_name3_kajitsutekiyasai_div',\n",
       " 'ccl_category_name3_kajitsuinryou_div',\n",
       " 'ccl_category_name3_kanarui_div',\n",
       " 'ccl_category_name3_kankitsurui_div',\n",
       " 'ccl_category_name3_kakukarui_div',\n",
       " 'ccl_category_name3_konsairui_div',\n",
       " 'ccl_category_name3_mizumono_div',\n",
       " 'ccl_category_name3_youfuusouzai_div',\n",
       " 'ccl_category_name3_seiryouinryou_div',\n",
       " 'ccl_category_name3_tsukemono.tsukudani_div',\n",
       " 'ccl_category_name3_yakimono_div',\n",
       " 'ccl_category_name3_gyuuniku_div',\n",
       " 'ccl_category_name3_chinmi_div',\n",
       " 'ccl_category_name3_seisensonohokakakousuisan_div',\n",
       " 'ccl_category_name3_kokumotsu_div',\n",
       " 'ccl_category_name3_beihan_div',\n",
       " 'ccl_category_name3_neriseihin_div',\n",
       " 'ccl_category_name3_kanzume_div',\n",
       " 'ccl_category_name3_kashi_div',\n",
       " 'ccl_category_name3_hakukinarui_div',\n",
       " 'ccl_category_name3_choumiryou_div',\n",
       " 'ccl_category_name3_chourihin_div',\n",
       " 'ccl_category_name3_mamerui_div',\n",
       " 'ccl_category_name3_butaniku_div',\n",
       " 'ccl_category_name3_kai_div',\n",
       " 'ccl_category_name3_nousankanbutsu_div',\n",
       " 'ccl_category_name3_shokuyouabura_div',\n",
       " 'ccl_category_name3_kaorishinyasai_div',\n",
       " 'ccl_category_name3_keiran_div',\n",
       " 'ccl_category_name3_toriniku_div',\n",
       " 'ccl_category_name3_menrui_div',\n",
       " 'ccl_category_name3_tataki_div',\n",
       " 'ccl_category_name3_pan.shiriarurui_div',\n",
       " 'ccl_category_name3_nimono_div',\n",
       " 'ccl_category_name3_sonohokanoyasairui_div',\n",
       " 'ccl_category_name3_kattofuruutsu_div',\n",
       " 'ccl_category_name3_konarui_div',\n",
       " 'ccl_category_name3_sengyosonohoka_div',\n",
       " 'ccl_category_name3_sunakku_div',\n",
       " 'ccl_category_name3_men.pasuta_div',\n",
       " 'ccl_category_name3_bentousonohoka_div',\n",
       " 'ccl_category_name3_sonohokakakoushokuhin_div',\n",
       " 'ccl_category_name3_sakeruiwofukumusettoshouhin_div',\n",
       " 'ccl_category_name1_souzai_ammount_div',\n",
       " 'ccl_category_name1_seisen_ammount_div',\n",
       " 'ccl_category_name1_shokuhin_ammount_div',\n",
       " 'ccl_category_name2_kakoushokuhin_ammount_div',\n",
       " 'ccl_category_name2_hanchourihin_ammount_div',\n",
       " 'ccl_category_name2_tamago_ammount_div',\n",
       " 'ccl_category_name2_bentou_ammount_div',\n",
       " 'ccl_category_name2_kajitsu_ammount_div',\n",
       " 'ccl_category_name2_seiniku_ammount_div',\n",
       " 'ccl_category_name2_kashirui_ammount_div',\n",
       " 'ccl_category_name2_chourizumi_ammount_div',\n",
       " 'ccl_category_name2_yasai_ammount_div',\n",
       " 'ccl_category_name2_inryou.sakerui_ammount_div',\n",
       " 'ccl_category_name2_sengyo_ammount_div',\n",
       " 'ccl_category_name3_kinokorui_ammount_div',\n",
       " 'ccl_category_name3_sonohoka_ammount_div',\n",
       " 'ccl_category_name3_sonohokanokudamono_ammount_div',\n",
       " 'ccl_category_name3_sonohokasouzai_ammount_div',\n",
       " 'ccl_category_name3_sonohokaseinikurui_ammount_div',\n",
       " 'ccl_category_name3_aisukuriimurui_ammount_div',\n",
       " 'ccl_category_name3_arukooruinryou_ammount_div',\n",
       " 'ccl_category_name3_kattoyasai_ammount_div',\n",
       " 'ccl_category_name3_supureddorui_ammount_div',\n",
       " 'ccl_category_name3_suupu_ammount_div',\n",
       " 'ccl_category_name3_dezaato.yooguruto_ammount_div',\n",
       " 'ccl_category_name3_pan_ammount_div',\n",
       " 'ccl_category_name3_hoomumeekinguzairyou_ammount_div',\n",
       " 'ccl_category_name3_chuukasouzai_ammount_div',\n",
       " 'ccl_category_name3_marumono_ammount_div',\n",
       " 'ccl_category_name3_nyuuseihin_ammount_div',\n",
       " 'ccl_category_name3_chichiinryou_ammount_div',\n",
       " 'ccl_category_name3_hitoshikarui_ammount_div',\n",
       " 'ccl_category_name3_satsurui_ammount_div',\n",
       " 'ccl_category_name3_reitoushokuhin_ammount_div',\n",
       " 'ccl_category_name3_kirimi_ammount_div',\n",
       " 'ccl_category_name3_sashimi_ammount_div',\n",
       " 'ccl_category_name3_kakousuisan_ammount_div',\n",
       " 'ccl_category_name3_kakounikurui_ammount_div',\n",
       " 'ccl_category_name3_wafuusouzai_ammount_div',\n",
       " 'ccl_category_name3_shikouinryou_ammount_div',\n",
       " 'ccl_category_name3_tsuchimonorui_ammount_div',\n",
       " 'ccl_category_name3_sushi_ammount_div',\n",
       " 'ccl_category_name3_souzairui_ammount_div',\n",
       " 'ccl_category_name3_youmono_ammount_div',\n",
       " 'ccl_category_name3_kajitsutekiyasai_ammount_div',\n",
       " 'ccl_category_name3_kajitsuinryou_ammount_div',\n",
       " 'ccl_category_name3_kanarui_ammount_div',\n",
       " 'ccl_category_name3_kankitsurui_ammount_div',\n",
       " 'ccl_category_name3_kakukarui_ammount_div',\n",
       " 'ccl_category_name3_konsairui_ammount_div',\n",
       " 'ccl_category_name3_mizumono_ammount_div',\n",
       " 'ccl_category_name3_youfuusouzai_ammount_div',\n",
       " 'ccl_category_name3_seiryouinryou_ammount_div',\n",
       " 'ccl_category_name3_tsukemono.tsukudani_ammount_div',\n",
       " 'ccl_category_name3_yakimono_ammount_div',\n",
       " 'ccl_category_name3_gyuuniku_ammount_div',\n",
       " 'ccl_category_name3_chinmi_ammount_div',\n",
       " 'ccl_category_name3_seisensonohokakakousuisan_ammount_div',\n",
       " 'ccl_category_name3_kokumotsu_ammount_div',\n",
       " 'ccl_category_name3_beihan_ammount_div',\n",
       " 'ccl_category_name3_neriseihin_ammount_div',\n",
       " 'ccl_category_name3_kanzume_ammount_div',\n",
       " 'ccl_category_name3_kashi_ammount_div',\n",
       " 'ccl_category_name3_hakukinarui_ammount_div',\n",
       " 'ccl_category_name3_choumiryou_ammount_div',\n",
       " 'ccl_category_name3_chourihin_ammount_div',\n",
       " 'ccl_category_name3_mamerui_ammount_div',\n",
       " 'ccl_category_name3_butaniku_ammount_div',\n",
       " 'ccl_category_name3_kai_ammount_div',\n",
       " 'ccl_category_name3_nousankanbutsu_ammount_div',\n",
       " 'ccl_category_name3_shokuyouabura_ammount_div',\n",
       " 'ccl_category_name3_kaorishinyasai_ammount_div',\n",
       " 'ccl_category_name3_keiran_ammount_div',\n",
       " 'ccl_category_name3_toriniku_ammount_div',\n",
       " 'ccl_category_name3_menrui_ammount_div',\n",
       " 'ccl_category_name3_tataki_ammount_div',\n",
       " 'ccl_category_name3_pan.shiriarurui_ammount_div',\n",
       " 'ccl_category_name3_nimono_ammount_div',\n",
       " 'ccl_category_name3_sonohokanoyasairui_ammount_div',\n",
       " 'ccl_category_name3_kattofuruutsu_ammount_div',\n",
       " 'ccl_category_name3_konarui_ammount_div',\n",
       " 'ccl_category_name3_sengyosonohoka_ammount_div',\n",
       " 'ccl_category_name3_sunakku_ammount_div',\n",
       " 'ccl_category_name3_men.pasuta_ammount_div',\n",
       " 'ccl_category_name3_bentousonohoka_ammount_div',\n",
       " 'ccl_category_name3_sonohokakakoushokuhin_ammount_div',\n",
       " 'ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div',\n",
       " 'months_per_months',\n",
       " 'スナック_per_months',\n",
       " 'チョコレート_per_months',\n",
       " 'RTD_per_months',\n",
       " 'コーヒードリンク_per_months',\n",
       " '米菓_per_months',\n",
       " '新ジャンル_per_months',\n",
       " '日本茶・麦茶ドリンク_per_months',\n",
       " 'ビール_per_months',\n",
       " '発泡酒_per_months',\n",
       " 'チューインガム_per_months',\n",
       " '水_per_months',\n",
       " 'その他茶ドリンク_per_months',\n",
       " '炭酸水_per_months',\n",
       " 'days_per_days',\n",
       " 'スナック_per_days',\n",
       " 'チョコレート_per_days',\n",
       " 'RTD_per_days',\n",
       " 'コーヒードリンク_per_days',\n",
       " '米菓_per_days',\n",
       " '新ジャンル_per_days',\n",
       " '日本茶・麦茶ドリンク_per_days',\n",
       " 'ビール_per_days',\n",
       " '発泡酒_per_days',\n",
       " 'その他茶ドリンク_per_days',\n",
       " 'チューインガム_per_days',\n",
       " '水_per_days',\n",
       " '炭酸水_per_days',\n",
       " 'スナック_per_mstr',\n",
       " 'チョコレート_per_mstr',\n",
       " 'コーヒードリンク_per_mstr',\n",
       " '新ジャンル_per_mstr',\n",
       " '日本茶・麦茶ドリンク_per_mstr',\n",
       " '水_per_mstr',\n",
       " '発泡酒_per_mstr',\n",
       " 'その他茶ドリンク_per_mstr',\n",
       " '炭酸水_per_mstr']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_after = train_tmp.copy()\n",
    "test_after = test_tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_after = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/case9_train.pkl\")\n",
    "# test_after = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/case9_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "      <th>purchase_id_amount_sum</th>\n",
       "      <th>purchase_id_amount_max</th>\n",
       "      <th>purchase_id_amount_min</th>\n",
       "      <th>purchase_id_amount_mean</th>\n",
       "      <th>purchase_id_amount_std</th>\n",
       "      <th>purchase_id_amount_median</th>\n",
       "      <th>purchase_id_total_sum</th>\n",
       "      <th>purchase_id_total_max</th>\n",
       "      <th>purchase_id_total_min</th>\n",
       "      <th>purchase_id_total_mean</th>\n",
       "      <th>purchase_id_total_std</th>\n",
       "      <th>purchase_id_total_median</th>\n",
       "      <th>purchase_id_p_time_sum</th>\n",
       "      <th>purchase_id_p_time_max</th>\n",
       "      <th>purchase_id_p_time_min</th>\n",
       "      <th>purchase_id_p_time_mean</th>\n",
       "      <th>purchase_id_p_time_std</th>\n",
       "      <th>purchase_id_p_time_median</th>\n",
       "      <th>purchase_id_ccl_category_cd4_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd4_nunique</th>\n",
       "      <th>purchase_id_ccl_jan_mode</th>\n",
       "      <th>purchase_id_ccl_jan_nunique</th>\n",
       "      <th>purchase_id_jan_name_mode</th>\n",
       "      <th>purchase_id_jan_name_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd1_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd2_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd3_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name1_mode</th>\n",
       "      <th>purchase_id_ccl_category_name1_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_category_name3_menrui_ammount_div</th>\n",
       "      <th>ccl_category_name3_tataki_ammount_div</th>\n",
       "      <th>ccl_category_name3_pan.shiriarurui_ammount_div</th>\n",
       "      <th>ccl_category_name3_nimono_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokanoyasairui_ammount_div</th>\n",
       "      <th>ccl_category_name3_kattofuruutsu_ammount_div</th>\n",
       "      <th>ccl_category_name3_konarui_ammount_div</th>\n",
       "      <th>ccl_category_name3_sengyosonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sunakku_ammount_div</th>\n",
       "      <th>ccl_category_name3_men.pasuta_ammount_div</th>\n",
       "      <th>ccl_category_name3_bentousonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokakakoushokuhin_ammount_div</th>\n",
       "      <th>ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div</th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>スナック_per_months</th>\n",
       "      <th>チョコレート_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>コーヒードリンク_per_months</th>\n",
       "      <th>米菓_per_months</th>\n",
       "      <th>新ジャンル_per_months</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_months</th>\n",
       "      <th>ビール_per_months</th>\n",
       "      <th>発泡酒_per_months</th>\n",
       "      <th>チューインガム_per_months</th>\n",
       "      <th>水_per_months</th>\n",
       "      <th>その他茶ドリンク_per_months</th>\n",
       "      <th>炭酸水_per_months</th>\n",
       "      <th>days_per_days</th>\n",
       "      <th>スナック_per_days</th>\n",
       "      <th>チョコレート_per_days</th>\n",
       "      <th>RTD_per_days</th>\n",
       "      <th>コーヒードリンク_per_days</th>\n",
       "      <th>米菓_per_days</th>\n",
       "      <th>新ジャンル_per_days</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_days</th>\n",
       "      <th>ビール_per_days</th>\n",
       "      <th>発泡酒_per_days</th>\n",
       "      <th>その他茶ドリンク_per_days</th>\n",
       "      <th>チューインガム_per_days</th>\n",
       "      <th>水_per_days</th>\n",
       "      <th>炭酸水_per_days</th>\n",
       "      <th>スナック_per_mstr</th>\n",
       "      <th>チョコレート_per_mstr</th>\n",
       "      <th>コーヒードリンク_per_mstr</th>\n",
       "      <th>新ジャンル_per_mstr</th>\n",
       "      <th>日本茶・麦茶ドリンク_per_mstr</th>\n",
       "      <th>水_per_mstr</th>\n",
       "      <th>発泡酒_per_mstr</th>\n",
       "      <th>その他茶ドリンク_per_mstr</th>\n",
       "      <th>炭酸水_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7ph4WbHqqe5y56C4jd6FZEYhits=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>4671.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>359.307692</td>\n",
       "      <td>491.775929</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>110131.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>610104.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>13.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nQsjoHBDtiJvKNUxzUoR4d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fjh/JffZa97gbQC02s6dvnxBt3k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>305.800000</td>\n",
       "      <td>113.247811</td>\n",
       "      <td>305.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110121.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>630201.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ほんだし 小袋 ８ｇ×２０</td>\n",
       "      <td>10.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>720100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>惣菜</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9qw6QFmtqjjbPS9pMrwi7S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xsff30jxW8NWlTO4wtmhKSVqoyo=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>23</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>223.555556</td>\n",
       "      <td>106.693616</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130401.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>610107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JocGnYfx4qYadKzeaPctLc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gWIikBeY29ACfcC2K86DlXa+P3o=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>17</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>280.526316</td>\n",
       "      <td>341.616967</td>\n",
       "      <td>158.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.501460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110507.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610102.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>おいしい牛乳 パック ５００ｍｌ</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62ubQAVp2p6UqUSA6Udxk2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ReeIrDXm95KKD/mOty0eD+1q33k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>423.500000</td>\n",
       "      <td>487.433219</td>\n",
       "      <td>199.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>130137.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>730497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>オールド ７００ｍｌ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123  130125  130129  130131  140307  140313  \\\n",
       "0  njibeyLPrsnu4HCopjBihW       0       0       0       0       0       0   \n",
       "1  nQsjoHBDtiJvKNUxzUoR4d       0       0       0       0       0       0   \n",
       "2  9qw6QFmtqjjbPS9pMrwi7S       0       0       1       0       0       0   \n",
       "3  JocGnYfx4qYadKzeaPctLc       0       0       0       1       0       0   \n",
       "4  62ubQAVp2p6UqUSA6Udxk2       1       0       0       1       1       0   \n",
       "\n",
       "   140316  140317  140321  140501  140505  140641  140691  \\\n",
       "0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       1       0   \n",
       "4       0       0       0       0       0       0       0   \n",
       "\n",
       "                           mpno                    mstr     p_date  p_time  \\\n",
       "0  7ph4WbHqqe5y56C4jd6FZEYhits=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "1  fjh/JffZa97gbQC02s6dvnxBt3k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      11   \n",
       "2  xsff30jxW8NWlTO4wtmhKSVqoyo=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      23   \n",
       "3  gWIikBeY29ACfcC2K86DlXa+P3o=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      17   \n",
       "4  ReeIrDXm95KKD/mOty0eD+1q33k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "\n",
       "   purchase_id_amount_sum  purchase_id_amount_max  purchase_id_amount_min  \\\n",
       "0                  4671.0                  1980.0                   108.0   \n",
       "1                  3058.0                   470.0                   134.0   \n",
       "2                  2012.0                   478.0                    96.0   \n",
       "3                  5330.0                  1580.0                    84.0   \n",
       "4                  3388.0                  1580.0                   138.0   \n",
       "\n",
       "   purchase_id_amount_mean  purchase_id_amount_std  purchase_id_amount_median  \\\n",
       "0               359.307692              491.775929                      198.0   \n",
       "1               305.800000              113.247811                      305.5   \n",
       "2               223.555556              106.693616                      198.0   \n",
       "3               280.526316              341.616967                      158.0   \n",
       "4               423.500000              487.433219                      199.0   \n",
       "\n",
       "   purchase_id_total_sum  purchase_id_total_max  purchase_id_total_min  \\\n",
       "0                   15.0                    2.0                    1.0   \n",
       "1                   14.0                    2.0                    1.0   \n",
       "2                    9.0                    1.0                    1.0   \n",
       "3                   22.0                    3.0                    1.0   \n",
       "4                   13.0                    4.0                    1.0   \n",
       "\n",
       "   purchase_id_total_mean  purchase_id_total_std  purchase_id_total_median  \\\n",
       "0                1.153846               0.375534                       1.0   \n",
       "1                1.400000               0.516398                       1.0   \n",
       "2                1.000000               0.000000                       1.0   \n",
       "3                1.157895               0.501460                       1.0   \n",
       "4                1.625000               1.060660                       1.0   \n",
       "\n",
       "   purchase_id_p_time_sum  purchase_id_p_time_max  purchase_id_p_time_min  \\\n",
       "0                   182.0                    14.0                    14.0   \n",
       "1                   110.0                    11.0                    11.0   \n",
       "2                   207.0                    23.0                    23.0   \n",
       "3                   323.0                    17.0                    17.0   \n",
       "4                   112.0                    14.0                    14.0   \n",
       "\n",
       "   purchase_id_p_time_mean  purchase_id_p_time_std  purchase_id_p_time_median  \\\n",
       "0                     14.0                     0.0                       14.0   \n",
       "1                     11.0                     0.0                       11.0   \n",
       "2                     23.0                     0.0                       23.0   \n",
       "3                     17.0                     0.0                       17.0   \n",
       "4                     14.0                     0.0                       14.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd4_mode  purchase_id_ccl_category_cd4_nunique  \\\n",
       "0                           110131.0                                  13.0   \n",
       "1                           110121.0                                  10.0   \n",
       "2                           130401.0                                   7.0   \n",
       "3                           110507.0                                  18.0   \n",
       "4                           130137.0                                   7.0   \n",
       "\n",
       "   purchase_id_ccl_jan_mode  purchase_id_ccl_jan_nunique  \\\n",
       "0                  610104.0                         13.0   \n",
       "1                  630201.0                         10.0   \n",
       "2                  610107.0                          9.0   \n",
       "3                  610102.0                         19.0   \n",
       "4                  730497.0                          8.0   \n",
       "\n",
       "  purchase_id_jan_name_mode  purchase_id_jan_name_nunique  \\\n",
       "0                 きのこ類_しめじ茸                          13.0   \n",
       "1             ほんだし 小袋 ８ｇ×２０                          10.0   \n",
       "2                 きのこ類_しめじ茸                           9.0   \n",
       "3          おいしい牛乳 パック ５００ｍｌ                          19.0   \n",
       "4                オールド ７００ｍｌ                           8.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd1_mode  purchase_id_ccl_category_cd1_nunique  \\\n",
       "0                           600000.0                                   2.0   \n",
       "1                           700000.0                                   3.0   \n",
       "2                           100000.0                                   3.0   \n",
       "3                           100000.0                                   3.0   \n",
       "4                           100000.0                                   2.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd2_mode  purchase_id_ccl_category_cd2_nunique  \\\n",
       "0                           610000.0                                   6.0   \n",
       "1                           720000.0                                   4.0   \n",
       "2                           130000.0                                   6.0   \n",
       "3                           110000.0                                   8.0   \n",
       "4                           130000.0                                   3.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd3_mode  purchase_id_ccl_category_cd3_nunique  \\\n",
       "0                           610100.0                                  11.0   \n",
       "1                           720100.0                                   9.0   \n",
       "2                           130400.0                                   7.0   \n",
       "3                           610100.0                                  15.0   \n",
       "4                           130100.0                                   6.0   \n",
       "\n",
       "  purchase_id_ccl_category_name1_mode  purchase_id_ccl_category_name1_nunique  \\\n",
       "0                                  生鮮                                     2.0   \n",
       "1                                  惣菜                                     3.0   \n",
       "2                                  生鮮                                     3.0   \n",
       "3                                  食品                                     3.0   \n",
       "4                                  食品                                     2.0   \n",
       "\n",
       "       ...      ccl_category_name3_menrui_ammount_div  \\\n",
       "0      ...                                   0.024029   \n",
       "1      ...                                   0.036537   \n",
       "2      ...                                   0.008176   \n",
       "3      ...                                   0.010804   \n",
       "4      ...                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_tataki_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.003151   \n",
       "4                               0.000000   \n",
       "\n",
       "  ccl_category_name3_pan.shiriarurui_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_nimono_ammount_div  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "  ccl_category_name3_sonohokanoyasairui_ammount_div  \\\n",
       "0                                          0.007678   \n",
       "1                                          0.000756   \n",
       "2                                          0.000000   \n",
       "3                                          0.000000   \n",
       "4                                          0.000000   \n",
       "\n",
       "   ccl_category_name3_kattofuruutsu_ammount_div  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.001359   \n",
       "2                                      0.000000   \n",
       "3                                      0.001619   \n",
       "4                                      0.000000   \n",
       "\n",
       "  ccl_category_name3_konarui_ammount_div  \\\n",
       "0                               0.008242   \n",
       "1                               0.002821   \n",
       "2                               0.000000   \n",
       "3                               0.001184   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_sengyosonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "  ccl_category_name3_sunakku_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.013893   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_men.pasuta_ammount_div  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.007337   \n",
       "2                                   0.000000   \n",
       "3                                   0.002575   \n",
       "4                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_bentousonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokakakoushokuhin_ammount_div  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   months_per_months  スナック_per_months  チョコレート_per_months  RTD_per_months  \\\n",
       "0                  1         0.638197           0.556225         0.09933   \n",
       "1                  1         0.638197           0.556225         0.09933   \n",
       "2                  1         0.638197           0.556225         0.09933   \n",
       "3                  1         0.638197           0.556225         0.09933   \n",
       "4                  1         0.638197           0.556225         0.09933   \n",
       "\n",
       "   コーヒードリンク_per_months  米菓_per_months  新ジャンル_per_months  \\\n",
       "0             0.031246        0.43026               0.0   \n",
       "1             0.031246        0.43026               0.0   \n",
       "2             0.031246        0.43026               0.0   \n",
       "3             0.031246        0.43026               0.0   \n",
       "4             0.031246        0.43026               0.0   \n",
       "\n",
       "   日本茶・麦茶ドリンク_per_months  ビール_per_months  発泡酒_per_months  チューインガム_per_months  \\\n",
       "0               0.041853             0.0             0.0            0.125129   \n",
       "1               0.041853             0.0             0.0            0.125129   \n",
       "2               0.041853             0.0             0.0            0.125129   \n",
       "3               0.041853             0.0             0.0            0.125129   \n",
       "4               0.041853             0.0             0.0            0.125129   \n",
       "\n",
       "   水_per_months  その他茶ドリンク_per_months  炭酸水_per_months  days_per_days  \\\n",
       "0       0.01858                  0.0        0.078538              2   \n",
       "1       0.01858                  0.0        0.078538              2   \n",
       "2       0.01858                  0.0        0.078538              2   \n",
       "3       0.01858                  0.0        0.078538              2   \n",
       "4       0.01858                  0.0        0.078538              2   \n",
       "\n",
       "   スナック_per_days  チョコレート_per_days  RTD_per_days  コーヒードリンク_per_days  \\\n",
       "0            0.0         0.306292      0.569746           0.309674   \n",
       "1            0.0         0.306292      0.569746           0.309674   \n",
       "2            0.0         0.306292      0.569746           0.309674   \n",
       "3            0.0         0.306292      0.569746           0.309674   \n",
       "4            0.0         0.306292      0.569746           0.309674   \n",
       "\n",
       "   米菓_per_days  新ジャンル_per_days  日本茶・麦茶ドリンク_per_days  ビール_per_days  \\\n",
       "0     0.312486             1.0             0.641796           1.0   \n",
       "1     0.312486             1.0             0.641796           1.0   \n",
       "2     0.312486             1.0             0.641796           1.0   \n",
       "3     0.312486             1.0             0.641796           1.0   \n",
       "4     0.312486             1.0             0.641796           1.0   \n",
       "\n",
       "   発泡酒_per_days  その他茶ドリンク_per_days  チューインガム_per_days  水_per_days  \\\n",
       "0      0.799642           0.895045          0.093191    0.765309   \n",
       "1      0.799642           0.895045          0.093191    0.765309   \n",
       "2      0.799642           0.895045          0.093191    0.765309   \n",
       "3      0.799642           0.895045          0.093191    0.765309   \n",
       "4      0.799642           0.895045          0.093191    0.765309   \n",
       "\n",
       "   炭酸水_per_days  スナック_per_mstr  チョコレート_per_mstr  コーヒードリンク_per_mstr  \\\n",
       "0      0.105463       0.013318         0.008498           0.005858   \n",
       "1      0.105463       0.013318         0.008498           0.005858   \n",
       "2      0.105463       0.013318         0.008498           0.005858   \n",
       "3      0.105463       0.013318         0.008498           0.005858   \n",
       "4      0.105463       0.013318         0.008498           0.005858   \n",
       "\n",
       "   新ジャンル_per_mstr  日本茶・麦茶ドリンク_per_mstr  水_per_mstr  発泡酒_per_mstr  \\\n",
       "0        0.003332             0.002102    0.001044      0.001785   \n",
       "1        0.003332             0.002102    0.001044      0.001785   \n",
       "2        0.003332             0.002102    0.001044      0.001785   \n",
       "3        0.003332             0.002102    0.001044      0.001785   \n",
       "4        0.003332             0.002102    0.001044      0.001785   \n",
       "\n",
       "   その他茶ドリンク_per_mstr  炭酸水_per_mstr  \n",
       "0           0.000948       0.00072  \n",
       "1           0.000948       0.00072  \n",
       "2           0.000948       0.00072  \n",
       "3           0.000948       0.00072  \n",
       "4           0.000948       0.00072  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purchase_id                                                   0\n",
       "mpno                                                          0\n",
       "mstr                                                          0\n",
       "p_date                                                        0\n",
       "p_time                                                        0\n",
       "purchase_id_amount_sum                                        0\n",
       "purchase_id_amount_max                                        0\n",
       "purchase_id_amount_min                                        0\n",
       "purchase_id_amount_mean                                       0\n",
       "purchase_id_amount_std                                        0\n",
       "purchase_id_amount_median                                     0\n",
       "purchase_id_total_sum                                         0\n",
       "purchase_id_total_max                                         0\n",
       "purchase_id_total_min                                         0\n",
       "purchase_id_total_mean                                        0\n",
       "purchase_id_total_std                                         0\n",
       "purchase_id_total_median                                      0\n",
       "purchase_id_p_time_sum                                        0\n",
       "purchase_id_p_time_max                                        0\n",
       "purchase_id_p_time_min                                        0\n",
       "purchase_id_p_time_mean                                       0\n",
       "purchase_id_p_time_std                                        0\n",
       "purchase_id_p_time_median                                     0\n",
       "purchase_id_ccl_category_cd4_mode                             0\n",
       "purchase_id_ccl_category_cd4_nunique                          0\n",
       "purchase_id_ccl_jan_mode                                      0\n",
       "purchase_id_ccl_jan_nunique                                   0\n",
       "purchase_id_jan_name_mode                                     0\n",
       "purchase_id_jan_name_nunique                                  0\n",
       "purchase_id_ccl_category_cd1_mode                             0\n",
       "purchase_id_ccl_category_cd1_nunique                          0\n",
       "purchase_id_ccl_category_cd2_mode                             0\n",
       "purchase_id_ccl_category_cd2_nunique                          0\n",
       "purchase_id_ccl_category_cd3_mode                             0\n",
       "purchase_id_ccl_category_cd3_nunique                          0\n",
       "purchase_id_ccl_category_name1_mode                           0\n",
       "purchase_id_ccl_category_name1_nunique                        0\n",
       "purchase_id_ccl_category_name2_mode                           0\n",
       "purchase_id_ccl_category_name2_nunique                        0\n",
       "purchase_id_ccl_category_name3_mode                           0\n",
       "purchase_id_ccl_category_name3_nunique                        0\n",
       "purchase_id_ccl_category_name4_mode                           0\n",
       "purchase_id_ccl_category_name4_nunique                        0\n",
       "purchase_id_mpno_mode                                         0\n",
       "purchase_id_mpno_nunique                                      0\n",
       "purchase_id_mstr_mode                                         0\n",
       "purchase_id_mstr_nunique                                      0\n",
       "years                                                         0\n",
       "months                                                        0\n",
       "days                                                          0\n",
       "                                                             ..\n",
       "ccl_category_name3_menrui_ammount_div                         0\n",
       "ccl_category_name3_tataki_ammount_div                         0\n",
       "ccl_category_name3_pan.shiriarurui_ammount_div                0\n",
       "ccl_category_name3_nimono_ammount_div                         0\n",
       "ccl_category_name3_sonohokanoyasairui_ammount_div             0\n",
       "ccl_category_name3_kattofuruutsu_ammount_div                  0\n",
       "ccl_category_name3_konarui_ammount_div                        0\n",
       "ccl_category_name3_sengyosonohoka_ammount_div                 0\n",
       "ccl_category_name3_sunakku_ammount_div                        0\n",
       "ccl_category_name3_men.pasuta_ammount_div                     0\n",
       "ccl_category_name3_bentousonohoka_ammount_div                 0\n",
       "ccl_category_name3_sonohokakakoushokuhin_ammount_div          0\n",
       "ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div    0\n",
       "months_per_months                                             0\n",
       "sunakku_per_months                                            0\n",
       "chokoreeto_per_months                                         0\n",
       "RTD_per_months                                                0\n",
       "koohiidorinku_per_months                                      0\n",
       "komeka_per_months                                             0\n",
       "shinjanru_per_months                                          0\n",
       "nihoncha.mugichadorinku_per_months                            0\n",
       "biiru_per_months                                              0\n",
       "happousake_per_months                                         0\n",
       "chuuingamu_per_months                                         0\n",
       "mizu_per_months                                               0\n",
       "sonohokachadorinku_per_months                                 0\n",
       "tansansui_per_months                                          0\n",
       "days_per_days                                                 0\n",
       "sunakku_per_days                                              0\n",
       "chokoreeto_per_days                                           0\n",
       "RTD_per_days                                                  0\n",
       "koohiidorinku_per_days                                        0\n",
       "komeka_per_days                                               0\n",
       "shinjanru_per_days                                            0\n",
       "nihoncha.mugichadorinku_per_days                              0\n",
       "biiru_per_days                                                0\n",
       "happousake_per_days                                           0\n",
       "sonohokachadorinku_per_days                                   0\n",
       "chuuingamu_per_days                                           0\n",
       "mizu_per_days                                                 0\n",
       "tansansui_per_days                                            0\n",
       "sunakku_per_mstr                                              0\n",
       "chokoreeto_per_mstr                                           0\n",
       "koohiidorinku_per_mstr                                        0\n",
       "shinjanru_per_mstr                                            0\n",
       "nihoncha.mugichadorinku_per_mstr                              0\n",
       "mizu_per_mstr                                                 0\n",
       "happousake_per_mstr                                           0\n",
       "sonohokachadorinku_per_mstr                                   0\n",
       "tansansui_per_mstr                                            0\n",
       "Length: 381, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_after.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128376, 394)\n",
      "(96505, 381)\n"
     ]
    }
   ],
   "source": [
    "print(train_after.shape)\n",
    "print(test_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykakasi import kakasi\n",
    "\n",
    "kakasi = kakasi()\n",
    "\n",
    "kakasi.setMode('H', 'a')\n",
    "kakasi.setMode('K', 'a')\n",
    "kakasi.setMode('J', 'a')\n",
    "\n",
    "conv = kakasi.getConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list_train = []\n",
    "\n",
    "for i in train_after.columns.tolist():\n",
    "    columns_list_train.append(conv.do(i))\n",
    "\n",
    "train_after.columns = columns_list_train\n",
    "\n",
    "columns_list_test = []\n",
    "\n",
    "for i in test_after.columns.tolist():\n",
    "    columns_list_test.append(conv.do(i))\n",
    "\n",
    "test_after.columns = columns_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "      <th>purchase_id_amount_sum</th>\n",
       "      <th>purchase_id_amount_max</th>\n",
       "      <th>purchase_id_amount_min</th>\n",
       "      <th>purchase_id_amount_mean</th>\n",
       "      <th>purchase_id_amount_std</th>\n",
       "      <th>purchase_id_amount_median</th>\n",
       "      <th>purchase_id_total_sum</th>\n",
       "      <th>purchase_id_total_max</th>\n",
       "      <th>purchase_id_total_min</th>\n",
       "      <th>purchase_id_total_mean</th>\n",
       "      <th>purchase_id_total_std</th>\n",
       "      <th>purchase_id_total_median</th>\n",
       "      <th>purchase_id_p_time_sum</th>\n",
       "      <th>purchase_id_p_time_max</th>\n",
       "      <th>purchase_id_p_time_min</th>\n",
       "      <th>purchase_id_p_time_mean</th>\n",
       "      <th>purchase_id_p_time_std</th>\n",
       "      <th>purchase_id_p_time_median</th>\n",
       "      <th>purchase_id_ccl_category_cd4_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd4_nunique</th>\n",
       "      <th>purchase_id_ccl_jan_mode</th>\n",
       "      <th>purchase_id_ccl_jan_nunique</th>\n",
       "      <th>purchase_id_jan_name_mode</th>\n",
       "      <th>purchase_id_jan_name_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd1_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd2_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd3_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name1_mode</th>\n",
       "      <th>purchase_id_ccl_category_name1_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_category_name3_menrui_ammount_div</th>\n",
       "      <th>ccl_category_name3_tataki_ammount_div</th>\n",
       "      <th>ccl_category_name3_pan.shiriarurui_ammount_div</th>\n",
       "      <th>ccl_category_name3_nimono_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokanoyasairui_ammount_div</th>\n",
       "      <th>ccl_category_name3_kattofuruutsu_ammount_div</th>\n",
       "      <th>ccl_category_name3_konarui_ammount_div</th>\n",
       "      <th>ccl_category_name3_sengyosonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sunakku_ammount_div</th>\n",
       "      <th>ccl_category_name3_men.pasuta_ammount_div</th>\n",
       "      <th>ccl_category_name3_bentousonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokakakoushokuhin_ammount_div</th>\n",
       "      <th>ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div</th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>sunakku_per_months</th>\n",
       "      <th>chokoreeto_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>koohiidorinku_per_months</th>\n",
       "      <th>komeka_per_months</th>\n",
       "      <th>shinjanru_per_months</th>\n",
       "      <th>nihoncha.mugichadorinku_per_months</th>\n",
       "      <th>biiru_per_months</th>\n",
       "      <th>happousake_per_months</th>\n",
       "      <th>chuuingamu_per_months</th>\n",
       "      <th>mizu_per_months</th>\n",
       "      <th>sonohokachadorinku_per_months</th>\n",
       "      <th>tansansui_per_months</th>\n",
       "      <th>days_per_days</th>\n",
       "      <th>sunakku_per_days</th>\n",
       "      <th>chokoreeto_per_days</th>\n",
       "      <th>RTD_per_days</th>\n",
       "      <th>koohiidorinku_per_days</th>\n",
       "      <th>komeka_per_days</th>\n",
       "      <th>shinjanru_per_days</th>\n",
       "      <th>nihoncha.mugichadorinku_per_days</th>\n",
       "      <th>biiru_per_days</th>\n",
       "      <th>happousake_per_days</th>\n",
       "      <th>sonohokachadorinku_per_days</th>\n",
       "      <th>chuuingamu_per_days</th>\n",
       "      <th>mizu_per_days</th>\n",
       "      <th>tansansui_per_days</th>\n",
       "      <th>sunakku_per_mstr</th>\n",
       "      <th>chokoreeto_per_mstr</th>\n",
       "      <th>koohiidorinku_per_mstr</th>\n",
       "      <th>shinjanru_per_mstr</th>\n",
       "      <th>nihoncha.mugichadorinku_per_mstr</th>\n",
       "      <th>mizu_per_mstr</th>\n",
       "      <th>happousake_per_mstr</th>\n",
       "      <th>sonohokachadorinku_per_mstr</th>\n",
       "      <th>tansansui_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7ph4WbHqqe5y56C4jd6FZEYhits=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>4671.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>359.307692</td>\n",
       "      <td>491.775929</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>110131.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>610104.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>13.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nQsjoHBDtiJvKNUxzUoR4d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fjh/JffZa97gbQC02s6dvnxBt3k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>305.800000</td>\n",
       "      <td>113.247811</td>\n",
       "      <td>305.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110121.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>630201.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ほんだし 小袋 ８ｇ×２０</td>\n",
       "      <td>10.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>720100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>惣菜</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9qw6QFmtqjjbPS9pMrwi7S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xsff30jxW8NWlTO4wtmhKSVqoyo=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>23</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>223.555556</td>\n",
       "      <td>106.693616</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130401.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>610107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>きのこ類_しめじ茸</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JocGnYfx4qYadKzeaPctLc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gWIikBeY29ACfcC2K86DlXa+P3o=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>17</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>280.526316</td>\n",
       "      <td>341.616967</td>\n",
       "      <td>158.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.501460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110507.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610102.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>おいしい牛乳 パック ５００ｍｌ</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62ubQAVp2p6UqUSA6Udxk2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ReeIrDXm95KKD/mOty0eD+1q33k=</td>\n",
       "      <td>2rQSaktE9DDZe46wJuDCDC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>423.500000</td>\n",
       "      <td>487.433219</td>\n",
       "      <td>199.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>130137.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>730497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>オールド ７００ｍｌ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>食品</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123  130125  130129  130131  140307  140313  \\\n",
       "0  njibeyLPrsnu4HCopjBihW       0       0       0       0       0       0   \n",
       "1  nQsjoHBDtiJvKNUxzUoR4d       0       0       0       0       0       0   \n",
       "2  9qw6QFmtqjjbPS9pMrwi7S       0       0       1       0       0       0   \n",
       "3  JocGnYfx4qYadKzeaPctLc       0       0       0       1       0       0   \n",
       "4  62ubQAVp2p6UqUSA6Udxk2       1       0       0       1       1       0   \n",
       "\n",
       "   140316  140317  140321  140501  140505  140641  140691  \\\n",
       "0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       1       0   \n",
       "4       0       0       0       0       0       0       0   \n",
       "\n",
       "                           mpno                    mstr     p_date  p_time  \\\n",
       "0  7ph4WbHqqe5y56C4jd6FZEYhits=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "1  fjh/JffZa97gbQC02s6dvnxBt3k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      11   \n",
       "2  xsff30jxW8NWlTO4wtmhKSVqoyo=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      23   \n",
       "3  gWIikBeY29ACfcC2K86DlXa+P3o=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      17   \n",
       "4  ReeIrDXm95KKD/mOty0eD+1q33k=  2rQSaktE9DDZe46wJuDCDC 2017-01-02      14   \n",
       "\n",
       "   purchase_id_amount_sum  purchase_id_amount_max  purchase_id_amount_min  \\\n",
       "0                  4671.0                  1980.0                   108.0   \n",
       "1                  3058.0                   470.0                   134.0   \n",
       "2                  2012.0                   478.0                    96.0   \n",
       "3                  5330.0                  1580.0                    84.0   \n",
       "4                  3388.0                  1580.0                   138.0   \n",
       "\n",
       "   purchase_id_amount_mean  purchase_id_amount_std  purchase_id_amount_median  \\\n",
       "0               359.307692              491.775929                      198.0   \n",
       "1               305.800000              113.247811                      305.5   \n",
       "2               223.555556              106.693616                      198.0   \n",
       "3               280.526316              341.616967                      158.0   \n",
       "4               423.500000              487.433219                      199.0   \n",
       "\n",
       "   purchase_id_total_sum  purchase_id_total_max  purchase_id_total_min  \\\n",
       "0                   15.0                    2.0                    1.0   \n",
       "1                   14.0                    2.0                    1.0   \n",
       "2                    9.0                    1.0                    1.0   \n",
       "3                   22.0                    3.0                    1.0   \n",
       "4                   13.0                    4.0                    1.0   \n",
       "\n",
       "   purchase_id_total_mean  purchase_id_total_std  purchase_id_total_median  \\\n",
       "0                1.153846               0.375534                       1.0   \n",
       "1                1.400000               0.516398                       1.0   \n",
       "2                1.000000               0.000000                       1.0   \n",
       "3                1.157895               0.501460                       1.0   \n",
       "4                1.625000               1.060660                       1.0   \n",
       "\n",
       "   purchase_id_p_time_sum  purchase_id_p_time_max  purchase_id_p_time_min  \\\n",
       "0                   182.0                    14.0                    14.0   \n",
       "1                   110.0                    11.0                    11.0   \n",
       "2                   207.0                    23.0                    23.0   \n",
       "3                   323.0                    17.0                    17.0   \n",
       "4                   112.0                    14.0                    14.0   \n",
       "\n",
       "   purchase_id_p_time_mean  purchase_id_p_time_std  purchase_id_p_time_median  \\\n",
       "0                     14.0                     0.0                       14.0   \n",
       "1                     11.0                     0.0                       11.0   \n",
       "2                     23.0                     0.0                       23.0   \n",
       "3                     17.0                     0.0                       17.0   \n",
       "4                     14.0                     0.0                       14.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd4_mode  purchase_id_ccl_category_cd4_nunique  \\\n",
       "0                           110131.0                                  13.0   \n",
       "1                           110121.0                                  10.0   \n",
       "2                           130401.0                                   7.0   \n",
       "3                           110507.0                                  18.0   \n",
       "4                           130137.0                                   7.0   \n",
       "\n",
       "   purchase_id_ccl_jan_mode  purchase_id_ccl_jan_nunique  \\\n",
       "0                  610104.0                         13.0   \n",
       "1                  630201.0                         10.0   \n",
       "2                  610107.0                          9.0   \n",
       "3                  610102.0                         19.0   \n",
       "4                  730497.0                          8.0   \n",
       "\n",
       "  purchase_id_jan_name_mode  purchase_id_jan_name_nunique  \\\n",
       "0                 きのこ類_しめじ茸                          13.0   \n",
       "1             ほんだし 小袋 ８ｇ×２０                          10.0   \n",
       "2                 きのこ類_しめじ茸                           9.0   \n",
       "3          おいしい牛乳 パック ５００ｍｌ                          19.0   \n",
       "4                オールド ７００ｍｌ                           8.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd1_mode  purchase_id_ccl_category_cd1_nunique  \\\n",
       "0                           600000.0                                   2.0   \n",
       "1                           700000.0                                   3.0   \n",
       "2                           100000.0                                   3.0   \n",
       "3                           100000.0                                   3.0   \n",
       "4                           100000.0                                   2.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd2_mode  purchase_id_ccl_category_cd2_nunique  \\\n",
       "0                           610000.0                                   6.0   \n",
       "1                           720000.0                                   4.0   \n",
       "2                           130000.0                                   6.0   \n",
       "3                           110000.0                                   8.0   \n",
       "4                           130000.0                                   3.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd3_mode  purchase_id_ccl_category_cd3_nunique  \\\n",
       "0                           610100.0                                  11.0   \n",
       "1                           720100.0                                   9.0   \n",
       "2                           130400.0                                   7.0   \n",
       "3                           610100.0                                  15.0   \n",
       "4                           130100.0                                   6.0   \n",
       "\n",
       "  purchase_id_ccl_category_name1_mode  purchase_id_ccl_category_name1_nunique  \\\n",
       "0                                  生鮮                                     2.0   \n",
       "1                                  惣菜                                     3.0   \n",
       "2                                  生鮮                                     3.0   \n",
       "3                                  食品                                     3.0   \n",
       "4                                  食品                                     2.0   \n",
       "\n",
       "          ...         ccl_category_name3_menrui_ammount_div  \\\n",
       "0         ...                                      0.024029   \n",
       "1         ...                                      0.036537   \n",
       "2         ...                                      0.008176   \n",
       "3         ...                                      0.010804   \n",
       "4         ...                                      0.000000   \n",
       "\n",
       "   ccl_category_name3_tataki_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.003151   \n",
       "4                               0.000000   \n",
       "\n",
       "  ccl_category_name3_pan.shiriarurui_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_nimono_ammount_div  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "  ccl_category_name3_sonohokanoyasairui_ammount_div  \\\n",
       "0                                          0.007678   \n",
       "1                                          0.000756   \n",
       "2                                          0.000000   \n",
       "3                                          0.000000   \n",
       "4                                          0.000000   \n",
       "\n",
       "   ccl_category_name3_kattofuruutsu_ammount_div  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.001359   \n",
       "2                                      0.000000   \n",
       "3                                      0.001619   \n",
       "4                                      0.000000   \n",
       "\n",
       "  ccl_category_name3_konarui_ammount_div  \\\n",
       "0                               0.008242   \n",
       "1                               0.002821   \n",
       "2                               0.000000   \n",
       "3                               0.001184   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_sengyosonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "  ccl_category_name3_sunakku_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.013893   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_men.pasuta_ammount_div  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.007337   \n",
       "2                                   0.000000   \n",
       "3                                   0.002575   \n",
       "4                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_bentousonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokakakoushokuhin_ammount_div  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   months_per_months  sunakku_per_months  chokoreeto_per_months  \\\n",
       "0                  1            0.638197               0.556225   \n",
       "1                  1            0.638197               0.556225   \n",
       "2                  1            0.638197               0.556225   \n",
       "3                  1            0.638197               0.556225   \n",
       "4                  1            0.638197               0.556225   \n",
       "\n",
       "   RTD_per_months  koohiidorinku_per_months  komeka_per_months  \\\n",
       "0         0.09933                  0.031246            0.43026   \n",
       "1         0.09933                  0.031246            0.43026   \n",
       "2         0.09933                  0.031246            0.43026   \n",
       "3         0.09933                  0.031246            0.43026   \n",
       "4         0.09933                  0.031246            0.43026   \n",
       "\n",
       "   shinjanru_per_months  nihoncha.mugichadorinku_per_months  biiru_per_months  \\\n",
       "0                   0.0                            0.041853               0.0   \n",
       "1                   0.0                            0.041853               0.0   \n",
       "2                   0.0                            0.041853               0.0   \n",
       "3                   0.0                            0.041853               0.0   \n",
       "4                   0.0                            0.041853               0.0   \n",
       "\n",
       "   happousake_per_months  chuuingamu_per_months  mizu_per_months  \\\n",
       "0                    0.0               0.125129          0.01858   \n",
       "1                    0.0               0.125129          0.01858   \n",
       "2                    0.0               0.125129          0.01858   \n",
       "3                    0.0               0.125129          0.01858   \n",
       "4                    0.0               0.125129          0.01858   \n",
       "\n",
       "   sonohokachadorinku_per_months  tansansui_per_months  days_per_days  \\\n",
       "0                            0.0              0.078538              2   \n",
       "1                            0.0              0.078538              2   \n",
       "2                            0.0              0.078538              2   \n",
       "3                            0.0              0.078538              2   \n",
       "4                            0.0              0.078538              2   \n",
       "\n",
       "   sunakku_per_days  chokoreeto_per_days  RTD_per_days  \\\n",
       "0               0.0             0.306292      0.569746   \n",
       "1               0.0             0.306292      0.569746   \n",
       "2               0.0             0.306292      0.569746   \n",
       "3               0.0             0.306292      0.569746   \n",
       "4               0.0             0.306292      0.569746   \n",
       "\n",
       "   koohiidorinku_per_days  komeka_per_days  shinjanru_per_days  \\\n",
       "0                0.309674         0.312486                 1.0   \n",
       "1                0.309674         0.312486                 1.0   \n",
       "2                0.309674         0.312486                 1.0   \n",
       "3                0.309674         0.312486                 1.0   \n",
       "4                0.309674         0.312486                 1.0   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_days  biiru_per_days  happousake_per_days  \\\n",
       "0                          0.641796             1.0             0.799642   \n",
       "1                          0.641796             1.0             0.799642   \n",
       "2                          0.641796             1.0             0.799642   \n",
       "3                          0.641796             1.0             0.799642   \n",
       "4                          0.641796             1.0             0.799642   \n",
       "\n",
       "   sonohokachadorinku_per_days  chuuingamu_per_days  mizu_per_days  \\\n",
       "0                     0.895045             0.093191       0.765309   \n",
       "1                     0.895045             0.093191       0.765309   \n",
       "2                     0.895045             0.093191       0.765309   \n",
       "3                     0.895045             0.093191       0.765309   \n",
       "4                     0.895045             0.093191       0.765309   \n",
       "\n",
       "   tansansui_per_days  sunakku_per_mstr  chokoreeto_per_mstr  \\\n",
       "0            0.105463          0.013318             0.008498   \n",
       "1            0.105463          0.013318             0.008498   \n",
       "2            0.105463          0.013318             0.008498   \n",
       "3            0.105463          0.013318             0.008498   \n",
       "4            0.105463          0.013318             0.008498   \n",
       "\n",
       "   koohiidorinku_per_mstr  shinjanru_per_mstr  \\\n",
       "0                0.005858            0.003332   \n",
       "1                0.005858            0.003332   \n",
       "2                0.005858            0.003332   \n",
       "3                0.005858            0.003332   \n",
       "4                0.005858            0.003332   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_mstr  mizu_per_mstr  happousake_per_mstr  \\\n",
       "0                          0.002102       0.001044             0.001785   \n",
       "1                          0.002102       0.001044             0.001785   \n",
       "2                          0.002102       0.001044             0.001785   \n",
       "3                          0.002102       0.001044             0.001785   \n",
       "4                          0.002102       0.001044             0.001785   \n",
       "\n",
       "   sonohokachadorinku_per_mstr  tansansui_per_mstr  \n",
       "0                     0.000948             0.00072  \n",
       "1                     0.000948             0.00072  \n",
       "2                     0.000948             0.00072  \n",
       "3                     0.000948             0.00072  \n",
       "4                     0.000948             0.00072  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "      <th>purchase_id_amount_sum</th>\n",
       "      <th>purchase_id_amount_max</th>\n",
       "      <th>purchase_id_amount_min</th>\n",
       "      <th>purchase_id_amount_mean</th>\n",
       "      <th>purchase_id_amount_std</th>\n",
       "      <th>purchase_id_amount_median</th>\n",
       "      <th>purchase_id_total_sum</th>\n",
       "      <th>purchase_id_total_max</th>\n",
       "      <th>purchase_id_total_min</th>\n",
       "      <th>purchase_id_total_mean</th>\n",
       "      <th>purchase_id_total_std</th>\n",
       "      <th>purchase_id_total_median</th>\n",
       "      <th>purchase_id_p_time_sum</th>\n",
       "      <th>purchase_id_p_time_max</th>\n",
       "      <th>purchase_id_p_time_min</th>\n",
       "      <th>purchase_id_p_time_mean</th>\n",
       "      <th>purchase_id_p_time_std</th>\n",
       "      <th>purchase_id_p_time_median</th>\n",
       "      <th>purchase_id_ccl_category_cd4_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd4_nunique</th>\n",
       "      <th>purchase_id_ccl_jan_mode</th>\n",
       "      <th>purchase_id_ccl_jan_nunique</th>\n",
       "      <th>purchase_id_jan_name_mode</th>\n",
       "      <th>purchase_id_jan_name_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd1_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd2_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd3_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name1_mode</th>\n",
       "      <th>purchase_id_ccl_category_name1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name2_mode</th>\n",
       "      <th>purchase_id_ccl_category_name2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name3_mode</th>\n",
       "      <th>purchase_id_ccl_category_name3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name4_mode</th>\n",
       "      <th>purchase_id_ccl_category_name4_nunique</th>\n",
       "      <th>purchase_id_mpno_mode</th>\n",
       "      <th>purchase_id_mpno_nunique</th>\n",
       "      <th>purchase_id_mstr_mode</th>\n",
       "      <th>purchase_id_mstr_nunique</th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th>days</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_category_name3_menrui_ammount_div</th>\n",
       "      <th>ccl_category_name3_tataki_ammount_div</th>\n",
       "      <th>ccl_category_name3_pan.shiriarurui_ammount_div</th>\n",
       "      <th>ccl_category_name3_nimono_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokanoyasairui_ammount_div</th>\n",
       "      <th>ccl_category_name3_kattofuruutsu_ammount_div</th>\n",
       "      <th>ccl_category_name3_konarui_ammount_div</th>\n",
       "      <th>ccl_category_name3_sengyosonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sunakku_ammount_div</th>\n",
       "      <th>ccl_category_name3_men.pasuta_ammount_div</th>\n",
       "      <th>ccl_category_name3_bentousonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokakakoushokuhin_ammount_div</th>\n",
       "      <th>ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div</th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>sunakku_per_months</th>\n",
       "      <th>chokoreeto_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>koohiidorinku_per_months</th>\n",
       "      <th>komeka_per_months</th>\n",
       "      <th>shinjanru_per_months</th>\n",
       "      <th>nihoncha.mugichadorinku_per_months</th>\n",
       "      <th>biiru_per_months</th>\n",
       "      <th>happousake_per_months</th>\n",
       "      <th>chuuingamu_per_months</th>\n",
       "      <th>mizu_per_months</th>\n",
       "      <th>sonohokachadorinku_per_months</th>\n",
       "      <th>tansansui_per_months</th>\n",
       "      <th>days_per_days</th>\n",
       "      <th>sunakku_per_days</th>\n",
       "      <th>chokoreeto_per_days</th>\n",
       "      <th>RTD_per_days</th>\n",
       "      <th>koohiidorinku_per_days</th>\n",
       "      <th>komeka_per_days</th>\n",
       "      <th>shinjanru_per_days</th>\n",
       "      <th>nihoncha.mugichadorinku_per_days</th>\n",
       "      <th>biiru_per_days</th>\n",
       "      <th>happousake_per_days</th>\n",
       "      <th>sonohokachadorinku_per_days</th>\n",
       "      <th>chuuingamu_per_days</th>\n",
       "      <th>mizu_per_days</th>\n",
       "      <th>tansansui_per_days</th>\n",
       "      <th>sunakku_per_mstr</th>\n",
       "      <th>chokoreeto_per_mstr</th>\n",
       "      <th>koohiidorinku_per_mstr</th>\n",
       "      <th>shinjanru_per_mstr</th>\n",
       "      <th>nihoncha.mugichadorinku_per_mstr</th>\n",
       "      <th>mizu_per_mstr</th>\n",
       "      <th>happousake_per_mstr</th>\n",
       "      <th>sonohokachadorinku_per_mstr</th>\n",
       "      <th>tansansui_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3rcdjjRyw9qSh6NcZMKSX</td>\n",
       "      <td>kQwpKd7TRuarL3bsB91Dd2+TirQ=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>18</td>\n",
       "      <td>3759</td>\n",
       "      <td>696</td>\n",
       "      <td>14</td>\n",
       "      <td>208.833333</td>\n",
       "      <td>205.933813</td>\n",
       "      <td>119.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>110101</td>\n",
       "      <td>18</td>\n",
       "      <td>610104</td>\n",
       "      <td>18</td>\n",
       "      <td>はごろもフーズ　ホームクッキング　シャキッとコーン　５５ｇ</td>\n",
       "      <td>18</td>\n",
       "      <td>600000</td>\n",
       "      <td>3</td>\n",
       "      <td>610000</td>\n",
       "      <td>4</td>\n",
       "      <td>610100</td>\n",
       "      <td>10</td>\n",
       "      <td>生鮮</td>\n",
       "      <td>3</td>\n",
       "      <td>野菜</td>\n",
       "      <td>4</td>\n",
       "      <td>葉茎菜類</td>\n",
       "      <td>10</td>\n",
       "      <td>マカロニ</td>\n",
       "      <td>18</td>\n",
       "      <td>kQwpKd7TRuarL3bsB91Dd2+TirQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167602</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.390085</td>\n",
       "      <td>0.48549</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.61375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5tZuLssiSvTz6parm5st3Z</td>\n",
       "      <td>FTkZjmN73p+HlTUVDjthH2Y2rzw=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>19</td>\n",
       "      <td>1568</td>\n",
       "      <td>278</td>\n",
       "      <td>14</td>\n",
       "      <td>142.545455</td>\n",
       "      <td>82.192899</td>\n",
       "      <td>160.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>209</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>130497</td>\n",
       "      <td>8</td>\n",
       "      <td>610116</td>\n",
       "      <td>11</td>\n",
       "      <td>あけぼの 赤ウインナーの磯辺揚げ １００ｇ</td>\n",
       "      <td>11</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>5</td>\n",
       "      <td>130400</td>\n",
       "      <td>7</td>\n",
       "      <td>食品</td>\n",
       "      <td>3</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>5</td>\n",
       "      <td>アイスクリーム類</td>\n",
       "      <td>7</td>\n",
       "      <td>パーソナルアイスその他</td>\n",
       "      <td>8</td>\n",
       "      <td>FTkZjmN73p+HlTUVDjthH2Y2rzw=</td>\n",
       "      <td>1</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167602</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.390085</td>\n",
       "      <td>0.48549</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.61375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>985Cz7UZBvH8MmuC4VEx8S</td>\n",
       "      <td>ICbaANt+HlbjCJ6Mb3JyqWK9aak=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>13</td>\n",
       "      <td>6998</td>\n",
       "      <td>1032</td>\n",
       "      <td>64</td>\n",
       "      <td>259.185185</td>\n",
       "      <td>245.722958</td>\n",
       "      <td>169.0</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>0.483341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>351</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>111503</td>\n",
       "      <td>25</td>\n",
       "      <td>610106</td>\n",
       "      <td>27</td>\n",
       "      <td>きのこ類_えのき茸</td>\n",
       "      <td>27</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>6</td>\n",
       "      <td>111500</td>\n",
       "      <td>17</td>\n",
       "      <td>食品</td>\n",
       "      <td>3</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>6</td>\n",
       "      <td>加工肉類</td>\n",
       "      <td>17</td>\n",
       "      <td>ファミリーアイス</td>\n",
       "      <td>25</td>\n",
       "      <td>ICbaANt+HlbjCJ6Mb3JyqWK9aak=</td>\n",
       "      <td>1</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167602</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.390085</td>\n",
       "      <td>0.48549</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.61375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raeKhHCqEs5t4pRouomkcT</td>\n",
       "      <td>MENV9zBNaM0lsnHEifB4TQEkndQ=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>18</td>\n",
       "      <td>803</td>\n",
       "      <td>187</td>\n",
       "      <td>38</td>\n",
       "      <td>114.714286</td>\n",
       "      <td>47.922557</td>\n",
       "      <td>112.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>111211</td>\n",
       "      <td>7</td>\n",
       "      <td>610501</td>\n",
       "      <td>7</td>\n",
       "      <td>その他の果物_バナナ</td>\n",
       "      <td>7</td>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>110000</td>\n",
       "      <td>4</td>\n",
       "      <td>111800</td>\n",
       "      <td>6</td>\n",
       "      <td>食品</td>\n",
       "      <td>2</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>4</td>\n",
       "      <td>水物</td>\n",
       "      <td>6</td>\n",
       "      <td>その他の果物_バナナ</td>\n",
       "      <td>7</td>\n",
       "      <td>MENV9zBNaM0lsnHEifB4TQEkndQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167602</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.390085</td>\n",
       "      <td>0.48549</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.61375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>msddw6HzRYiWtrLXvzrrA7</td>\n",
       "      <td>QnHw35dB6t+7q5FyS4FFv7ZSTZQ=</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>20</td>\n",
       "      <td>1713</td>\n",
       "      <td>578</td>\n",
       "      <td>138</td>\n",
       "      <td>244.714286</td>\n",
       "      <td>158.212636</td>\n",
       "      <td>195.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>111203</td>\n",
       "      <td>6</td>\n",
       "      <td>630102</td>\n",
       "      <td>7</td>\n",
       "      <td>イトウ製菓 ラングリー バニラクリームサンド １２枚</td>\n",
       "      <td>7</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>5</td>\n",
       "      <td>111200</td>\n",
       "      <td>6</td>\n",
       "      <td>食品</td>\n",
       "      <td>3</td>\n",
       "      <td>加工食品</td>\n",
       "      <td>5</td>\n",
       "      <td>麺類</td>\n",
       "      <td>6</td>\n",
       "      <td>カップ麺</td>\n",
       "      <td>6</td>\n",
       "      <td>QnHw35dB6t+7q5FyS4FFv7ZSTZQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>nTq4zA7dqePmgkhebPgdjR</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876234</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>0.367034</td>\n",
       "      <td>0.278157</td>\n",
       "      <td>0.410407</td>\n",
       "      <td>0.711879</td>\n",
       "      <td>0.325582</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.868953</td>\n",
       "      <td>0.557202</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.195202</td>\n",
       "      <td>0.344214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167602</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.518071</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.390085</td>\n",
       "      <td>0.48549</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.61375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386959</td>\n",
       "      <td>0.423009</td>\n",
       "      <td>0.344461</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id                          mpno  \\\n",
       "0  C3rcdjjRyw9qSh6NcZMKSX  kQwpKd7TRuarL3bsB91Dd2+TirQ=   \n",
       "1  5tZuLssiSvTz6parm5st3Z  FTkZjmN73p+HlTUVDjthH2Y2rzw=   \n",
       "2  985Cz7UZBvH8MmuC4VEx8S  ICbaANt+HlbjCJ6Mb3JyqWK9aak=   \n",
       "3  raeKhHCqEs5t4pRouomkcT  MENV9zBNaM0lsnHEifB4TQEkndQ=   \n",
       "4  msddw6HzRYiWtrLXvzrrA7  QnHw35dB6t+7q5FyS4FFv7ZSTZQ=   \n",
       "\n",
       "                     mstr     p_date  p_time  purchase_id_amount_sum  \\\n",
       "0  nTq4zA7dqePmgkhebPgdjR 2018-04-01      18                    3759   \n",
       "1  nTq4zA7dqePmgkhebPgdjR 2018-04-01      19                    1568   \n",
       "2  nTq4zA7dqePmgkhebPgdjR 2018-04-01      13                    6998   \n",
       "3  nTq4zA7dqePmgkhebPgdjR 2018-04-01      18                     803   \n",
       "4  nTq4zA7dqePmgkhebPgdjR 2018-04-01      20                    1713   \n",
       "\n",
       "   purchase_id_amount_max  purchase_id_amount_min  purchase_id_amount_mean  \\\n",
       "0                     696                      14               208.833333   \n",
       "1                     278                      14               142.545455   \n",
       "2                    1032                      64               259.185185   \n",
       "3                     187                      38               114.714286   \n",
       "4                     578                     138               244.714286   \n",
       "\n",
       "   purchase_id_amount_std  purchase_id_amount_median  purchase_id_total_sum  \\\n",
       "0              205.933813                      119.0                     19   \n",
       "1               82.192899                      160.0                     12   \n",
       "2              245.722958                      169.0                     32   \n",
       "3               47.922557                      112.0                      7   \n",
       "4              158.212636                      195.0                      9   \n",
       "\n",
       "   purchase_id_total_max  purchase_id_total_min  purchase_id_total_mean  \\\n",
       "0                      2                      1                1.055556   \n",
       "1                      2                      1                1.090909   \n",
       "2                      3                      1                1.185185   \n",
       "3                      1                      1                1.000000   \n",
       "4                      2                      1                1.285714   \n",
       "\n",
       "   purchase_id_total_std  purchase_id_total_median  purchase_id_p_time_sum  \\\n",
       "0               0.235702                       1.0                     324   \n",
       "1               0.301511                       1.0                     209   \n",
       "2               0.483341                       1.0                     351   \n",
       "3               0.000000                       1.0                     126   \n",
       "4               0.487950                       1.0                     140   \n",
       "\n",
       "   purchase_id_p_time_max  purchase_id_p_time_min  purchase_id_p_time_mean  \\\n",
       "0                      18                      18                       18   \n",
       "1                      19                      19                       19   \n",
       "2                      13                      13                       13   \n",
       "3                      18                      18                       18   \n",
       "4                      20                      20                       20   \n",
       "\n",
       "   purchase_id_p_time_std  purchase_id_p_time_median  \\\n",
       "0                     0.0                         18   \n",
       "1                     0.0                         19   \n",
       "2                     0.0                         13   \n",
       "3                     0.0                         18   \n",
       "4                     0.0                         20   \n",
       "\n",
       "   purchase_id_ccl_category_cd4_mode  purchase_id_ccl_category_cd4_nunique  \\\n",
       "0                             110101                                    18   \n",
       "1                             130497                                     8   \n",
       "2                             111503                                    25   \n",
       "3                             111211                                     7   \n",
       "4                             111203                                     6   \n",
       "\n",
       "   purchase_id_ccl_jan_mode  purchase_id_ccl_jan_nunique  \\\n",
       "0                    610104                           18   \n",
       "1                    610116                           11   \n",
       "2                    610106                           27   \n",
       "3                    610501                            7   \n",
       "4                    630102                            7   \n",
       "\n",
       "       purchase_id_jan_name_mode  purchase_id_jan_name_nunique  \\\n",
       "0  はごろもフーズ　ホームクッキング　シャキッとコーン　５５ｇ                            18   \n",
       "1          あけぼの 赤ウインナーの磯辺揚げ １００ｇ                            11   \n",
       "2                      きのこ類_えのき茸                            27   \n",
       "3                     その他の果物_バナナ                             7   \n",
       "4     イトウ製菓 ラングリー バニラクリームサンド １２枚                             7   \n",
       "\n",
       "   purchase_id_ccl_category_cd1_mode  purchase_id_ccl_category_cd1_nunique  \\\n",
       "0                             600000                                     3   \n",
       "1                             100000                                     3   \n",
       "2                             100000                                     3   \n",
       "3                             100000                                     2   \n",
       "4                             100000                                     3   \n",
       "\n",
       "   purchase_id_ccl_category_cd2_mode  purchase_id_ccl_category_cd2_nunique  \\\n",
       "0                             610000                                     4   \n",
       "1                             110000                                     5   \n",
       "2                             110000                                     6   \n",
       "3                             110000                                     4   \n",
       "4                             110000                                     5   \n",
       "\n",
       "   purchase_id_ccl_category_cd3_mode  purchase_id_ccl_category_cd3_nunique  \\\n",
       "0                             610100                                    10   \n",
       "1                             130400                                     7   \n",
       "2                             111500                                    17   \n",
       "3                             111800                                     6   \n",
       "4                             111200                                     6   \n",
       "\n",
       "  purchase_id_ccl_category_name1_mode  purchase_id_ccl_category_name1_nunique  \\\n",
       "0                                  生鮮                                       3   \n",
       "1                                  食品                                       3   \n",
       "2                                  食品                                       3   \n",
       "3                                  食品                                       2   \n",
       "4                                  食品                                       3   \n",
       "\n",
       "  purchase_id_ccl_category_name2_mode  purchase_id_ccl_category_name2_nunique  \\\n",
       "0                                  野菜                                       4   \n",
       "1                                加工食品                                       5   \n",
       "2                                加工食品                                       6   \n",
       "3                                加工食品                                       4   \n",
       "4                                加工食品                                       5   \n",
       "\n",
       "  purchase_id_ccl_category_name3_mode  purchase_id_ccl_category_name3_nunique  \\\n",
       "0                                葉茎菜類                                      10   \n",
       "1                            アイスクリーム類                                       7   \n",
       "2                                加工肉類                                      17   \n",
       "3                                  水物                                       6   \n",
       "4                                  麺類                                       6   \n",
       "\n",
       "  purchase_id_ccl_category_name4_mode  purchase_id_ccl_category_name4_nunique  \\\n",
       "0                                マカロニ                                      18   \n",
       "1                         パーソナルアイスその他                                       8   \n",
       "2                            ファミリーアイス                                      25   \n",
       "3                          その他の果物_バナナ                                       7   \n",
       "4                                カップ麺                                       6   \n",
       "\n",
       "          purchase_id_mpno_mode  purchase_id_mpno_nunique  \\\n",
       "0  kQwpKd7TRuarL3bsB91Dd2+TirQ=                         1   \n",
       "1  FTkZjmN73p+HlTUVDjthH2Y2rzw=                         1   \n",
       "2  ICbaANt+HlbjCJ6Mb3JyqWK9aak=                         1   \n",
       "3  MENV9zBNaM0lsnHEifB4TQEkndQ=                         1   \n",
       "4  QnHw35dB6t+7q5FyS4FFv7ZSTZQ=                         1   \n",
       "\n",
       "    purchase_id_mstr_mode  purchase_id_mstr_nunique  years  months  days  \\\n",
       "0  nTq4zA7dqePmgkhebPgdjR                         1   2018       4     1   \n",
       "1  nTq4zA7dqePmgkhebPgdjR                         1   2018       4     1   \n",
       "2  nTq4zA7dqePmgkhebPgdjR                         1   2018       4     1   \n",
       "3  nTq4zA7dqePmgkhebPgdjR                         1   2018       4     1   \n",
       "4  nTq4zA7dqePmgkhebPgdjR                         1   2018       4     1   \n",
       "\n",
       "          ...          ccl_category_name3_menrui_ammount_div  \\\n",
       "0         ...                                       0.011838   \n",
       "1         ...                                       0.019764   \n",
       "2         ...                                       0.013975   \n",
       "3         ...                                       0.018449   \n",
       "4         ...                                       0.010336   \n",
       "\n",
       "   ccl_category_name3_tataki_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.005740   \n",
       "2                               0.009399   \n",
       "3                               0.000000   \n",
       "4                               0.005456   \n",
       "\n",
       "   ccl_category_name3_pan.shiriarurui_ammount_div  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   ccl_category_name3_nimono_ammount_div  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokanoyasairui_ammount_div  \\\n",
       "0                                           0.000000   \n",
       "1                                           0.007166   \n",
       "2                                           0.000000   \n",
       "3                                           0.000000   \n",
       "4                                           0.000000   \n",
       "\n",
       "   ccl_category_name3_kattofuruutsu_ammount_div  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   ccl_category_name3_konarui_ammount_div  \\\n",
       "0                                0.000000   \n",
       "1                                0.000000   \n",
       "2                                0.002703   \n",
       "3                                0.000000   \n",
       "4                                0.000000   \n",
       "\n",
       "   ccl_category_name3_sengyosonohoka_ammount_div  \\\n",
       "0                                       0.000000   \n",
       "1                                       0.000000   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       0.003331   \n",
       "\n",
       "   ccl_category_name3_sunakku_ammount_div  \\\n",
       "0                                0.000000   \n",
       "1                                0.005740   \n",
       "2                                0.000000   \n",
       "3                                0.000000   \n",
       "4                                0.004387   \n",
       "\n",
       "   ccl_category_name3_men.pasuta_ammount_div  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.000000   \n",
       "2                                   0.000000   \n",
       "3                                   0.000000   \n",
       "4                                   0.004085   \n",
       "\n",
       "   ccl_category_name3_bentousonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokakakoushokuhin_ammount_div  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   months_per_months  sunakku_per_months  chokoreeto_per_months  \\\n",
       "0                  4            0.876234               0.453102   \n",
       "1                  4            0.876234               0.453102   \n",
       "2                  4            0.876234               0.453102   \n",
       "3                  4            0.876234               0.453102   \n",
       "4                  4            0.876234               0.453102   \n",
       "\n",
       "   RTD_per_months  koohiidorinku_per_months  komeka_per_months  \\\n",
       "0        0.367034                  0.278157           0.410407   \n",
       "1        0.367034                  0.278157           0.410407   \n",
       "2        0.367034                  0.278157           0.410407   \n",
       "3        0.367034                  0.278157           0.410407   \n",
       "4        0.367034                  0.278157           0.410407   \n",
       "\n",
       "   shinjanru_per_months  nihoncha.mugichadorinku_per_months  biiru_per_months  \\\n",
       "0              0.711879                            0.325582          0.873317   \n",
       "1              0.711879                            0.325582          0.873317   \n",
       "2              0.711879                            0.325582          0.873317   \n",
       "3              0.711879                            0.325582          0.873317   \n",
       "4              0.711879                            0.325582          0.873317   \n",
       "\n",
       "   happousake_per_months  chuuingamu_per_months  mizu_per_months  \\\n",
       "0               0.868953               0.557202           0.0721   \n",
       "1               0.868953               0.557202           0.0721   \n",
       "2               0.868953               0.557202           0.0721   \n",
       "3               0.868953               0.557202           0.0721   \n",
       "4               0.868953               0.557202           0.0721   \n",
       "\n",
       "   sonohokachadorinku_per_months  tansansui_per_months  days_per_days  \\\n",
       "0                       0.195202              0.344214              1   \n",
       "1                       0.195202              0.344214              1   \n",
       "2                       0.195202              0.344214              1   \n",
       "3                       0.195202              0.344214              1   \n",
       "4                       0.195202              0.344214              1   \n",
       "\n",
       "   sunakku_per_days  chokoreeto_per_days  RTD_per_days  \\\n",
       "0          0.167602             0.148109      0.518071   \n",
       "1          0.167602             0.148109      0.518071   \n",
       "2          0.167602             0.148109      0.518071   \n",
       "3          0.167602             0.148109      0.518071   \n",
       "4          0.167602             0.148109      0.518071   \n",
       "\n",
       "   koohiidorinku_per_days  komeka_per_days  shinjanru_per_days  \\\n",
       "0                0.220866         0.390085             0.48549   \n",
       "1                0.220866         0.390085             0.48549   \n",
       "2                0.220866         0.390085             0.48549   \n",
       "3                0.220866         0.390085             0.48549   \n",
       "4                0.220866         0.390085             0.48549   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_days  biiru_per_days  happousake_per_days  \\\n",
       "0                            0.4006        0.367773              0.61375   \n",
       "1                            0.4006        0.367773              0.61375   \n",
       "2                            0.4006        0.367773              0.61375   \n",
       "3                            0.4006        0.367773              0.61375   \n",
       "4                            0.4006        0.367773              0.61375   \n",
       "\n",
       "   sonohokachadorinku_per_days  chuuingamu_per_days  mizu_per_days  \\\n",
       "0                          1.0             0.386959       0.423009   \n",
       "1                          1.0             0.386959       0.423009   \n",
       "2                          1.0             0.386959       0.423009   \n",
       "3                          1.0             0.386959       0.423009   \n",
       "4                          1.0             0.386959       0.423009   \n",
       "\n",
       "   tansansui_per_days  sunakku_per_mstr  chokoreeto_per_mstr  \\\n",
       "0            0.344461          0.009488             0.008556   \n",
       "1            0.344461          0.009488             0.008556   \n",
       "2            0.344461          0.009488             0.008556   \n",
       "3            0.344461          0.009488             0.008556   \n",
       "4            0.344461          0.009488             0.008556   \n",
       "\n",
       "   koohiidorinku_per_mstr  shinjanru_per_mstr  \\\n",
       "0                0.004323            0.002058   \n",
       "1                0.004323            0.002058   \n",
       "2                0.004323            0.002058   \n",
       "3                0.004323            0.002058   \n",
       "4                0.004323            0.002058   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_mstr  mizu_per_mstr  happousake_per_mstr  \\\n",
       "0                          0.002409       0.000629             0.001461   \n",
       "1                          0.002409       0.000629             0.001461   \n",
       "2                          0.002409       0.000629             0.001461   \n",
       "3                          0.002409       0.000629             0.001461   \n",
       "4                          0.002409       0.000629             0.001461   \n",
       "\n",
       "   sonohokachadorinku_per_mstr  tansansui_per_mstr  \n",
       "0                     0.000657            0.000967  \n",
       "1                     0.000657            0.000967  \n",
       "2                     0.000657            0.000967  \n",
       "3                     0.000657            0.000967  \n",
       "4                     0.000657            0.000967  \n",
       "\n",
       "[5 rows x 381 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128376, 394)\n",
      "(96505, 381)\n"
     ]
    }
   ],
   "source": [
    "print(train_after.shape)\n",
    "print(test_after.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict ={'130123':'チョコレート',\n",
    " '130125':'チューインガム',\n",
    " '130129':'米菓',\n",
    "'130131':'スナック',\n",
    "'140307':'コーヒードリンク',\n",
    "'140313':'日本茶・麦茶ドリンク',\n",
    "'140316':'その他茶ドリンク',\n",
    "'140317':'水',\n",
    "'140321':'炭酸水',\n",
    "'140501':'新ジャンル',\n",
    "'140505':'RTD',\n",
    "'140641':'ビール',\n",
    "'140691':'発泡酒'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, target,categoricals=[], n_splits=5, verbose=True, group = \"months\"):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = target\n",
    "        self.X = self.train_df.drop(target,axis=1)\n",
    "        self.y = self.train_df[target]\n",
    "        self.group = group\n",
    "        self.groups = np.array(self.train_df[self.group].values)\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model,self.oof_pred = self.fit()\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        #cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "            labels_num = np.max(y) + 1\n",
    "            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "            y_distr = Counter()\n",
    "            for label, g in zip(y, groups):\n",
    "                y_counts_per_group[g][label] += 1\n",
    "                y_distr[label] += 1\n",
    "\n",
    "            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "            groups_per_fold = defaultdict(set)\n",
    "\n",
    "            # fold毎のaccuracy_groupの分布を計算する関数\n",
    "            def eval_y_counts_per_fold(y_counts, fold):\n",
    "                y_counts_per_fold[fold] += y_counts\n",
    "                std_per_label = []\n",
    "                for label in range(labels_num):\n",
    "                    label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "                    std_per_label.append(label_std)\n",
    "                y_counts_per_fold[fold] -= y_counts\n",
    "                return np.mean(std_per_label)\n",
    "\n",
    "            groups_and_y_counts = list(y_counts_per_group.items())\n",
    "            random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "\n",
    "                best_fold = None\n",
    "                min_eval = None\n",
    "                # kはfold数\n",
    "                for i in range(k):\n",
    "                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "\n",
    "                    if min_eval is None or fold_eval < min_eval:\n",
    "                        min_eval = fold_eval\n",
    "                        best_fold = i\n",
    "                y_counts_per_fold[best_fold] += y_counts\n",
    "                groups_per_fold[best_fold].add(g)\n",
    "\n",
    "            all_groups = set(groups)\n",
    "            for i in range(k):\n",
    "                train_groups = all_groups - groups_per_fold[i]\n",
    "                test_groups = groups_per_fold[i]\n",
    "\n",
    "                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "                yield train_indices, test_indices\n",
    "        \n",
    "        return stratified_group_k_fold(self.X, self.y, self.groups, k=5)\n",
    "        #return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(self.train_df), ))\n",
    "        y_pred = np.zeros((len(self.test_df), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            \n",
    "            #Check Stratified k-fold\n",
    "            print('Check Stratified k-fold')\n",
    "            print('y_train.value_counts(normalize=True)')\n",
    "            print(y_train.value_counts(normalize=True,sort=False))\n",
    "            print('y_val.value_counts(normalize=True)')\n",
    "            print(y_val.value_counts(normalize=True,sort=False))\n",
    "            check_tr = self.train_df.iloc[train_idx,:].copy()\n",
    "            check_vl = self.train_df.iloc[val_idx,:].copy()\n",
    "            print('')\n",
    "\n",
    "            #Check Group k-fold\n",
    "            print('Check Group k-fold')\n",
    "            check_dup_tr = list(check_tr[self.group].unique())\n",
    "            check_dup_vl = list(check_vl[self.group].unique())\n",
    "            check_dup_diff = set(check_dup_tr) - set(check_dup_vl)\n",
    "            print('len(check_dup_tr)')\n",
    "            print(len(check_dup_tr))\n",
    "            print('len(check_dup_diff)')\n",
    "            print(len(check_dup_diff))\n",
    "            print('Check SAME Number!')\n",
    "            print('')\n",
    "            \n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, roc_auc_score(y_val, oof_pred[val_idx])))\n",
    "            score = roc_auc_score(self.train_df[self.target], oof_pred)\n",
    "            \n",
    "            #特徴量重要度の計算\n",
    "            fold_importance = pd.DataFrame(list(zip(x_train.columns, model.feature_importance())),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            fold_importance.rename(columns={'importance': fold},inplace=True)\n",
    "            if fold == 0:\n",
    "                self.feature_importances = fold_importance\n",
    "            else:\n",
    "                self.feature_importances = pd.merge(self.feature_importances,fold_importance,on='feature')\n",
    "         \n",
    "        #特徴量重要度の計算\n",
    "        self.feature_importances.set_index(\"feature\",inplace=True)\n",
    "        self.feature_importances[\"mean\"] = self.feature_importances.mean(axis='columns')\n",
    "        self.feature_importances.sort_values(\"mean\",ascending=False,inplace=True)\n",
    "        #print(self.feature_importances)\n",
    "        #特徴量重要度の保存\n",
    "        self.feature_importances.to_csv(f'../model/FTI/{CASE}_{rename_dict[self.target]}_FTI.csv')\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('AUC score is: ', score)\n",
    "        return y_pred, score, model, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'binary',\n",
    "                    'metric': 'auc',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 7,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = [ \n",
    " '130123',\n",
    " '130125',\n",
    " '130129',\n",
    " '130131',\n",
    " '140307',\n",
    " '140313',\n",
    " '140316',\n",
    " '140317',\n",
    " '140321',\n",
    " '140501',\n",
    " '140505',\n",
    " '140641',\n",
    " '140691'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [\n",
    "    'purchase_id',\n",
    "    'years',\n",
    "    'p_date',\n",
    "    'mpno',\n",
    "    'purchase_id_mpno_mode',\n",
    "    'purchase_id_jan_name_mode',\n",
    "    'purchase_id_ccl_jan_mode',\n",
    "    'purchase_id_ccl_category_cd4_mode',\n",
    "    'purchase_id_ccl_category_cd3_mode',\n",
    "    'purchase_id_ccl_category_cd2_mode',\n",
    "    'purchase_id_ccl_category_cd1_mode'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_after.columns.tolist()\n",
    "\n",
    "for i in target_list:\n",
    "    features.remove(i)\n",
    "    \n",
    "for i in remove_list:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mstr',\n",
       " 'p_time',\n",
       " 'purchase_id_amount_sum',\n",
       " 'purchase_id_amount_max',\n",
       " 'purchase_id_amount_min',\n",
       " 'purchase_id_amount_mean',\n",
       " 'purchase_id_amount_std',\n",
       " 'purchase_id_amount_median',\n",
       " 'purchase_id_total_sum',\n",
       " 'purchase_id_total_max',\n",
       " 'purchase_id_total_min',\n",
       " 'purchase_id_total_mean',\n",
       " 'purchase_id_total_std',\n",
       " 'purchase_id_total_median',\n",
       " 'purchase_id_p_time_sum',\n",
       " 'purchase_id_p_time_max',\n",
       " 'purchase_id_p_time_min',\n",
       " 'purchase_id_p_time_mean',\n",
       " 'purchase_id_p_time_std',\n",
       " 'purchase_id_p_time_median',\n",
       " 'purchase_id_ccl_category_cd4_nunique',\n",
       " 'purchase_id_ccl_jan_nunique',\n",
       " 'purchase_id_jan_name_nunique',\n",
       " 'purchase_id_ccl_category_cd1_nunique',\n",
       " 'purchase_id_ccl_category_cd2_nunique',\n",
       " 'purchase_id_ccl_category_cd3_nunique',\n",
       " 'purchase_id_ccl_category_name1_mode',\n",
       " 'purchase_id_ccl_category_name1_nunique',\n",
       " 'purchase_id_ccl_category_name2_mode',\n",
       " 'purchase_id_ccl_category_name2_nunique',\n",
       " 'purchase_id_ccl_category_name3_mode',\n",
       " 'purchase_id_ccl_category_name3_nunique',\n",
       " 'purchase_id_ccl_category_name4_mode',\n",
       " 'purchase_id_ccl_category_name4_nunique',\n",
       " 'purchase_id_mpno_nunique',\n",
       " 'purchase_id_mstr_mode',\n",
       " 'purchase_id_mstr_nunique',\n",
       " 'months',\n",
       " 'days',\n",
       " 'weekdays',\n",
       " 'holiday_flg',\n",
       " 'satsun_flg',\n",
       " 'special_flg',\n",
       " 'End_Start_year_flg',\n",
       " 'GW_flg',\n",
       " 'Halloween_flg',\n",
       " 'Valentine_flg',\n",
       " 'Whiteday_flg',\n",
       " 'Christmas_flg',\n",
       " 'months_amount_sum',\n",
       " 'months_amount_max',\n",
       " 'months_amount_min',\n",
       " 'months_amount_mean',\n",
       " 'months_amount_std',\n",
       " 'months_amount_median',\n",
       " 'months_total_sum',\n",
       " 'months_total_max',\n",
       " 'months_total_min',\n",
       " 'months_total_mean',\n",
       " 'months_total_std',\n",
       " 'months_total_median',\n",
       " 'months_p_time_sum',\n",
       " 'months_p_time_max',\n",
       " 'months_p_time_min',\n",
       " 'months_p_time_mean',\n",
       " 'months_p_time_std',\n",
       " 'months_p_time_median',\n",
       " 'weekdays_amount_sum',\n",
       " 'weekdays_amount_max',\n",
       " 'weekdays_amount_min',\n",
       " 'weekdays_amount_mean',\n",
       " 'weekdays_amount_std',\n",
       " 'weekdays_amount_median',\n",
       " 'weekdays_total_sum',\n",
       " 'weekdays_total_max',\n",
       " 'weekdays_total_min',\n",
       " 'weekdays_total_mean',\n",
       " 'weekdays_total_std',\n",
       " 'weekdays_total_median',\n",
       " 'weekdays_p_time_sum',\n",
       " 'weekdays_p_time_max',\n",
       " 'weekdays_p_time_min',\n",
       " 'weekdays_p_time_mean',\n",
       " 'weekdays_p_time_std',\n",
       " 'weekdays_p_time_median',\n",
       " 'days_amount_sum',\n",
       " 'days_amount_max',\n",
       " 'days_amount_min',\n",
       " 'days_amount_mean',\n",
       " 'days_amount_std',\n",
       " 'days_amount_median',\n",
       " 'days_total_sum',\n",
       " 'days_total_max',\n",
       " 'days_total_min',\n",
       " 'days_total_mean',\n",
       " 'days_total_std',\n",
       " 'days_total_median',\n",
       " 'days_p_time_sum',\n",
       " 'days_p_time_max',\n",
       " 'days_p_time_min',\n",
       " 'days_p_time_mean',\n",
       " 'days_p_time_std',\n",
       " 'days_p_time_median',\n",
       " 'holiday_flg_amount_sum',\n",
       " 'holiday_flg_amount_max',\n",
       " 'holiday_flg_amount_min',\n",
       " 'holiday_flg_amount_mean',\n",
       " 'holiday_flg_amount_std',\n",
       " 'holiday_flg_amount_median',\n",
       " 'holiday_flg_total_sum',\n",
       " 'holiday_flg_total_max',\n",
       " 'holiday_flg_total_min',\n",
       " 'holiday_flg_total_mean',\n",
       " 'holiday_flg_total_std',\n",
       " 'holiday_flg_total_median',\n",
       " 'holiday_flg_p_time_sum',\n",
       " 'holiday_flg_p_time_max',\n",
       " 'holiday_flg_p_time_min',\n",
       " 'holiday_flg_p_time_mean',\n",
       " 'holiday_flg_p_time_std',\n",
       " 'holiday_flg_p_time_median',\n",
       " 'mstr_amount_sum',\n",
       " 'mstr_amount_max',\n",
       " 'mstr_amount_min',\n",
       " 'mstr_amount_mean',\n",
       " 'mstr_amount_std',\n",
       " 'mstr_amount_median',\n",
       " 'mstr_total_sum',\n",
       " 'mstr_total_max',\n",
       " 'mstr_total_min',\n",
       " 'mstr_total_mean',\n",
       " 'mstr_total_std',\n",
       " 'mstr_total_median',\n",
       " 'mstr_p_time_sum',\n",
       " 'mstr_p_time_max',\n",
       " 'mstr_p_time_min',\n",
       " 'mstr_p_time_mean',\n",
       " 'mstr_p_time_std',\n",
       " 'mstr_p_time_median',\n",
       " 'mstr_ccl_category_cd4_mode',\n",
       " 'mstr_ccl_category_cd4_nunique',\n",
       " 'mstr_ccl_jan_mode',\n",
       " 'mstr_ccl_jan_nunique',\n",
       " 'mstr_jan_name_mode',\n",
       " 'mstr_jan_name_nunique',\n",
       " 'mstr_ccl_category_cd1_mode',\n",
       " 'mstr_ccl_category_cd1_nunique',\n",
       " 'mstr_ccl_category_cd2_mode',\n",
       " 'mstr_ccl_category_cd2_nunique',\n",
       " 'mstr_ccl_category_cd3_mode',\n",
       " 'mstr_ccl_category_cd3_nunique',\n",
       " 'mstr_ccl_category_name1_mode',\n",
       " 'mstr_ccl_category_name1_nunique',\n",
       " 'mstr_ccl_category_name2_mode',\n",
       " 'mstr_ccl_category_name2_nunique',\n",
       " 'mstr_ccl_category_name3_mode',\n",
       " 'mstr_ccl_category_name3_nunique',\n",
       " 'mstr_ccl_category_name4_mode',\n",
       " 'mstr_ccl_category_name4_nunique',\n",
       " 'ccl_category_name1_souzai_div',\n",
       " 'ccl_category_name1_seisen_div',\n",
       " 'ccl_category_name1_shokuhin_div',\n",
       " 'ccl_category_name2_kakoushokuhin_div',\n",
       " 'ccl_category_name2_hanchourihin_div',\n",
       " 'ccl_category_name2_tamago_div',\n",
       " 'ccl_category_name2_bentou_div',\n",
       " 'ccl_category_name2_kajitsu_div',\n",
       " 'ccl_category_name2_seiniku_div',\n",
       " 'ccl_category_name2_kashirui_div',\n",
       " 'ccl_category_name2_chourizumi_div',\n",
       " 'ccl_category_name2_yasai_div',\n",
       " 'ccl_category_name2_inryou.sakerui_div',\n",
       " 'ccl_category_name2_sengyo_div',\n",
       " 'ccl_category_name3_kinokorui_div',\n",
       " 'ccl_category_name3_sonohoka_div',\n",
       " 'ccl_category_name3_sonohokanokudamono_div',\n",
       " 'ccl_category_name3_sonohokasouzai_div',\n",
       " 'ccl_category_name3_sonohokaseinikurui_div',\n",
       " 'ccl_category_name3_aisukuriimurui_div',\n",
       " 'ccl_category_name3_arukooruinryou_div',\n",
       " 'ccl_category_name3_kattoyasai_div',\n",
       " 'ccl_category_name3_supureddorui_div',\n",
       " 'ccl_category_name3_suupu_div',\n",
       " 'ccl_category_name3_dezaato.yooguruto_div',\n",
       " 'ccl_category_name3_pan_div',\n",
       " 'ccl_category_name3_hoomumeekinguzairyou_div',\n",
       " 'ccl_category_name3_chuukasouzai_div',\n",
       " 'ccl_category_name3_marumono_div',\n",
       " 'ccl_category_name3_nyuuseihin_div',\n",
       " 'ccl_category_name3_chichiinryou_div',\n",
       " 'ccl_category_name3_hitoshikarui_div',\n",
       " 'ccl_category_name3_satsurui_div',\n",
       " 'ccl_category_name3_reitoushokuhin_div',\n",
       " 'ccl_category_name3_kirimi_div',\n",
       " 'ccl_category_name3_sashimi_div',\n",
       " 'ccl_category_name3_kakousuisan_div',\n",
       " 'ccl_category_name3_kakounikurui_div',\n",
       " 'ccl_category_name3_wafuusouzai_div',\n",
       " 'ccl_category_name3_shikouinryou_div',\n",
       " 'ccl_category_name3_tsuchimonorui_div',\n",
       " 'ccl_category_name3_sushi_div',\n",
       " 'ccl_category_name3_souzairui_div',\n",
       " 'ccl_category_name3_youmono_div',\n",
       " 'ccl_category_name3_kajitsutekiyasai_div',\n",
       " 'ccl_category_name3_kajitsuinryou_div',\n",
       " 'ccl_category_name3_kanarui_div',\n",
       " 'ccl_category_name3_kankitsurui_div',\n",
       " 'ccl_category_name3_kakukarui_div',\n",
       " 'ccl_category_name3_konsairui_div',\n",
       " 'ccl_category_name3_mizumono_div',\n",
       " 'ccl_category_name3_youfuusouzai_div',\n",
       " 'ccl_category_name3_seiryouinryou_div',\n",
       " 'ccl_category_name3_tsukemono.tsukudani_div',\n",
       " 'ccl_category_name3_yakimono_div',\n",
       " 'ccl_category_name3_gyuuniku_div',\n",
       " 'ccl_category_name3_chinmi_div',\n",
       " 'ccl_category_name3_seisensonohokakakousuisan_div',\n",
       " 'ccl_category_name3_kokumotsu_div',\n",
       " 'ccl_category_name3_beihan_div',\n",
       " 'ccl_category_name3_neriseihin_div',\n",
       " 'ccl_category_name3_kanzume_div',\n",
       " 'ccl_category_name3_kashi_div',\n",
       " 'ccl_category_name3_hakukinarui_div',\n",
       " 'ccl_category_name3_choumiryou_div',\n",
       " 'ccl_category_name3_chourihin_div',\n",
       " 'ccl_category_name3_mamerui_div',\n",
       " 'ccl_category_name3_butaniku_div',\n",
       " 'ccl_category_name3_kai_div',\n",
       " 'ccl_category_name3_nousankanbutsu_div',\n",
       " 'ccl_category_name3_shokuyouabura_div',\n",
       " 'ccl_category_name3_kaorishinyasai_div',\n",
       " 'ccl_category_name3_keiran_div',\n",
       " 'ccl_category_name3_toriniku_div',\n",
       " 'ccl_category_name3_menrui_div',\n",
       " 'ccl_category_name3_tataki_div',\n",
       " 'ccl_category_name3_pan.shiriarurui_div',\n",
       " 'ccl_category_name3_nimono_div',\n",
       " 'ccl_category_name3_sonohokanoyasairui_div',\n",
       " 'ccl_category_name3_kattofuruutsu_div',\n",
       " 'ccl_category_name3_konarui_div',\n",
       " 'ccl_category_name3_sengyosonohoka_div',\n",
       " 'ccl_category_name3_sunakku_div',\n",
       " 'ccl_category_name3_men.pasuta_div',\n",
       " 'ccl_category_name3_bentousonohoka_div',\n",
       " 'ccl_category_name3_sonohokakakoushokuhin_div',\n",
       " 'ccl_category_name3_sakeruiwofukumusettoshouhin_div',\n",
       " 'ccl_category_name1_souzai_ammount_div',\n",
       " 'ccl_category_name1_seisen_ammount_div',\n",
       " 'ccl_category_name1_shokuhin_ammount_div',\n",
       " 'ccl_category_name2_kakoushokuhin_ammount_div',\n",
       " 'ccl_category_name2_hanchourihin_ammount_div',\n",
       " 'ccl_category_name2_tamago_ammount_div',\n",
       " 'ccl_category_name2_bentou_ammount_div',\n",
       " 'ccl_category_name2_kajitsu_ammount_div',\n",
       " 'ccl_category_name2_seiniku_ammount_div',\n",
       " 'ccl_category_name2_kashirui_ammount_div',\n",
       " 'ccl_category_name2_chourizumi_ammount_div',\n",
       " 'ccl_category_name2_yasai_ammount_div',\n",
       " 'ccl_category_name2_inryou.sakerui_ammount_div',\n",
       " 'ccl_category_name2_sengyo_ammount_div',\n",
       " 'ccl_category_name3_kinokorui_ammount_div',\n",
       " 'ccl_category_name3_sonohoka_ammount_div',\n",
       " 'ccl_category_name3_sonohokanokudamono_ammount_div',\n",
       " 'ccl_category_name3_sonohokasouzai_ammount_div',\n",
       " 'ccl_category_name3_sonohokaseinikurui_ammount_div',\n",
       " 'ccl_category_name3_aisukuriimurui_ammount_div',\n",
       " 'ccl_category_name3_arukooruinryou_ammount_div',\n",
       " 'ccl_category_name3_kattoyasai_ammount_div',\n",
       " 'ccl_category_name3_supureddorui_ammount_div',\n",
       " 'ccl_category_name3_suupu_ammount_div',\n",
       " 'ccl_category_name3_dezaato.yooguruto_ammount_div',\n",
       " 'ccl_category_name3_pan_ammount_div',\n",
       " 'ccl_category_name3_hoomumeekinguzairyou_ammount_div',\n",
       " 'ccl_category_name3_chuukasouzai_ammount_div',\n",
       " 'ccl_category_name3_marumono_ammount_div',\n",
       " 'ccl_category_name3_nyuuseihin_ammount_div',\n",
       " 'ccl_category_name3_chichiinryou_ammount_div',\n",
       " 'ccl_category_name3_hitoshikarui_ammount_div',\n",
       " 'ccl_category_name3_satsurui_ammount_div',\n",
       " 'ccl_category_name3_reitoushokuhin_ammount_div',\n",
       " 'ccl_category_name3_kirimi_ammount_div',\n",
       " 'ccl_category_name3_sashimi_ammount_div',\n",
       " 'ccl_category_name3_kakousuisan_ammount_div',\n",
       " 'ccl_category_name3_kakounikurui_ammount_div',\n",
       " 'ccl_category_name3_wafuusouzai_ammount_div',\n",
       " 'ccl_category_name3_shikouinryou_ammount_div',\n",
       " 'ccl_category_name3_tsuchimonorui_ammount_div',\n",
       " 'ccl_category_name3_sushi_ammount_div',\n",
       " 'ccl_category_name3_souzairui_ammount_div',\n",
       " 'ccl_category_name3_youmono_ammount_div',\n",
       " 'ccl_category_name3_kajitsutekiyasai_ammount_div',\n",
       " 'ccl_category_name3_kajitsuinryou_ammount_div',\n",
       " 'ccl_category_name3_kanarui_ammount_div',\n",
       " 'ccl_category_name3_kankitsurui_ammount_div',\n",
       " 'ccl_category_name3_kakukarui_ammount_div',\n",
       " 'ccl_category_name3_konsairui_ammount_div',\n",
       " 'ccl_category_name3_mizumono_ammount_div',\n",
       " 'ccl_category_name3_youfuusouzai_ammount_div',\n",
       " 'ccl_category_name3_seiryouinryou_ammount_div',\n",
       " 'ccl_category_name3_tsukemono.tsukudani_ammount_div',\n",
       " 'ccl_category_name3_yakimono_ammount_div',\n",
       " 'ccl_category_name3_gyuuniku_ammount_div',\n",
       " 'ccl_category_name3_chinmi_ammount_div',\n",
       " 'ccl_category_name3_seisensonohokakakousuisan_ammount_div',\n",
       " 'ccl_category_name3_kokumotsu_ammount_div',\n",
       " 'ccl_category_name3_beihan_ammount_div',\n",
       " 'ccl_category_name3_neriseihin_ammount_div',\n",
       " 'ccl_category_name3_kanzume_ammount_div',\n",
       " 'ccl_category_name3_kashi_ammount_div',\n",
       " 'ccl_category_name3_hakukinarui_ammount_div',\n",
       " 'ccl_category_name3_choumiryou_ammount_div',\n",
       " 'ccl_category_name3_chourihin_ammount_div',\n",
       " 'ccl_category_name3_mamerui_ammount_div',\n",
       " 'ccl_category_name3_butaniku_ammount_div',\n",
       " 'ccl_category_name3_kai_ammount_div',\n",
       " 'ccl_category_name3_nousankanbutsu_ammount_div',\n",
       " 'ccl_category_name3_shokuyouabura_ammount_div',\n",
       " 'ccl_category_name3_kaorishinyasai_ammount_div',\n",
       " 'ccl_category_name3_keiran_ammount_div',\n",
       " 'ccl_category_name3_toriniku_ammount_div',\n",
       " 'ccl_category_name3_menrui_ammount_div',\n",
       " 'ccl_category_name3_tataki_ammount_div',\n",
       " 'ccl_category_name3_pan.shiriarurui_ammount_div',\n",
       " 'ccl_category_name3_nimono_ammount_div',\n",
       " 'ccl_category_name3_sonohokanoyasairui_ammount_div',\n",
       " 'ccl_category_name3_kattofuruutsu_ammount_div',\n",
       " 'ccl_category_name3_konarui_ammount_div',\n",
       " 'ccl_category_name3_sengyosonohoka_ammount_div',\n",
       " 'ccl_category_name3_sunakku_ammount_div',\n",
       " 'ccl_category_name3_men.pasuta_ammount_div',\n",
       " 'ccl_category_name3_bentousonohoka_ammount_div',\n",
       " 'ccl_category_name3_sonohokakakoushokuhin_ammount_div',\n",
       " 'ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div',\n",
       " 'months_per_months',\n",
       " 'sunakku_per_months',\n",
       " 'chokoreeto_per_months',\n",
       " 'RTD_per_months',\n",
       " 'koohiidorinku_per_months',\n",
       " 'komeka_per_months',\n",
       " 'shinjanru_per_months',\n",
       " 'nihoncha.mugichadorinku_per_months',\n",
       " 'biiru_per_months',\n",
       " 'happousake_per_months',\n",
       " 'chuuingamu_per_months',\n",
       " 'mizu_per_months',\n",
       " 'sonohokachadorinku_per_months',\n",
       " 'tansansui_per_months',\n",
       " 'days_per_days',\n",
       " 'sunakku_per_days',\n",
       " 'chokoreeto_per_days',\n",
       " 'RTD_per_days',\n",
       " 'koohiidorinku_per_days',\n",
       " 'komeka_per_days',\n",
       " 'shinjanru_per_days',\n",
       " 'nihoncha.mugichadorinku_per_days',\n",
       " 'biiru_per_days',\n",
       " 'happousake_per_days',\n",
       " 'sonohokachadorinku_per_days',\n",
       " 'chuuingamu_per_days',\n",
       " 'mizu_per_days',\n",
       " 'tansansui_per_days',\n",
       " 'sunakku_per_mstr',\n",
       " 'chokoreeto_per_mstr',\n",
       " 'koohiidorinku_per_mstr',\n",
       " 'shinjanru_per_mstr',\n",
       " 'nihoncha.mugichadorinku_per_mstr',\n",
       " 'mizu_per_mstr',\n",
       " 'happousake_per_mstr',\n",
       " 'sonohokachadorinku_per_mstr',\n",
       " 'tansansui_per_mstr']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Enc\n",
    "def LabelEnc(train,test):\n",
    "    train_after = train.copy()\n",
    "    test_after = test.copy()\n",
    "    \n",
    "    train[\"type\"] = \"train\"\n",
    "    test[\"type\"] = \"test\"\n",
    "    \n",
    "    # データを全結合\n",
    "    all_tmp = pd.concat([train,test],sort=False)\n",
    "    \n",
    "    # Labelencを行うリストを取得\n",
    "    obj_lost = all_tmp.select_dtypes(\"O\").columns.tolist()\n",
    "    obj_lost.remove(\"type\")\n",
    "    \n",
    "    ### LabelEncを実施\n",
    "    import category_encoders as ce\n",
    "    #ce_oe = ce.OrdinalEncoder(cols=obj_lost,handle_unknown='impute')\n",
    "    ce_oe = ce.OrdinalEncoder(cols=obj_lost)\n",
    "    all_tmp_2 = ce_oe.fit_transform(all_tmp)\n",
    "    all_tmp_2_train = all_tmp_2[all_tmp_2[\"type\"] == \"train\"]\n",
    "    all_tmp_2_test = all_tmp_2[all_tmp_2[\"type\"] == \"test\"]\n",
    "    #文字を序数に変換\n",
    "    for i in obj_lost:\n",
    "        train_after[i] = all_tmp_2_train[i] - 1\n",
    "        test_after[i] = all_tmp_2_test[i] - 1\n",
    "    \n",
    "    return train_after,test_after\n",
    "\n",
    "train_after,test_after = LabelEnc(train_after,test_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>mpno</th>\n",
       "      <th>mstr</th>\n",
       "      <th>p_date</th>\n",
       "      <th>p_time</th>\n",
       "      <th>purchase_id_amount_sum</th>\n",
       "      <th>purchase_id_amount_max</th>\n",
       "      <th>purchase_id_amount_min</th>\n",
       "      <th>purchase_id_amount_mean</th>\n",
       "      <th>purchase_id_amount_std</th>\n",
       "      <th>purchase_id_amount_median</th>\n",
       "      <th>purchase_id_total_sum</th>\n",
       "      <th>purchase_id_total_max</th>\n",
       "      <th>purchase_id_total_min</th>\n",
       "      <th>purchase_id_total_mean</th>\n",
       "      <th>purchase_id_total_std</th>\n",
       "      <th>purchase_id_total_median</th>\n",
       "      <th>purchase_id_p_time_sum</th>\n",
       "      <th>purchase_id_p_time_max</th>\n",
       "      <th>purchase_id_p_time_min</th>\n",
       "      <th>purchase_id_p_time_mean</th>\n",
       "      <th>purchase_id_p_time_std</th>\n",
       "      <th>purchase_id_p_time_median</th>\n",
       "      <th>purchase_id_ccl_category_cd4_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd4_nunique</th>\n",
       "      <th>purchase_id_ccl_jan_mode</th>\n",
       "      <th>purchase_id_ccl_jan_nunique</th>\n",
       "      <th>purchase_id_jan_name_mode</th>\n",
       "      <th>purchase_id_jan_name_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd1_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd1_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd2_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd2_nunique</th>\n",
       "      <th>purchase_id_ccl_category_cd3_mode</th>\n",
       "      <th>purchase_id_ccl_category_cd3_nunique</th>\n",
       "      <th>purchase_id_ccl_category_name1_mode</th>\n",
       "      <th>purchase_id_ccl_category_name1_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>ccl_category_name3_menrui_ammount_div</th>\n",
       "      <th>ccl_category_name3_tataki_ammount_div</th>\n",
       "      <th>ccl_category_name3_pan.shiriarurui_ammount_div</th>\n",
       "      <th>ccl_category_name3_nimono_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokanoyasairui_ammount_div</th>\n",
       "      <th>ccl_category_name3_kattofuruutsu_ammount_div</th>\n",
       "      <th>ccl_category_name3_konarui_ammount_div</th>\n",
       "      <th>ccl_category_name3_sengyosonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sunakku_ammount_div</th>\n",
       "      <th>ccl_category_name3_men.pasuta_ammount_div</th>\n",
       "      <th>ccl_category_name3_bentousonohoka_ammount_div</th>\n",
       "      <th>ccl_category_name3_sonohokakakoushokuhin_ammount_div</th>\n",
       "      <th>ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div</th>\n",
       "      <th>months_per_months</th>\n",
       "      <th>sunakku_per_months</th>\n",
       "      <th>chokoreeto_per_months</th>\n",
       "      <th>RTD_per_months</th>\n",
       "      <th>koohiidorinku_per_months</th>\n",
       "      <th>komeka_per_months</th>\n",
       "      <th>shinjanru_per_months</th>\n",
       "      <th>nihoncha.mugichadorinku_per_months</th>\n",
       "      <th>biiru_per_months</th>\n",
       "      <th>happousake_per_months</th>\n",
       "      <th>chuuingamu_per_months</th>\n",
       "      <th>mizu_per_months</th>\n",
       "      <th>sonohokachadorinku_per_months</th>\n",
       "      <th>tansansui_per_months</th>\n",
       "      <th>days_per_days</th>\n",
       "      <th>sunakku_per_days</th>\n",
       "      <th>chokoreeto_per_days</th>\n",
       "      <th>RTD_per_days</th>\n",
       "      <th>koohiidorinku_per_days</th>\n",
       "      <th>komeka_per_days</th>\n",
       "      <th>shinjanru_per_days</th>\n",
       "      <th>nihoncha.mugichadorinku_per_days</th>\n",
       "      <th>biiru_per_days</th>\n",
       "      <th>happousake_per_days</th>\n",
       "      <th>sonohokachadorinku_per_days</th>\n",
       "      <th>chuuingamu_per_days</th>\n",
       "      <th>mizu_per_days</th>\n",
       "      <th>tansansui_per_days</th>\n",
       "      <th>sunakku_per_mstr</th>\n",
       "      <th>chokoreeto_per_mstr</th>\n",
       "      <th>koohiidorinku_per_mstr</th>\n",
       "      <th>shinjanru_per_mstr</th>\n",
       "      <th>nihoncha.mugichadorinku_per_mstr</th>\n",
       "      <th>mizu_per_mstr</th>\n",
       "      <th>happousake_per_mstr</th>\n",
       "      <th>sonohokachadorinku_per_mstr</th>\n",
       "      <th>tansansui_per_mstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>4671.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>359.307692</td>\n",
       "      <td>491.775929</td>\n",
       "      <td>198.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>110131.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>610104.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>305.800000</td>\n",
       "      <td>113.247811</td>\n",
       "      <td>305.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110121.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>630201.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>720100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>23</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>223.555556</td>\n",
       "      <td>106.693616</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>130401.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>610107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>17</td>\n",
       "      <td>5330.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>280.526316</td>\n",
       "      <td>341.616967</td>\n",
       "      <td>158.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.501460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>110507.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>610102.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>610100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>14</td>\n",
       "      <td>3388.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>423.500000</td>\n",
       "      <td>487.433219</td>\n",
       "      <td>199.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>130137.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>730497.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638197</td>\n",
       "      <td>0.556225</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.43026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125129</td>\n",
       "      <td>0.01858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.569746</td>\n",
       "      <td>0.309674</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.895045</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>0.105463</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.00072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_id  130123  130125  130129  130131  140307  140313  140316  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            1       0       0       0       0       0       0       0   \n",
       "2            2       0       0       1       0       0       0       0   \n",
       "3            3       0       0       0       1       0       0       0   \n",
       "4            4       1       0       0       1       1       0       0   \n",
       "\n",
       "   140317  140321  140501  140505  140641  140691  mpno  mstr     p_date  \\\n",
       "0       0       0       0       0       0       0     0     0 2017-01-02   \n",
       "1       0       0       0       0       0       0     1     0 2017-01-02   \n",
       "2       0       0       0       0       0       0     2     0 2017-01-02   \n",
       "3       0       0       0       0       1       0     3     0 2017-01-02   \n",
       "4       0       0       0       0       0       0     4     0 2017-01-02   \n",
       "\n",
       "   p_time  purchase_id_amount_sum  purchase_id_amount_max  \\\n",
       "0      14                  4671.0                  1980.0   \n",
       "1      11                  3058.0                   470.0   \n",
       "2      23                  2012.0                   478.0   \n",
       "3      17                  5330.0                  1580.0   \n",
       "4      14                  3388.0                  1580.0   \n",
       "\n",
       "   purchase_id_amount_min  purchase_id_amount_mean  purchase_id_amount_std  \\\n",
       "0                   108.0               359.307692              491.775929   \n",
       "1                   134.0               305.800000              113.247811   \n",
       "2                    96.0               223.555556              106.693616   \n",
       "3                    84.0               280.526316              341.616967   \n",
       "4                   138.0               423.500000              487.433219   \n",
       "\n",
       "   purchase_id_amount_median  purchase_id_total_sum  purchase_id_total_max  \\\n",
       "0                      198.0                   15.0                    2.0   \n",
       "1                      305.5                   14.0                    2.0   \n",
       "2                      198.0                    9.0                    1.0   \n",
       "3                      158.0                   22.0                    3.0   \n",
       "4                      199.0                   13.0                    4.0   \n",
       "\n",
       "   purchase_id_total_min  purchase_id_total_mean  purchase_id_total_std  \\\n",
       "0                    1.0                1.153846               0.375534   \n",
       "1                    1.0                1.400000               0.516398   \n",
       "2                    1.0                1.000000               0.000000   \n",
       "3                    1.0                1.157895               0.501460   \n",
       "4                    1.0                1.625000               1.060660   \n",
       "\n",
       "   purchase_id_total_median  purchase_id_p_time_sum  purchase_id_p_time_max  \\\n",
       "0                       1.0                   182.0                    14.0   \n",
       "1                       1.0                   110.0                    11.0   \n",
       "2                       1.0                   207.0                    23.0   \n",
       "3                       1.0                   323.0                    17.0   \n",
       "4                       1.0                   112.0                    14.0   \n",
       "\n",
       "   purchase_id_p_time_min  purchase_id_p_time_mean  purchase_id_p_time_std  \\\n",
       "0                    14.0                     14.0                     0.0   \n",
       "1                    11.0                     11.0                     0.0   \n",
       "2                    23.0                     23.0                     0.0   \n",
       "3                    17.0                     17.0                     0.0   \n",
       "4                    14.0                     14.0                     0.0   \n",
       "\n",
       "   purchase_id_p_time_median  purchase_id_ccl_category_cd4_mode  \\\n",
       "0                       14.0                           110131.0   \n",
       "1                       11.0                           110121.0   \n",
       "2                       23.0                           130401.0   \n",
       "3                       17.0                           110507.0   \n",
       "4                       14.0                           130137.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd4_nunique  purchase_id_ccl_jan_mode  \\\n",
       "0                                  13.0                  610104.0   \n",
       "1                                  10.0                  630201.0   \n",
       "2                                   7.0                  610107.0   \n",
       "3                                  18.0                  610102.0   \n",
       "4                                   7.0                  730497.0   \n",
       "\n",
       "   purchase_id_ccl_jan_nunique  purchase_id_jan_name_mode  \\\n",
       "0                         13.0                          0   \n",
       "1                         10.0                          1   \n",
       "2                          9.0                          0   \n",
       "3                         19.0                          2   \n",
       "4                          8.0                          3   \n",
       "\n",
       "   purchase_id_jan_name_nunique  purchase_id_ccl_category_cd1_mode  \\\n",
       "0                          13.0                           600000.0   \n",
       "1                          10.0                           700000.0   \n",
       "2                           9.0                           100000.0   \n",
       "3                          19.0                           100000.0   \n",
       "4                           8.0                           100000.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd1_nunique  purchase_id_ccl_category_cd2_mode  \\\n",
       "0                                   2.0                           610000.0   \n",
       "1                                   3.0                           720000.0   \n",
       "2                                   3.0                           130000.0   \n",
       "3                                   3.0                           110000.0   \n",
       "4                                   2.0                           130000.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd2_nunique  purchase_id_ccl_category_cd3_mode  \\\n",
       "0                                   6.0                           610100.0   \n",
       "1                                   4.0                           720100.0   \n",
       "2                                   6.0                           130400.0   \n",
       "3                                   8.0                           610100.0   \n",
       "4                                   3.0                           130100.0   \n",
       "\n",
       "   purchase_id_ccl_category_cd3_nunique  purchase_id_ccl_category_name1_mode  \\\n",
       "0                                  11.0                                    0   \n",
       "1                                   9.0                                    1   \n",
       "2                                   7.0                                    0   \n",
       "3                                  15.0                                    2   \n",
       "4                                   6.0                                    2   \n",
       "\n",
       "   purchase_id_ccl_category_name1_nunique         ...          \\\n",
       "0                                     2.0         ...           \n",
       "1                                     3.0         ...           \n",
       "2                                     3.0         ...           \n",
       "3                                     3.0         ...           \n",
       "4                                     2.0         ...           \n",
       "\n",
       "   ccl_category_name3_menrui_ammount_div  \\\n",
       "0                               0.024029   \n",
       "1                               0.036537   \n",
       "2                               0.008176   \n",
       "3                               0.010804   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_tataki_ammount_div  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.003151   \n",
       "4                               0.000000   \n",
       "\n",
       "   ccl_category_name3_pan.shiriarurui_ammount_div  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   ccl_category_name3_nimono_ammount_div  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokanoyasairui_ammount_div  \\\n",
       "0                                           0.007678   \n",
       "1                                           0.000756   \n",
       "2                                           0.000000   \n",
       "3                                           0.000000   \n",
       "4                                           0.000000   \n",
       "\n",
       "   ccl_category_name3_kattofuruutsu_ammount_div  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.001359   \n",
       "2                                      0.000000   \n",
       "3                                      0.001619   \n",
       "4                                      0.000000   \n",
       "\n",
       "   ccl_category_name3_konarui_ammount_div  \\\n",
       "0                                0.008242   \n",
       "1                                0.002821   \n",
       "2                                0.000000   \n",
       "3                                0.001184   \n",
       "4                                0.000000   \n",
       "\n",
       "   ccl_category_name3_sengyosonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sunakku_ammount_div  \\\n",
       "0                                0.000000   \n",
       "1                                0.013893   \n",
       "2                                0.000000   \n",
       "3                                0.000000   \n",
       "4                                0.000000   \n",
       "\n",
       "   ccl_category_name3_men.pasuta_ammount_div  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.007337   \n",
       "2                                   0.000000   \n",
       "3                                   0.002575   \n",
       "4                                   0.000000   \n",
       "\n",
       "   ccl_category_name3_bentousonohoka_ammount_div  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   ccl_category_name3_sonohokakakoushokuhin_ammount_div  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   ccl_category_name3_sakeruiwofukumusettoshouhin_ammount_div  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   months_per_months  sunakku_per_months  chokoreeto_per_months  \\\n",
       "0                  1            0.638197               0.556225   \n",
       "1                  1            0.638197               0.556225   \n",
       "2                  1            0.638197               0.556225   \n",
       "3                  1            0.638197               0.556225   \n",
       "4                  1            0.638197               0.556225   \n",
       "\n",
       "   RTD_per_months  koohiidorinku_per_months  komeka_per_months  \\\n",
       "0         0.09933                  0.031246            0.43026   \n",
       "1         0.09933                  0.031246            0.43026   \n",
       "2         0.09933                  0.031246            0.43026   \n",
       "3         0.09933                  0.031246            0.43026   \n",
       "4         0.09933                  0.031246            0.43026   \n",
       "\n",
       "   shinjanru_per_months  nihoncha.mugichadorinku_per_months  biiru_per_months  \\\n",
       "0                   0.0                            0.041853               0.0   \n",
       "1                   0.0                            0.041853               0.0   \n",
       "2                   0.0                            0.041853               0.0   \n",
       "3                   0.0                            0.041853               0.0   \n",
       "4                   0.0                            0.041853               0.0   \n",
       "\n",
       "   happousake_per_months  chuuingamu_per_months  mizu_per_months  \\\n",
       "0                    0.0               0.125129          0.01858   \n",
       "1                    0.0               0.125129          0.01858   \n",
       "2                    0.0               0.125129          0.01858   \n",
       "3                    0.0               0.125129          0.01858   \n",
       "4                    0.0               0.125129          0.01858   \n",
       "\n",
       "   sonohokachadorinku_per_months  tansansui_per_months  days_per_days  \\\n",
       "0                            0.0              0.078538              2   \n",
       "1                            0.0              0.078538              2   \n",
       "2                            0.0              0.078538              2   \n",
       "3                            0.0              0.078538              2   \n",
       "4                            0.0              0.078538              2   \n",
       "\n",
       "   sunakku_per_days  chokoreeto_per_days  RTD_per_days  \\\n",
       "0               0.0             0.306292      0.569746   \n",
       "1               0.0             0.306292      0.569746   \n",
       "2               0.0             0.306292      0.569746   \n",
       "3               0.0             0.306292      0.569746   \n",
       "4               0.0             0.306292      0.569746   \n",
       "\n",
       "   koohiidorinku_per_days  komeka_per_days  shinjanru_per_days  \\\n",
       "0                0.309674         0.312486                 1.0   \n",
       "1                0.309674         0.312486                 1.0   \n",
       "2                0.309674         0.312486                 1.0   \n",
       "3                0.309674         0.312486                 1.0   \n",
       "4                0.309674         0.312486                 1.0   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_days  biiru_per_days  happousake_per_days  \\\n",
       "0                          0.641796             1.0             0.799642   \n",
       "1                          0.641796             1.0             0.799642   \n",
       "2                          0.641796             1.0             0.799642   \n",
       "3                          0.641796             1.0             0.799642   \n",
       "4                          0.641796             1.0             0.799642   \n",
       "\n",
       "   sonohokachadorinku_per_days  chuuingamu_per_days  mizu_per_days  \\\n",
       "0                     0.895045             0.093191       0.765309   \n",
       "1                     0.895045             0.093191       0.765309   \n",
       "2                     0.895045             0.093191       0.765309   \n",
       "3                     0.895045             0.093191       0.765309   \n",
       "4                     0.895045             0.093191       0.765309   \n",
       "\n",
       "   tansansui_per_days  sunakku_per_mstr  chokoreeto_per_mstr  \\\n",
       "0            0.105463          0.013318             0.008498   \n",
       "1            0.105463          0.013318             0.008498   \n",
       "2            0.105463          0.013318             0.008498   \n",
       "3            0.105463          0.013318             0.008498   \n",
       "4            0.105463          0.013318             0.008498   \n",
       "\n",
       "   koohiidorinku_per_mstr  shinjanru_per_mstr  \\\n",
       "0                0.005858            0.003332   \n",
       "1                0.005858            0.003332   \n",
       "2                0.005858            0.003332   \n",
       "3                0.005858            0.003332   \n",
       "4                0.005858            0.003332   \n",
       "\n",
       "   nihoncha.mugichadorinku_per_mstr  mizu_per_mstr  happousake_per_mstr  \\\n",
       "0                          0.002102       0.001044             0.001785   \n",
       "1                          0.002102       0.001044             0.001785   \n",
       "2                          0.002102       0.001044             0.001785   \n",
       "3                          0.002102       0.001044             0.001785   \n",
       "4                          0.002102       0.001044             0.001785   \n",
       "\n",
       "   sonohokachadorinku_per_mstr  tansansui_per_mstr  \n",
       "0                     0.000948             0.00072  \n",
       "1                     0.000948             0.00072  \n",
       "2                     0.000948             0.00072  \n",
       "3                     0.000948             0.00072  \n",
       "4                     0.000948             0.00072  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### 1 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.873793\n",
      "1    0.126207\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.866931\n",
      "1    0.133069\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.781338\tvalid_1's auc: 0.717179\n",
      "[200]\ttraining's auc: 0.824769\tvalid_1's auc: 0.728727\n",
      "[300]\ttraining's auc: 0.856782\tvalid_1's auc: 0.731077\n",
      "[400]\ttraining's auc: 0.880743\tvalid_1's auc: 0.732621\n",
      "[500]\ttraining's auc: 0.900958\tvalid_1's auc: 0.733095\n",
      "[600]\ttraining's auc: 0.917203\tvalid_1's auc: 0.733111\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's auc: 0.909659\tvalid_1's auc: 0.733463\n",
      "Partial score of fold 0 is: 0.7334633020578308\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.875437\n",
      "1    0.124563\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.860169\n",
      "1    0.139831\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.781321\tvalid_1's auc: 0.716331\n",
      "[200]\ttraining's auc: 0.824927\tvalid_1's auc: 0.725534\n",
      "[300]\ttraining's auc: 0.856034\tvalid_1's auc: 0.729593\n",
      "[400]\ttraining's auc: 0.880078\tvalid_1's auc: 0.729987\n",
      "[500]\ttraining's auc: 0.90008\tvalid_1's auc: 0.730597\n",
      "[600]\ttraining's auc: 0.916272\tvalid_1's auc: 0.731002\n",
      "[700]\ttraining's auc: 0.93013\tvalid_1's auc: 0.731052\n",
      "[800]\ttraining's auc: 0.941707\tvalid_1's auc: 0.730716\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's auc: 0.936002\tvalid_1's auc: 0.731392\n",
      "Partial score of fold 1 is: 0.731392208949148\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.880546\n",
      "1    0.119454\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.837457\n",
      "1    0.162543\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.782911\tvalid_1's auc: 0.705555\n",
      "[200]\ttraining's auc: 0.827982\tvalid_1's auc: 0.712691\n",
      "[300]\ttraining's auc: 0.859215\tvalid_1's auc: 0.71427\n",
      "[400]\ttraining's auc: 0.882956\tvalid_1's auc: 0.714677\n",
      "[500]\ttraining's auc: 0.902462\tvalid_1's auc: 0.715111\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's auc: 0.887992\tvalid_1's auc: 0.715251\n",
      "Partial score of fold 2 is: 0.7152510453770714\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.867128\n",
      "1    0.132872\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.892627\n",
      "1    0.107373\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.777523\tvalid_1's auc: 0.725833\n",
      "[200]\ttraining's auc: 0.82093\tvalid_1's auc: 0.73689\n",
      "[300]\ttraining's auc: 0.851714\tvalid_1's auc: 0.740714\n",
      "[400]\ttraining's auc: 0.875675\tvalid_1's auc: 0.741229\n",
      "[500]\ttraining's auc: 0.895178\tvalid_1's auc: 0.741979\n",
      "[600]\ttraining's auc: 0.911647\tvalid_1's auc: 0.741514\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's auc: 0.898607\tvalid_1's auc: 0.74224\n",
      "Partial score of fold 3 is: 0.7422399843800832\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.864933\n",
      "1    0.135067\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.901669\n",
      "1    0.098331\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.775282\tvalid_1's auc: 0.730842\n",
      "[200]\ttraining's auc: 0.817791\tvalid_1's auc: 0.742321\n",
      "[300]\ttraining's auc: 0.848492\tvalid_1's auc: 0.744566\n",
      "[400]\ttraining's auc: 0.87343\tvalid_1's auc: 0.74619\n",
      "[500]\ttraining's auc: 0.893358\tvalid_1's auc: 0.74719\n",
      "[600]\ttraining's auc: 0.910693\tvalid_1's auc: 0.748512\n",
      "[700]\ttraining's auc: 0.92459\tvalid_1's auc: 0.748099\n",
      "Early stopping, best iteration is:\n",
      "[636]\ttraining's auc: 0.915623\tvalid_1's auc: 0.748786\n",
      "Partial score of fold 4 is: 0.7487863822393392\n",
      "AUC score is:  0.7359421185066743\n",
      "################### 2 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981708\n",
      "1    0.018292\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.98105\n",
      "1    0.01895\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.94838\tvalid_1's auc: 0.808861\n",
      "[200]\ttraining's auc: 0.982512\tvalid_1's auc: 0.816299\n",
      "[300]\ttraining's auc: 0.99318\tvalid_1's auc: 0.815579\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's auc: 0.98265\tvalid_1's auc: 0.816459\n",
      "Partial score of fold 0 is: 0.8164591098343479\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981434\n",
      "1    0.018566\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982158\n",
      "1    0.017842\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.946193\tvalid_1's auc: 0.792752\n",
      "[200]\ttraining's auc: 0.981131\tvalid_1's auc: 0.799166\n",
      "[300]\ttraining's auc: 0.993036\tvalid_1's auc: 0.801968\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's auc: 0.992103\tvalid_1's auc: 0.802965\n",
      "Partial score of fold 1 is: 0.8029650170969475\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981179\n",
      "1    0.018821\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983244\n",
      "1    0.016756\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.942838\tvalid_1's auc: 0.817342\n",
      "[200]\ttraining's auc: 0.979553\tvalid_1's auc: 0.822151\n",
      "[300]\ttraining's auc: 0.992253\tvalid_1's auc: 0.825162\n",
      "[400]\ttraining's auc: 0.996973\tvalid_1's auc: 0.827169\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's auc: 0.995362\tvalid_1's auc: 0.827636\n",
      "Partial score of fold 2 is: 0.8276362348210186\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.982171\n",
      "1    0.017829\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.979282\n",
      "1    0.020718\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.94847\tvalid_1's auc: 0.79342\n",
      "[200]\ttraining's auc: 0.984525\tvalid_1's auc: 0.802236\n",
      "[300]\ttraining's auc: 0.994404\tvalid_1's auc: 0.805446\n",
      "[400]\ttraining's auc: 0.997938\tvalid_1's auc: 0.806007\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's auc: 0.996217\tvalid_1's auc: 0.806445\n",
      "Partial score of fold 3 is: 0.8064452144776075\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981402\n",
      "1    0.018598\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982257\n",
      "1    0.017743\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.944098\tvalid_1's auc: 0.789131\n",
      "[200]\ttraining's auc: 0.980653\tvalid_1's auc: 0.795989\n",
      "[300]\ttraining's auc: 0.992334\tvalid_1's auc: 0.797471\n",
      "[400]\ttraining's auc: 0.997062\tvalid_1's auc: 0.799541\n",
      "[500]\ttraining's auc: 0.998907\tvalid_1's auc: 0.797107\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttraining's auc: 0.997087\tvalid_1's auc: 0.799899\n",
      "Partial score of fold 4 is: 0.7998987993150253\n",
      "AUC score is:  0.8094631189535232\n",
      "################### 3 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.936164\n",
      "1    0.063836\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931381\n",
      "1    0.068619\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.820682\tvalid_1's auc: 0.722128\n",
      "[200]\ttraining's auc: 0.880297\tvalid_1's auc: 0.731234\n",
      "[300]\ttraining's auc: 0.915611\tvalid_1's auc: 0.734455\n",
      "[400]\ttraining's auc: 0.939321\tvalid_1's auc: 0.735089\n",
      "[500]\ttraining's auc: 0.955365\tvalid_1's auc: 0.735192\n",
      "[600]\ttraining's auc: 0.967525\tvalid_1's auc: 0.735033\n",
      "Early stopping, best iteration is:\n",
      "[517]\ttraining's auc: 0.957616\tvalid_1's auc: 0.735902\n",
      "Partial score of fold 0 is: 0.7359016792123713\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.93549\n",
      "1    0.06451\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.934139\n",
      "1    0.065861\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.81721\tvalid_1's auc: 0.709565\n",
      "[200]\ttraining's auc: 0.877471\tvalid_1's auc: 0.723392\n",
      "[300]\ttraining's auc: 0.913204\tvalid_1's auc: 0.728873\n",
      "[400]\ttraining's auc: 0.937767\tvalid_1's auc: 0.730965\n",
      "[500]\ttraining's auc: 0.955411\tvalid_1's auc: 0.730663\n",
      "Early stopping, best iteration is:\n",
      "[422]\ttraining's auc: 0.942226\tvalid_1's auc: 0.731408\n",
      "Partial score of fold 1 is: 0.7314075388609551\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.934328\n",
      "1    0.065672\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.938661\n",
      "1    0.061339\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815229\tvalid_1's auc: 0.713285\n",
      "[200]\ttraining's auc: 0.875573\tvalid_1's auc: 0.724654\n",
      "[300]\ttraining's auc: 0.912768\tvalid_1's auc: 0.729888\n",
      "[400]\ttraining's auc: 0.936435\tvalid_1's auc: 0.730813\n",
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's auc: 0.926232\tvalid_1's auc: 0.731408\n",
      "Partial score of fold 2 is: 0.7314075063290939\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.933981\n",
      "1    0.066019\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.93998\n",
      "1    0.06002\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815393\tvalid_1's auc: 0.723702\n",
      "[200]\ttraining's auc: 0.875191\tvalid_1's auc: 0.735537\n",
      "[300]\ttraining's auc: 0.911004\tvalid_1's auc: 0.73964\n",
      "[400]\ttraining's auc: 0.935548\tvalid_1's auc: 0.742085\n",
      "[500]\ttraining's auc: 0.953317\tvalid_1's auc: 0.743988\n",
      "[600]\ttraining's auc: 0.965953\tvalid_1's auc: 0.744679\n",
      "[700]\ttraining's auc: 0.975349\tvalid_1's auc: 0.744129\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttraining's auc: 0.966259\tvalid_1's auc: 0.744808\n",
      "Partial score of fold 3 is: 0.7448081589115277\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.936113\n",
      "1    0.063887\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931453\n",
      "1    0.068547\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815813\tvalid_1's auc: 0.722292\n",
      "[200]\ttraining's auc: 0.876692\tvalid_1's auc: 0.733418\n",
      "[300]\ttraining's auc: 0.913887\tvalid_1's auc: 0.736677\n",
      "[400]\ttraining's auc: 0.938307\tvalid_1's auc: 0.736636\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's auc: 0.928172\tvalid_1's auc: 0.737101\n",
      "Partial score of fold 4 is: 0.7371013919511866\n",
      "AUC score is:  0.7362339192757318\n",
      "################### 4 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.848349\n",
      "1    0.151651\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.844265\n",
      "1    0.155735\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.773767\tvalid_1's auc: 0.716033\n",
      "[200]\ttraining's auc: 0.816417\tvalid_1's auc: 0.729889\n",
      "[300]\ttraining's auc: 0.845966\tvalid_1's auc: 0.735966\n",
      "[400]\ttraining's auc: 0.868749\tvalid_1's auc: 0.738196\n",
      "[500]\ttraining's auc: 0.887173\tvalid_1's auc: 0.738786\n",
      "[600]\ttraining's auc: 0.90324\tvalid_1's auc: 0.739638\n",
      "[700]\ttraining's auc: 0.916832\tvalid_1's auc: 0.740433\n",
      "[800]\ttraining's auc: 0.928549\tvalid_1's auc: 0.740582\n",
      "[900]\ttraining's auc: 0.938687\tvalid_1's auc: 0.741092\n",
      "[1000]\ttraining's auc: 0.947043\tvalid_1's auc: 0.74048\n",
      "Early stopping, best iteration is:\n",
      "[911]\ttraining's auc: 0.939617\tvalid_1's auc: 0.741199\n",
      "Partial score of fold 0 is: 0.7411991067922336\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.849224\n",
      "1    0.150776\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.840709\n",
      "1    0.159291\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.771303\tvalid_1's auc: 0.720589\n",
      "[200]\ttraining's auc: 0.813985\tvalid_1's auc: 0.733218\n",
      "[300]\ttraining's auc: 0.843708\tvalid_1's auc: 0.73809\n",
      "[400]\ttraining's auc: 0.866856\tvalid_1's auc: 0.740073\n",
      "[500]\ttraining's auc: 0.886309\tvalid_1's auc: 0.740876\n",
      "[600]\ttraining's auc: 0.9024\tvalid_1's auc: 0.742165\n",
      "[700]\ttraining's auc: 0.916031\tvalid_1's auc: 0.741932\n",
      "Early stopping, best iteration is:\n",
      "[605]\ttraining's auc: 0.903184\tvalid_1's auc: 0.742258\n",
      "Partial score of fold 1 is: 0.7422583970055294\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846808\n",
      "1    0.153192\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.85062\n",
      "1    0.14938\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.770626\tvalid_1's auc: 0.72572\n",
      "[200]\ttraining's auc: 0.813683\tvalid_1's auc: 0.741002\n",
      "[300]\ttraining's auc: 0.843458\tvalid_1's auc: 0.7459\n",
      "[400]\ttraining's auc: 0.86706\tvalid_1's auc: 0.748079\n",
      "[500]\ttraining's auc: 0.885195\tvalid_1's auc: 0.749083\n",
      "[600]\ttraining's auc: 0.900937\tvalid_1's auc: 0.749665\n",
      "[700]\ttraining's auc: 0.914919\tvalid_1's auc: 0.749627\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttraining's auc: 0.907762\tvalid_1's auc: 0.749862\n",
      "Partial score of fold 2 is: 0.7498622541624458\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846371\n",
      "1    0.153629\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.851993\n",
      "1    0.148007\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.772838\tvalid_1's auc: 0.718613\n",
      "[200]\ttraining's auc: 0.81457\tvalid_1's auc: 0.732146\n",
      "[300]\ttraining's auc: 0.844335\tvalid_1's auc: 0.736822\n",
      "[400]\ttraining's auc: 0.867296\tvalid_1's auc: 0.738533\n",
      "[500]\ttraining's auc: 0.885802\tvalid_1's auc: 0.739837\n",
      "[600]\ttraining's auc: 0.90179\tvalid_1's auc: 0.740604\n",
      "[700]\ttraining's auc: 0.915107\tvalid_1's auc: 0.740721\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's auc: 0.911879\tvalid_1's auc: 0.740915\n",
      "Partial score of fold 3 is: 0.7409154194517796\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846908\n",
      "1    0.153092\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.849964\n",
      "1    0.150036\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.770373\tvalid_1's auc: 0.728288\n",
      "[200]\ttraining's auc: 0.81388\tvalid_1's auc: 0.742552\n",
      "[300]\ttraining's auc: 0.844169\tvalid_1's auc: 0.748001\n",
      "[400]\ttraining's auc: 0.867157\tvalid_1's auc: 0.749748\n",
      "[500]\ttraining's auc: 0.886925\tvalid_1's auc: 0.751773\n",
      "[600]\ttraining's auc: 0.903168\tvalid_1's auc: 0.752394\n",
      "[700]\ttraining's auc: 0.916165\tvalid_1's auc: 0.752834\n",
      "[800]\ttraining's auc: 0.928023\tvalid_1's auc: 0.751889\n",
      "Early stopping, best iteration is:\n",
      "[723]\ttraining's auc: 0.918936\tvalid_1's auc: 0.753069\n",
      "Partial score of fold 4 is: 0.7530691735044778\n",
      "AUC score is:  0.7449715631465162\n",
      "################### 5 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.910698\n",
      "1    0.089302\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.90939\n",
      "1    0.09061\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.850097\tvalid_1's auc: 0.778455\n",
      "[200]\ttraining's auc: 0.89143\tvalid_1's auc: 0.795176\n",
      "[300]\ttraining's auc: 0.916361\tvalid_1's auc: 0.801314\n",
      "[400]\ttraining's auc: 0.933701\tvalid_1's auc: 0.806314\n",
      "[500]\ttraining's auc: 0.947291\tvalid_1's auc: 0.808604\n",
      "[600]\ttraining's auc: 0.957545\tvalid_1's auc: 0.810203\n",
      "[700]\ttraining's auc: 0.965901\tvalid_1's auc: 0.810972\n",
      "[800]\ttraining's auc: 0.972567\tvalid_1's auc: 0.811374\n",
      "[900]\ttraining's auc: 0.978241\tvalid_1's auc: 0.812015\n",
      "[1000]\ttraining's auc: 0.982645\tvalid_1's auc: 0.812311\n",
      "[1100]\ttraining's auc: 0.986277\tvalid_1's auc: 0.812409\n",
      "Early stopping, best iteration is:\n",
      "[1052]\ttraining's auc: 0.984627\tvalid_1's auc: 0.812648\n",
      "Partial score of fold 0 is: 0.8126476321084213\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.906117\n",
      "1    0.093883\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.928431\n",
      "1    0.071569\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.839991\tvalid_1's auc: 0.812932\n",
      "[200]\ttraining's auc: 0.88284\tvalid_1's auc: 0.829896\n",
      "[300]\ttraining's auc: 0.908945\tvalid_1's auc: 0.836858\n",
      "[400]\ttraining's auc: 0.926957\tvalid_1's auc: 0.841041\n",
      "[500]\ttraining's auc: 0.941356\tvalid_1's auc: 0.843858\n",
      "[600]\ttraining's auc: 0.952433\tvalid_1's auc: 0.844682\n",
      "[700]\ttraining's auc: 0.961504\tvalid_1's auc: 0.84571\n",
      "[800]\ttraining's auc: 0.968825\tvalid_1's auc: 0.846511\n",
      "[900]\ttraining's auc: 0.974811\tvalid_1's auc: 0.846719\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttraining's auc: 0.972542\tvalid_1's auc: 0.847063\n",
      "Partial score of fold 1 is: 0.8470628197272002\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.916028\n",
      "1    0.083972\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.889039\n",
      "1    0.110961\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.853599\tvalid_1's auc: 0.751067\n",
      "[200]\ttraining's auc: 0.895663\tvalid_1's auc: 0.773615\n",
      "[300]\ttraining's auc: 0.920458\tvalid_1's auc: 0.782062\n",
      "[400]\ttraining's auc: 0.938075\tvalid_1's auc: 0.786107\n",
      "[500]\ttraining's auc: 0.951406\tvalid_1's auc: 0.788981\n",
      "[600]\ttraining's auc: 0.961665\tvalid_1's auc: 0.790913\n",
      "[700]\ttraining's auc: 0.969578\tvalid_1's auc: 0.79143\n",
      "[800]\ttraining's auc: 0.975796\tvalid_1's auc: 0.791404\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's auc: 0.973954\tvalid_1's auc: 0.791855\n",
      "Partial score of fold 2 is: 0.79185455506149\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.908803\n",
      "1    0.091197\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.917141\n",
      "1    0.082859\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841701\tvalid_1's auc: 0.803746\n",
      "[200]\ttraining's auc: 0.884264\tvalid_1's auc: 0.824078\n",
      "[300]\ttraining's auc: 0.911003\tvalid_1's auc: 0.829947\n",
      "[400]\ttraining's auc: 0.92908\tvalid_1's auc: 0.834481\n",
      "[500]\ttraining's auc: 0.943371\tvalid_1's auc: 0.836273\n",
      "[600]\ttraining's auc: 0.954158\tvalid_1's auc: 0.837052\n",
      "Early stopping, best iteration is:\n",
      "[580]\ttraining's auc: 0.951989\tvalid_1's auc: 0.837343\n",
      "Partial score of fold 3 is: 0.8373426339353174\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.910624\n",
      "1    0.089376\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.909689\n",
      "1    0.090311\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.847202\tvalid_1's auc: 0.774374\n",
      "[200]\ttraining's auc: 0.890573\tvalid_1's auc: 0.794958\n",
      "[300]\ttraining's auc: 0.915646\tvalid_1's auc: 0.802997\n",
      "[400]\ttraining's auc: 0.933785\tvalid_1's auc: 0.806367\n",
      "[500]\ttraining's auc: 0.946888\tvalid_1's auc: 0.808238\n",
      "[600]\ttraining's auc: 0.957526\tvalid_1's auc: 0.808194\n",
      "Early stopping, best iteration is:\n",
      "[525]\ttraining's auc: 0.949854\tvalid_1's auc: 0.808497\n",
      "Partial score of fold 4 is: 0.8084967697914627\n",
      "AUC score is:  0.819199520051759\n",
      "################### 6 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953892\n",
      "1    0.046108\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956306\n",
      "1    0.043694\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.884926\tvalid_1's auc: 0.791684\n",
      "[200]\ttraining's auc: 0.930389\tvalid_1's auc: 0.806557\n",
      "[300]\ttraining's auc: 0.954782\tvalid_1's auc: 0.810214\n",
      "[400]\ttraining's auc: 0.969655\tvalid_1's auc: 0.810566\n",
      "[500]\ttraining's auc: 0.979219\tvalid_1's auc: 0.811462\n",
      "[600]\ttraining's auc: 0.986108\tvalid_1's auc: 0.809925\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's auc: 0.980047\tvalid_1's auc: 0.81164\n",
      "Partial score of fold 0 is: 0.8116403476124903\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954374\n",
      "1    0.045626\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.954346\n",
      "1    0.045654\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88451\tvalid_1's auc: 0.776404\n",
      "[200]\ttraining's auc: 0.930138\tvalid_1's auc: 0.794659\n",
      "[300]\ttraining's auc: 0.954264\tvalid_1's auc: 0.799928\n",
      "[400]\ttraining's auc: 0.969695\tvalid_1's auc: 0.802289\n",
      "[500]\ttraining's auc: 0.980363\tvalid_1's auc: 0.803721\n",
      "[600]\ttraining's auc: 0.986917\tvalid_1's auc: 0.803689\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttraining's auc: 0.983218\tvalid_1's auc: 0.804848\n",
      "Partial score of fold 1 is: 0.8048476995171827\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.95223\n",
      "1    0.04777\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.963406\n",
      "1    0.036594\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.880865\tvalid_1's auc: 0.798379\n",
      "[200]\ttraining's auc: 0.927148\tvalid_1's auc: 0.816145\n",
      "[300]\ttraining's auc: 0.952004\tvalid_1's auc: 0.819645\n",
      "[400]\ttraining's auc: 0.967743\tvalid_1's auc: 0.821053\n",
      "[500]\ttraining's auc: 0.97791\tvalid_1's auc: 0.82151\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's auc: 0.974931\tvalid_1's auc: 0.822913\n",
      "Partial score of fold 2 is: 0.8229127560470828\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.955878\n",
      "1    0.044122\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.948557\n",
      "1    0.051443\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888532\tvalid_1's auc: 0.78047\n",
      "[200]\ttraining's auc: 0.935215\tvalid_1's auc: 0.79447\n",
      "[300]\ttraining's auc: 0.95847\tvalid_1's auc: 0.797229\n",
      "[400]\ttraining's auc: 0.97248\tvalid_1's auc: 0.798287\n",
      "Early stopping, best iteration is:\n",
      "[344]\ttraining's auc: 0.965627\tvalid_1's auc: 0.799299\n",
      "Partial score of fold 3 is: 0.7992993213793852\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.955516\n",
      "1    0.044484\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.949993\n",
      "1    0.050007\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.887597\tvalid_1's auc: 0.784442\n",
      "[200]\ttraining's auc: 0.934327\tvalid_1's auc: 0.799127\n",
      "[300]\ttraining's auc: 0.958127\tvalid_1's auc: 0.805253\n",
      "[400]\ttraining's auc: 0.972737\tvalid_1's auc: 0.807003\n",
      "[500]\ttraining's auc: 0.981531\tvalid_1's auc: 0.806889\n",
      "Early stopping, best iteration is:\n",
      "[409]\ttraining's auc: 0.973725\tvalid_1's auc: 0.807431\n",
      "Partial score of fold 4 is: 0.8074307491507187\n",
      "AUC score is:  0.8087412156984022\n",
      "################### 7 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983029\n",
      "1    0.016971\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.98575\n",
      "1    0.01425\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.947821\tvalid_1's auc: 0.745899\n",
      "[200]\ttraining's auc: 0.984159\tvalid_1's auc: 0.766041\n",
      "[300]\ttraining's auc: 0.994324\tvalid_1's auc: 0.770213\n",
      "[400]\ttraining's auc: 0.99802\tvalid_1's auc: 0.773425\n",
      "[500]\ttraining's auc: 0.999368\tvalid_1's auc: 0.774209\n",
      "[600]\ttraining's auc: 0.999791\tvalid_1's auc: 0.775202\n",
      "Early stopping, best iteration is:\n",
      "[591]\ttraining's auc: 0.999773\tvalid_1's auc: 0.776015\n",
      "Partial score of fold 0 is: 0.7760151086954752\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983313\n",
      "1    0.016687\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.984619\n",
      "1    0.015381\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.952569\tvalid_1's auc: 0.784591\n",
      "[200]\ttraining's auc: 0.98499\tvalid_1's auc: 0.792918\n",
      "[300]\ttraining's auc: 0.994793\tvalid_1's auc: 0.792812\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's auc: 0.993795\tvalid_1's auc: 0.79394\n",
      "Partial score of fold 1 is: 0.7939395487563261\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98394\n",
      "1    0.01606\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982137\n",
      "1    0.017863\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.955081\tvalid_1's auc: 0.807751\n",
      "[200]\ttraining's auc: 0.986043\tvalid_1's auc: 0.809034\n",
      "[300]\ttraining's auc: 0.995579\tvalid_1's auc: 0.809564\n",
      "[400]\ttraining's auc: 0.998532\tvalid_1's auc: 0.810678\n",
      "Early stopping, best iteration is:\n",
      "[360]\ttraining's auc: 0.997688\tvalid_1's auc: 0.811776\n",
      "Partial score of fold 2 is: 0.8117764500600002\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.984094\n",
      "1    0.015906\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.981387\n",
      "1    0.018613\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.956389\tvalid_1's auc: 0.767898\n",
      "[200]\ttraining's auc: 0.986635\tvalid_1's auc: 0.778072\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's auc: 0.984554\tvalid_1's auc: 0.779266\n",
      "Partial score of fold 3 is: 0.7792658249402545\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98348\n",
      "1    0.01652\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983927\n",
      "1    0.016073\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.951511\tvalid_1's auc: 0.78929\n",
      "[200]\ttraining's auc: 0.984783\tvalid_1's auc: 0.804712\n",
      "[300]\ttraining's auc: 0.994818\tvalid_1's auc: 0.807622\n",
      "[400]\ttraining's auc: 0.998108\tvalid_1's auc: 0.808595\n",
      "[500]\ttraining's auc: 0.99933\tvalid_1's auc: 0.81088\n",
      "[600]\ttraining's auc: 0.999734\tvalid_1's auc: 0.808473\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's auc: 0.99933\tvalid_1's auc: 0.81088\n",
      "Partial score of fold 4 is: 0.8108800908560987\n",
      "AUC score is:  0.7943650029118041\n",
      "################### 8 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98377\n",
      "1    0.01623\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983832\n",
      "1    0.016168\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.965195\tvalid_1's auc: 0.851586\n",
      "[200]\ttraining's auc: 0.987965\tvalid_1's auc: 0.858351\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's auc: 0.984097\tvalid_1's auc: 0.86058\n",
      "Partial score of fold 0 is: 0.8605801041776653\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983944\n",
      "1    0.016056\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983104\n",
      "1    0.016896\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.962728\tvalid_1's auc: 0.829839\n",
      "[200]\ttraining's auc: 0.98842\tvalid_1's auc: 0.841156\n",
      "[300]\ttraining's auc: 0.996343\tvalid_1's auc: 0.844747\n",
      "[400]\ttraining's auc: 0.998702\tvalid_1's auc: 0.846242\n",
      "[500]\ttraining's auc: 0.999501\tvalid_1's auc: 0.845565\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttraining's auc: 0.998946\tvalid_1's auc: 0.846467\n",
      "Partial score of fold 1 is: 0.8464666448691267\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.984141\n",
      "1    0.015859\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982387\n",
      "1    0.017613\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.966017\tvalid_1's auc: 0.82546\n",
      "[200]\ttraining's auc: 0.989371\tvalid_1's auc: 0.830652\n",
      "[300]\ttraining's auc: 0.996354\tvalid_1's auc: 0.833021\n",
      "[400]\ttraining's auc: 0.998721\tvalid_1's auc: 0.833422\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's auc: 0.998548\tvalid_1's auc: 0.833578\n",
      "Partial score of fold 2 is: 0.8335778444415898\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983165\n",
      "1    0.016835\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.986258\n",
      "1    0.013742\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.962173\tvalid_1's auc: 0.784771\n",
      "[200]\ttraining's auc: 0.987422\tvalid_1's auc: 0.796747\n",
      "[300]\ttraining's auc: 0.995691\tvalid_1's auc: 0.802839\n",
      "[400]\ttraining's auc: 0.998553\tvalid_1's auc: 0.804557\n",
      "Early stopping, best iteration is:\n",
      "[376]\ttraining's auc: 0.99814\tvalid_1's auc: 0.807375\n",
      "Partial score of fold 3 is: 0.8073754664749786\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983892\n",
      "1    0.016108\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983357\n",
      "1    0.016643\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.963503\tvalid_1's auc: 0.839244\n",
      "[200]\ttraining's auc: 0.989079\tvalid_1's auc: 0.843679\n",
      "[300]\ttraining's auc: 0.996309\tvalid_1's auc: 0.845023\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's auc: 0.9927\tvalid_1's auc: 0.845692\n",
      "Partial score of fold 4 is: 0.8456920066622909\n",
      "AUC score is:  0.8344491198867251\n",
      "################### 9 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989412\n",
      "1    0.010588\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.991567\n",
      "1    0.008433\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.983599\tvalid_1's auc: 0.834888\n",
      "[200]\ttraining's auc: 0.996978\tvalid_1's auc: 0.835729\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's auc: 0.99538\tvalid_1's auc: 0.837898\n",
      "Partial score of fold 0 is: 0.8378980701309231\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989856\n",
      "1    0.010144\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.989786\n",
      "1    0.010214\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.984285\tvalid_1's auc: 0.876585\n",
      "[200]\ttraining's auc: 0.99734\tvalid_1's auc: 0.883965\n",
      "[300]\ttraining's auc: 0.999514\tvalid_1's auc: 0.882916\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's auc: 0.997539\tvalid_1's auc: 0.88457\n",
      "Partial score of fold 1 is: 0.8845701523895874\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989747\n",
      "1    0.010253\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.990242\n",
      "1    0.009758\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.983902\tvalid_1's auc: 0.867634\n",
      "[200]\ttraining's auc: 0.997105\tvalid_1's auc: 0.86889\n",
      "[300]\ttraining's auc: 0.999416\tvalid_1's auc: 0.86908\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's auc: 0.997777\tvalid_1's auc: 0.870821\n",
      "Partial score of fold 2 is: 0.8708213678616489\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.990352\n",
      "1    0.009648\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.987865\n",
      "1    0.012135\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.986831\tvalid_1's auc: 0.858531\n",
      "[200]\ttraining's auc: 0.997628\tvalid_1's auc: 0.86524\n",
      "[300]\ttraining's auc: 0.99957\tvalid_1's auc: 0.865215\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's auc: 0.999453\tvalid_1's auc: 0.86756\n",
      "Partial score of fold 3 is: 0.8675595065641436\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989849\n",
      "1    0.010151\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.989817\n",
      "1    0.010183\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.984106\tvalid_1's auc: 0.861448\n",
      "[200]\ttraining's auc: 0.996841\tvalid_1's auc: 0.857192\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's auc: 0.986288\tvalid_1's auc: 0.865569\n",
      "Partial score of fold 4 is: 0.8655689403271548\n",
      "AUC score is:  0.8616581755544027\n",
      "################### 10 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954864\n",
      "1    0.045136\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.951977\n",
      "1    0.048023\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.924005\tvalid_1's auc: 0.884443\n",
      "[200]\ttraining's auc: 0.959002\tvalid_1's auc: 0.897866\n",
      "[300]\ttraining's auc: 0.974032\tvalid_1's auc: 0.903507\n",
      "[400]\ttraining's auc: 0.983099\tvalid_1's auc: 0.905659\n",
      "[500]\ttraining's auc: 0.988749\tvalid_1's auc: 0.906211\n",
      "[600]\ttraining's auc: 0.992499\tvalid_1's auc: 0.907072\n",
      "Early stopping, best iteration is:\n",
      "[587]\ttraining's auc: 0.992064\tvalid_1's auc: 0.90722\n",
      "Partial score of fold 0 is: 0.907220230245082\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953718\n",
      "1    0.046282\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956611\n",
      "1    0.043389\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.927174\tvalid_1's auc: 0.85806\n",
      "[200]\ttraining's auc: 0.958599\tvalid_1's auc: 0.874002\n",
      "[300]\ttraining's auc: 0.973144\tvalid_1's auc: 0.880101\n",
      "[400]\ttraining's auc: 0.98212\tvalid_1's auc: 0.883871\n",
      "[500]\ttraining's auc: 0.988028\tvalid_1's auc: 0.885318\n",
      "[600]\ttraining's auc: 0.991939\tvalid_1's auc: 0.887065\n",
      "[700]\ttraining's auc: 0.994587\tvalid_1's auc: 0.88759\n",
      "[800]\ttraining's auc: 0.996444\tvalid_1's auc: 0.887486\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's auc: 0.99462\tvalid_1's auc: 0.887695\n",
      "Partial score of fold 1 is: 0.8876954618455658\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954608\n",
      "1    0.045392\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.952962\n",
      "1    0.047038\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.925352\tvalid_1's auc: 0.862258\n",
      "[200]\ttraining's auc: 0.959121\tvalid_1's auc: 0.880166\n",
      "[300]\ttraining's auc: 0.974005\tvalid_1's auc: 0.88788\n",
      "[400]\ttraining's auc: 0.982798\tvalid_1's auc: 0.890698\n",
      "[500]\ttraining's auc: 0.988378\tvalid_1's auc: 0.892711\n",
      "[600]\ttraining's auc: 0.992236\tvalid_1's auc: 0.894257\n",
      "[700]\ttraining's auc: 0.994918\tvalid_1's auc: 0.89527\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttraining's auc: 0.994611\tvalid_1's auc: 0.895473\n",
      "Partial score of fold 2 is: 0.8954732867986382\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953812\n",
      "1    0.046188\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956134\n",
      "1    0.043866\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.924633\tvalid_1's auc: 0.872711\n",
      "[200]\ttraining's auc: 0.958053\tvalid_1's auc: 0.889314\n",
      "[300]\ttraining's auc: 0.973678\tvalid_1's auc: 0.895473\n",
      "[400]\ttraining's auc: 0.982566\tvalid_1's auc: 0.898698\n",
      "[500]\ttraining's auc: 0.988117\tvalid_1's auc: 0.901055\n",
      "[600]\ttraining's auc: 0.992084\tvalid_1's auc: 0.900909\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's auc: 0.988739\tvalid_1's auc: 0.90116\n",
      "Partial score of fold 3 is: 0.9011603528741088\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954446\n",
      "1    0.045554\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.953687\n",
      "1    0.046313\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.92562\tvalid_1's auc: 0.868583\n",
      "[200]\ttraining's auc: 0.958909\tvalid_1's auc: 0.884858\n",
      "[300]\ttraining's auc: 0.974011\tvalid_1's auc: 0.890591\n",
      "[400]\ttraining's auc: 0.982968\tvalid_1's auc: 0.892908\n",
      "[500]\ttraining's auc: 0.98857\tvalid_1's auc: 0.895455\n",
      "[600]\ttraining's auc: 0.992385\tvalid_1's auc: 0.896695\n",
      "[700]\ttraining's auc: 0.995028\tvalid_1's auc: 0.897435\n",
      "[800]\ttraining's auc: 0.996734\tvalid_1's auc: 0.897845\n",
      "Early stopping, best iteration is:\n",
      "[799]\ttraining's auc: 0.996721\tvalid_1's auc: 0.897919\n",
      "Partial score of fold 4 is: 0.8979192502522281\n",
      "AUC score is:  0.8971713112835623\n",
      "################### 11 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.921689\n",
      "1    0.078311\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931208\n",
      "1    0.068792\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890939\tvalid_1's auc: 0.852617\n",
      "[200]\ttraining's auc: 0.926568\tvalid_1's auc: 0.869634\n",
      "[300]\ttraining's auc: 0.946025\tvalid_1's auc: 0.876335\n",
      "[400]\ttraining's auc: 0.959164\tvalid_1's auc: 0.880198\n",
      "[500]\ttraining's auc: 0.968706\tvalid_1's auc: 0.881109\n",
      "[600]\ttraining's auc: 0.975805\tvalid_1's auc: 0.881849\n",
      "[700]\ttraining's auc: 0.981282\tvalid_1's auc: 0.882784\n",
      "[800]\ttraining's auc: 0.985603\tvalid_1's auc: 0.883191\n",
      "[900]\ttraining's auc: 0.988839\tvalid_1's auc: 0.883685\n",
      "[1000]\ttraining's auc: 0.991443\tvalid_1's auc: 0.884204\n",
      "Early stopping, best iteration is:\n",
      "[978]\ttraining's auc: 0.990932\tvalid_1's auc: 0.884289\n",
      "Partial score of fold 0 is: 0.884288930543286\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923346\n",
      "1    0.076654\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.924375\n",
      "1    0.075625\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890759\tvalid_1's auc: 0.844583\n",
      "[200]\ttraining's auc: 0.92653\tvalid_1's auc: 0.863269\n",
      "[300]\ttraining's auc: 0.946403\tvalid_1's auc: 0.871054\n",
      "[400]\ttraining's auc: 0.960067\tvalid_1's auc: 0.875037\n",
      "[500]\ttraining's auc: 0.969812\tvalid_1's auc: 0.877379\n",
      "[600]\ttraining's auc: 0.976691\tvalid_1's auc: 0.878348\n",
      "[700]\ttraining's auc: 0.982215\tvalid_1's auc: 0.879626\n",
      "[800]\ttraining's auc: 0.986384\tvalid_1's auc: 0.880372\n",
      "[900]\ttraining's auc: 0.989561\tvalid_1's auc: 0.880591\n",
      "[1000]\ttraining's auc: 0.992066\tvalid_1's auc: 0.880813\n",
      "[1100]\ttraining's auc: 0.993982\tvalid_1's auc: 0.880793\n",
      "[1200]\ttraining's auc: 0.995507\tvalid_1's auc: 0.880887\n",
      "[1300]\ttraining's auc: 0.996669\tvalid_1's auc: 0.880947\n",
      "Early stopping, best iteration is:\n",
      "[1239]\ttraining's auc: 0.995987\tvalid_1's auc: 0.881354\n",
      "Partial score of fold 1 is: 0.8813536453968243\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.924851\n",
      "1    0.075149\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.918363\n",
      "1    0.081637\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894439\tvalid_1's auc: 0.834752\n",
      "[200]\ttraining's auc: 0.92877\tvalid_1's auc: 0.850798\n",
      "[300]\ttraining's auc: 0.9483\tvalid_1's auc: 0.857531\n",
      "[400]\ttraining's auc: 0.960908\tvalid_1's auc: 0.861272\n",
      "[500]\ttraining's auc: 0.970187\tvalid_1's auc: 0.863327\n",
      "[600]\ttraining's auc: 0.977206\tvalid_1's auc: 0.865597\n",
      "[700]\ttraining's auc: 0.982615\tvalid_1's auc: 0.866413\n",
      "[800]\ttraining's auc: 0.986743\tvalid_1's auc: 0.867183\n",
      "[900]\ttraining's auc: 0.989867\tvalid_1's auc: 0.868032\n",
      "[1000]\ttraining's auc: 0.992351\tvalid_1's auc: 0.868677\n",
      "[1100]\ttraining's auc: 0.994217\tvalid_1's auc: 0.868351\n",
      "Early stopping, best iteration is:\n",
      "[1004]\ttraining's auc: 0.992435\tvalid_1's auc: 0.868718\n",
      "Partial score of fold 2 is: 0.8687178233874356\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923954\n",
      "1    0.076046\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.921962\n",
      "1    0.078038\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890331\tvalid_1's auc: 0.849916\n",
      "[200]\ttraining's auc: 0.926317\tvalid_1's auc: 0.866444\n",
      "[300]\ttraining's auc: 0.946686\tvalid_1's auc: 0.87338\n",
      "[400]\ttraining's auc: 0.960124\tvalid_1's auc: 0.875783\n",
      "[500]\ttraining's auc: 0.969616\tvalid_1's auc: 0.877133\n",
      "[600]\ttraining's auc: 0.976432\tvalid_1's auc: 0.87762\n",
      "[700]\ttraining's auc: 0.981888\tvalid_1's auc: 0.878207\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttraining's auc: 0.980005\tvalid_1's auc: 0.878321\n",
      "Partial score of fold 3 is: 0.8783213214754687\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923905\n",
      "1    0.076095\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.922152\n",
      "1    0.077848\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893042\tvalid_1's auc: 0.844461\n",
      "[200]\ttraining's auc: 0.926908\tvalid_1's auc: 0.860775\n",
      "[300]\ttraining's auc: 0.946755\tvalid_1's auc: 0.866804\n",
      "[400]\ttraining's auc: 0.959513\tvalid_1's auc: 0.8709\n",
      "[500]\ttraining's auc: 0.968955\tvalid_1's auc: 0.873433\n",
      "[600]\ttraining's auc: 0.976379\tvalid_1's auc: 0.874395\n",
      "[700]\ttraining's auc: 0.981828\tvalid_1's auc: 0.875142\n",
      "[800]\ttraining's auc: 0.985985\tvalid_1's auc: 0.87558\n",
      "[900]\ttraining's auc: 0.989408\tvalid_1's auc: 0.876139\n",
      "[1000]\ttraining's auc: 0.992001\tvalid_1's auc: 0.876964\n",
      "[1100]\ttraining's auc: 0.993968\tvalid_1's auc: 0.876628\n",
      "Early stopping, best iteration is:\n",
      "[1028]\ttraining's auc: 0.992604\tvalid_1's auc: 0.876984\n",
      "Partial score of fold 4 is: 0.8769838676367434\n",
      "AUC score is:  0.8769159825957257\n",
      "################### 12 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.97321\n",
      "1    0.02679\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.972047\n",
      "1    0.027953\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.935606\tvalid_1's auc: 0.840429\n",
      "[200]\ttraining's auc: 0.970835\tvalid_1's auc: 0.860938\n",
      "[300]\ttraining's auc: 0.985545\tvalid_1's auc: 0.866285\n",
      "[400]\ttraining's auc: 0.992793\tvalid_1's auc: 0.868038\n",
      "[500]\ttraining's auc: 0.996464\tvalid_1's auc: 0.868423\n",
      "[600]\ttraining's auc: 0.998197\tvalid_1's auc: 0.868629\n",
      "[700]\ttraining's auc: 0.999121\tvalid_1's auc: 0.866825\n",
      "Early stopping, best iteration is:\n",
      "[612]\ttraining's auc: 0.998348\tvalid_1's auc: 0.869122\n",
      "Partial score of fold 0 is: 0.8691219393000538\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.972132\n",
      "1    0.027868\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.976408\n",
      "1    0.023592\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.937256\tvalid_1's auc: 0.815405\n",
      "[200]\ttraining's auc: 0.970997\tvalid_1's auc: 0.830073\n",
      "[300]\ttraining's auc: 0.985148\tvalid_1's auc: 0.838702\n",
      "[400]\ttraining's auc: 0.992158\tvalid_1's auc: 0.840632\n",
      "[500]\ttraining's auc: 0.995871\tvalid_1's auc: 0.841868\n",
      "[600]\ttraining's auc: 0.997885\tvalid_1's auc: 0.843774\n",
      "Early stopping, best iteration is:\n",
      "[568]\ttraining's auc: 0.997384\tvalid_1's auc: 0.843873\n",
      "Partial score of fold 1 is: 0.8438730760779483\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.972695\n",
      "1    0.027305\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.974159\n",
      "1    0.025841\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.93439\tvalid_1's auc: 0.849266\n",
      "[200]\ttraining's auc: 0.969933\tvalid_1's auc: 0.863056\n",
      "[300]\ttraining's auc: 0.984534\tvalid_1's auc: 0.86454\n",
      "[400]\ttraining's auc: 0.992048\tvalid_1's auc: 0.865196\n",
      "[500]\ttraining's auc: 0.995847\tvalid_1's auc: 0.86522\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's auc: 0.994439\tvalid_1's auc: 0.866309\n",
      "Partial score of fold 2 is: 0.8663088487482904\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.973298\n",
      "1    0.026702\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.971735\n",
      "1    0.028265\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.937672\tvalid_1's auc: 0.849469\n",
      "[200]\ttraining's auc: 0.971187\tvalid_1's auc: 0.861404\n",
      "[300]\ttraining's auc: 0.985684\tvalid_1's auc: 0.862569\n",
      "[400]\ttraining's auc: 0.992566\tvalid_1's auc: 0.862701\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's auc: 0.989435\tvalid_1's auc: 0.863958\n",
      "Partial score of fold 3 is: 0.8639581442666264\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.973564\n",
      "1    0.026436\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.970704\n",
      "1    0.029296\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.935912\tvalid_1's auc: 0.855115\n",
      "[200]\ttraining's auc: 0.97141\tvalid_1's auc: 0.868003\n",
      "[100]\ttraining's auc: 0.969527\tvalid_1's auc: 0.924011\n",
      "[200]\ttraining's auc: 0.986865\tvalid_1's auc: 0.933707\n",
      "[300]\ttraining's auc: 0.993397\tvalid_1's auc: 0.936618\n",
      "[400]\ttraining's auc: 0.996646\tvalid_1's auc: 0.938649\n",
      "[500]\ttraining's auc: 0.998336\tvalid_1's auc: 0.939106\n",
      "[600]\ttraining's auc: 0.999227\tvalid_1's auc: 0.939083\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttraining's auc: 0.998719\tvalid_1's auc: 0.939415\n",
      "Partial score of fold 4 is: 0.9394147931814107\n",
      "AUC score is:  0.9334502480579995\n"
     ]
    }
   ],
   "source": [
    "print(\"################### 1 ###################\")\n",
    "lgb_model_130123 = Lgb_Model(train_after, test_after, features, '130123')\n",
    "print(\"################### 2 ###################\")\n",
    "lgb_model_130125 = Lgb_Model(train_after, test_after, features, '130125')\n",
    "print(\"################### 3 ###################\")\n",
    "lgb_model_130129 = Lgb_Model(train_after, test_after, features, '130129')\n",
    "print(\"################### 4 ###################\")\n",
    "lgb_model_130131 = Lgb_Model(train_after, test_after, features, '130131')\n",
    "print(\"################### 5 ###################\")\n",
    "lgb_model_140307 = Lgb_Model(train_after, test_after, features, '140307')\n",
    "print(\"################### 6 ###################\")\n",
    "lgb_model_140313 = Lgb_Model(train_after, test_after, features, '140313')\n",
    "print(\"################### 7 ###################\")\n",
    "lgb_model_140316 = Lgb_Model(train_after, test_after, features, '140316')\n",
    "print(\"################### 8 ###################\")\n",
    "lgb_model_140317 = Lgb_Model(train_after, test_after, features, '140317')\n",
    "print(\"################### 9 ###################\")\n",
    "lgb_model_140321 = Lgb_Model(train_after, test_after, features, '140321')\n",
    "print(\"################### 10 ###################\")\n",
    "lgb_model_140501 = Lgb_Model(train_after, test_after, features, '140501')\n",
    "print(\"################### 11 ###################\")\n",
    "lgb_model_140505 = Lgb_Model(train_after, test_after, features, '140505')\n",
    "print(\"################### 12 ###################\")\n",
    "lgb_model_140641 = Lgb_Model(train_after, test_after, features, '140641')\n",
    "print(\"################### 13 ###################\")\n",
    "lgb_model_140691 = Lgb_Model(train_after, test_after, features, '140691')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            13G        8.8G        4.2G         16M        675M        4.5G\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"130123_AUC: {lgb_model_130123.score}\")\n",
    "# print(f\"130125_AUC: {lgb_model_130125.score}\")\n",
    "# print(f\"130129_AUC: {lgb_model_130129.score}\")\n",
    "# print(f\"130131_AUC: {lgb_model_130131.score}\")\n",
    "# print(f\"140307_AUC: {lgb_model_140307.score}\")\n",
    "# print(f\"140313_AUC: {lgb_model_140313.score}\")\n",
    "# print(f\"140316_AUC: {lgb_model_140316.score}\")\n",
    "# print(f\"140317_AUC: {lgb_model_140317.score}\")\n",
    "# print(f\"140321_AUC: {lgb_model_140321.score}\")\n",
    "# print(f\"140501_AUC: {lgb_model_140501.score}\")\n",
    "# print(f\"140505_AUC: {lgb_model_140505.score}\")\n",
    "# print(f\"140641_AUC: {lgb_model_140641.score}\")\n",
    "# print(f\"140691_AUC: {lgb_model_140691.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96505"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_model_130123.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128376"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_model_140641.oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = pd.DataFrame({\n",
    "   \"130123\" :  lgb_model_130123.oof_pred,\n",
    "   \"130125\" :  lgb_model_130125.oof_pred,\n",
    "   \"130129\" :  lgb_model_130129.oof_pred,\n",
    "   \"130131\" :  lgb_model_130131.oof_pred,\n",
    "   \"140307\" :  lgb_model_140307.oof_pred,\n",
    "   \"140313\" :  lgb_model_140313.oof_pred,\n",
    "   \"140316\" :  lgb_model_140316.oof_pred,\n",
    "   \"140317\" :  lgb_model_140317.oof_pred,\n",
    "   \"140321\" :  lgb_model_140321.oof_pred,\n",
    "   \"140501\" :  lgb_model_140501.oof_pred,\n",
    "   \"140505\" :  lgb_model_140505.oof_pred,\n",
    "   \"140641\" :  lgb_model_140641.oof_pred,\n",
    "   \"140691\" :  lgb_model_140691.oof_pred,\n",
    " })\n",
    "\n",
    "oof_pred.to_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/{CASE}_oof_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チョコレート_AUC: 0.7359421185066743\n",
      "チューインガム_AUC: 0.8094631189535232\n",
      "米菓_AUC: 0.7362339192757318\n",
      "スナック_AUC: 0.7449715631465162\n",
      "コーヒードリンク_AUC: 0.819199520051759\n",
      "日本茶・麦茶ドリンク_AUC: 0.8087412156984022\n",
      "その他茶ドリンク_AUC: 0.7943650029118041\n",
      "水_AUC: 0.8344491198867251\n",
      "炭酸水_AUC: 0.8616581755544027\n",
      "新ジャンル_AUC: 0.8971713112835623\n",
      "RTD_AUC: 0.8769159825957257\n",
      "ビール_AUC: 0.8631077941706128\n",
      "発泡酒_AUC: 0.9334502480579995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_w = f'/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/model/{CASE}_lgb_score.txt'\n",
    "\n",
    "s1 = f\"チョコレート_AUC: {lgb_model_130123.score}\"\n",
    "s2 = f\"チューインガム_AUC: {lgb_model_130125.score}\"\n",
    "s3 = f\"米菓_AUC: {lgb_model_130129.score}\"\n",
    "s4 = f\"スナック_AUC: {lgb_model_130131.score}\"\n",
    "s5 = f\"コーヒードリンク_AUC: {lgb_model_140307.score}\"\n",
    "s6 = f\"日本茶・麦茶ドリンク_AUC: {lgb_model_140313.score}\"\n",
    "s7 = f\"その他茶ドリンク_AUC: {lgb_model_140316.score}\"\n",
    "s8 = f\"水_AUC: {lgb_model_140317.score}\"\n",
    "s9 = f\"炭酸水_AUC: {lgb_model_140321.score}\"\n",
    "s10 = f\"新ジャンル_AUC: {lgb_model_140501.score}\"\n",
    "s11 = f\"RTD_AUC: {lgb_model_140505.score}\"\n",
    "s12 = f\"ビール_AUC: {lgb_model_140641.score}\"\n",
    "s13 = f\"発泡酒_AUC: {lgb_model_140691.score}\"\n",
    "\n",
    "with open(path_w, mode='w') as f:\n",
    "    f.write(s1+\"\\n\")\n",
    "    f.write(s2+\"\\n\")\n",
    "    f.write(s3+\"\\n\")\n",
    "    f.write(s4+\"\\n\")\n",
    "    f.write(s5+\"\\n\")\n",
    "    f.write(s6+\"\\n\")\n",
    "    f.write(s7+\"\\n\")\n",
    "    f.write(s8+\"\\n\")\n",
    "    f.write(s9+\"\\n\")\n",
    "    f.write(s10+\"\\n\")\n",
    "    f.write(s11+\"\\n\")\n",
    "    f.write(s12+\"\\n\")\n",
    "    f.write(s13+\"\\n\")\n",
    "\n",
    "with open(path_w) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"130123\"] = lgb_model_130123.y_pred\n",
    "sample_submission[\"130125\"] = lgb_model_130125.y_pred\n",
    "sample_submission[\"130129\"] = lgb_model_130129.y_pred\n",
    "sample_submission[\"130131\"] = lgb_model_130131.y_pred\n",
    "sample_submission[\"140307\"] = lgb_model_140307.y_pred\n",
    "sample_submission[\"140313\"] = lgb_model_140313.y_pred\n",
    "sample_submission[\"140316\"] = lgb_model_140316.y_pred\n",
    "sample_submission[\"140317\"] = lgb_model_140317.y_pred\n",
    "sample_submission[\"140321\"] = lgb_model_140321.y_pred\n",
    "sample_submission[\"140501\"] = lgb_model_140501.y_pred\n",
    "sample_submission[\"140505\"] = lgb_model_140505.y_pred\n",
    "sample_submission[\"140641\"] = lgb_model_140641.y_pred\n",
    "sample_submission[\"140691\"] = lgb_model_140691.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130123    0\n",
       "130125    0\n",
       "130129    0\n",
       "130131    0\n",
       "140307    0\n",
       "140313    0\n",
       "140316    0\n",
       "140317    0\n",
       "140321    0\n",
       "140501    0\n",
       "140505    0\n",
       "140641    0\n",
       "140691    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96505, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SAME_PATH}\" + \"/Users/td017/kaggle-pipeline/submission/sub_\" + f\"{CASE}\" + \".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Xgb_Model(Base_Model):\n",
    "    \n",
    "#     def train_model(self, train_set, val_set):\n",
    "#         verbosity = 100 if self.verbose else 0\n",
    "#         return xgb.train(self.params, train_set, \n",
    "#                          num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "#                          verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "#     def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "#         train_set = xgb.DMatrix(x_train, y_train)\n",
    "#         val_set = xgb.DMatrix(x_val, y_val)\n",
    "#         return train_set, val_set\n",
    "    \n",
    "#     def convert_x(self, x):\n",
    "#         return xgb.DMatrix(x)\n",
    "        \n",
    "#     def get_params(self):\n",
    "#         params = {'objective': 'binary:logistic',\n",
    "#          'learning_rate': 0.01,\n",
    "#         'eval_metric': 'logloss',\n",
    "#         #'num_class': 9,\n",
    "#         'max_depth': 12,\n",
    "#         'eta': 0.1,\n",
    "#         'min_child_weight': 32,\n",
    "#         'subsample': 0.9,\n",
    "#         'colsample_bytree': 0.8,\n",
    "#         'silent': 1,\n",
    "#         'random_state': 71,\n",
    "#         #'num_round': 10000,\n",
    "#         'early_stopping_rounds': 10}\n",
    "        \n",
    "#         #{'colsample_bytree': 0.8,                 \n",
    "#             #'learning_rate': 0.01,\n",
    "#             #'max_depth': 7,#10\n",
    "# #             'subsample': 1,\n",
    "# #             'objective':'reg:squarederror',\n",
    "# #             #'eval_metric':'rmse',\n",
    "# #             'min_child_weight':32,#16,\n",
    "# #             'gamma':0.25,\n",
    "# #             'n_estimators':5000}\n",
    "\n",
    "#         return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"################### 1 ###################\")\n",
    "# xgb_model_130123 = Xgb_Model(train_after, test_after, features, '130123')\n",
    "# print(\"################### 2 ###################\")\n",
    "# xgb_model_130125 = Xgb_Model(train_after, test_after, features, '130125')\n",
    "# print(\"################### 3 ###################\")\n",
    "# xgb_model_130129 = Xgb_Model(train_after, test_after, features, '130129')\n",
    "# print(\"################### 4 ###################\")\n",
    "# xgb_model_130131 = Xgb_Model(train_after, test_after, features, '130131')\n",
    "# print(\"################### 5 ###################\")\n",
    "# xgb_model_140307 = Xgb_Model(train_after, test_after, features, '140307')\n",
    "# print(\"################### 6 ###################\")\n",
    "# xgb_model_140313 = Xgb_Model(train_after, test_after, features, '140313')\n",
    "# print(\"################### 7 ###################\")\n",
    "# xgb_model_140316 = Xgb_Model(train_after, test_after, features, '140316')\n",
    "# print(\"################### 8 ###################\")\n",
    "# xgb_model_140317 = Xgb_Model(train_after, test_after, features, '140317')\n",
    "# print(\"################### 9 ###################\")\n",
    "# xgb_model_140321 = Xgb_Model(train_after, test_after, features, '140321')\n",
    "# print(\"################### 10 ###################\")\n",
    "# xgb_model_140501 = Xgb_Model(train_after, test_after, features, '140501')\n",
    "# print(\"################### 11 ###################\")\n",
    "# xgb_model_140505 = Xgb_Model(train_after, test_after, features, '140505')\n",
    "# print(\"################### 12 ###################\")\n",
    "# xgb_model_140641 = Xgb_Model(train_after, test_after, features, '140641')\n",
    "# print(\"################### 13 ###################\")\n",
    "# xgb_model_140691 = Xgb_Model(train_after, test_after, features, '140691')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"130123_AUC: {xgb_model_130123.score}\")\n",
    "# print(f\"130125_AUC: {xgb_model_130125.score}\")\n",
    "# print(f\"130129_AUC: {xgb_model_130129.score}\")\n",
    "# print(f\"130131_AUC: {xgb_model_130131.score}\")\n",
    "# print(f\"140307_AUC: {xgb_model_140307.score}\")\n",
    "# print(f\"140313_AUC: {xgb_model_140313.score}\")\n",
    "# print(f\"140316_AUC: {xgb_model_140316.score}\")\n",
    "# print(f\"140317_AUC: {xgb_model_140317.score}\")\n",
    "# print(f\"140321_AUC: {xgb_model_140321.score}\")\n",
    "# print(f\"140501_AUC: {xgb_model_140501.score}\")\n",
    "# print(f\"140505_AUC: {xgb_model_140505.score}\")\n",
    "# print(f\"140641_AUC: {xgb_model_140641.score}\")\n",
    "# print(f\"140691_AUC: {xgb_model_140691.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_w = f'/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir0/code/Users/td017/kaggle-pipeline/model/{CASE}_xgb_score.txt'\n",
    "\n",
    "# s1 = f\"130123_AUC: {xgb_model_130123.score}\"\n",
    "# s2 = f\"130125_AUC: {xgb_model_130125.score}\"\n",
    "# s3 = f\"130129_AUC: {xgb_model_130129.score}\"\n",
    "# s4 = f\"130131_AUC: {xgb_model_130131.score}\"\n",
    "# s5 = f\"140307_AUC: {xgb_model_140307.score}\"\n",
    "# s6 = f\"140313_AUC: {xgb_model_140313.score}\"\n",
    "# s7 = f\"140316_AUC: {xgb_model_140316.score}\"\n",
    "# s8 = f\"140317_AUC: {xgb_model_140317.score}\"\n",
    "# s9 = f\"140321_AUC: {xgb_model_140321.score}\"\n",
    "# s10 = f\"140501_AUC: {xgb_model_140501.score}\"\n",
    "# s11 = f\"140505_AUC: {xgb_model_140505.score}\"\n",
    "# s12 = f\"140641_AUC: {xgb_model_140641.score}\"\n",
    "# s13 = f\"140691_AUC: {xgb_model_140691.score}\"\n",
    "\n",
    "# with open(path_w, mode='w') as f:\n",
    "#     f.write(s1+\"\\n\")\n",
    "#     f.write(s2+\"\\n\")\n",
    "#     f.write(s3+\"\\n\")\n",
    "#     f.write(s4+\"\\n\")\n",
    "#     f.write(s5+\"\\n\")\n",
    "#     f.write(s6+\"\\n\")\n",
    "#     f.write(s7+\"\\n\")\n",
    "#     f.write(s8+\"\\n\")\n",
    "#     f.write(s9+\"\\n\")\n",
    "#     f.write(s10+\"\\n\")\n",
    "#     f.write(s11+\"\\n\")\n",
    "#     f.write(s12+\"\\n\")\n",
    "#     f.write(s13+\"\\n\")\n",
    "\n",
    "# with open(path_w) as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stackingのような何か"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class Base_Model_Second(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, target,categoricals=[], n_splits=5, verbose=True, group = \"months\"):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = target\n",
    "        self.X = self.train_df.drop(target,axis=1)\n",
    "        self.y = self.train_df[target]\n",
    "        self.group = group\n",
    "        self.groups = np.array(self.train_df[self.group].values)\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model,self.oof_pred = self.fit()\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        #cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "            labels_num = np.max(y) + 1\n",
    "            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "            y_distr = Counter()\n",
    "            for label, g in zip(y, groups):\n",
    "                y_counts_per_group[g][label] += 1\n",
    "                y_distr[label] += 1\n",
    "\n",
    "            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "            groups_per_fold = defaultdict(set)\n",
    "\n",
    "            # fold毎のaccuracy_groupの分布を計算する関数\n",
    "            def eval_y_counts_per_fold(y_counts, fold):\n",
    "                y_counts_per_fold[fold] += y_counts\n",
    "                std_per_label = []\n",
    "                for label in range(labels_num):\n",
    "                    label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "                    std_per_label.append(label_std)\n",
    "                y_counts_per_fold[fold] -= y_counts\n",
    "                return np.mean(std_per_label)\n",
    "\n",
    "            groups_and_y_counts = list(y_counts_per_group.items())\n",
    "            random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "\n",
    "                best_fold = None\n",
    "                min_eval = None\n",
    "                # kはfold数\n",
    "                for i in range(k):\n",
    "                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "\n",
    "                    if min_eval is None or fold_eval < min_eval:\n",
    "                        min_eval = fold_eval\n",
    "                        best_fold = i\n",
    "                y_counts_per_fold[best_fold] += y_counts\n",
    "                groups_per_fold[best_fold].add(g)\n",
    "\n",
    "            all_groups = set(groups)\n",
    "            for i in range(k):\n",
    "                train_groups = all_groups - groups_per_fold[i]\n",
    "                test_groups = groups_per_fold[i]\n",
    "\n",
    "                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "                yield train_indices, test_indices\n",
    "        \n",
    "        return stratified_group_k_fold(self.X, self.y, self.groups, k=5)\n",
    "        #return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(self.train_df), ))\n",
    "        y_pred = np.zeros((len(self.test_df), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            \n",
    "            #Check Stratified k-fold\n",
    "            print('Check Stratified k-fold')\n",
    "            print('y_train.value_counts(normalize=True)')\n",
    "            print(y_train.value_counts(normalize=True,sort=False))\n",
    "            print('y_val.value_counts(normalize=True)')\n",
    "            print(y_val.value_counts(normalize=True,sort=False))\n",
    "            check_tr = self.train_df.iloc[train_idx,:].copy()\n",
    "            check_vl = self.train_df.iloc[val_idx,:].copy()\n",
    "            print('')\n",
    "\n",
    "            #Check Group k-fold\n",
    "            print('Check Group k-fold')\n",
    "            check_dup_tr = list(check_tr[self.group].unique())\n",
    "            check_dup_vl = list(check_vl[self.group].unique())\n",
    "            check_dup_diff = set(check_dup_tr) - set(check_dup_vl)\n",
    "            print('len(check_dup_tr)')\n",
    "            print(len(check_dup_tr))\n",
    "            print('len(check_dup_diff)')\n",
    "            print(len(check_dup_diff))\n",
    "            print('Check SAME Number!')\n",
    "            print('')\n",
    "            \n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, roc_auc_score(y_val, oof_pred[val_idx])))\n",
    "            score = roc_auc_score(self.train_df[self.target], oof_pred)\n",
    "            \n",
    "            #特徴量重要度の計算\n",
    "            fold_importance = pd.DataFrame(list(zip(x_train.columns, model.feature_importance())),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            fold_importance.rename(columns={'importance': fold},inplace=True)\n",
    "            if fold == 0:\n",
    "                self.feature_importances = fold_importance\n",
    "            else:\n",
    "                self.feature_importances = pd.merge(self.feature_importances,fold_importance,on='feature')\n",
    "         \n",
    "        #特徴量重要度の計算\n",
    "        self.feature_importances.set_index(\"feature\",inplace=True)\n",
    "        self.feature_importances[\"mean\"] = self.feature_importances.mean(axis='columns')\n",
    "        self.feature_importances.sort_values(\"mean\",ascending=False,inplace=True)\n",
    "        #print(self.feature_importances)\n",
    "        #特徴量重要度の保存\n",
    "        self.feature_importances.to_csv(f'../model/FTI/{CASE}_{rename_dict[self.target]}_second_FTI.csv')\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('AUC score is: ', score)\n",
    "        return y_pred, score, model, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model_Second(Base_Model_Second):\n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'binary',\n",
    "                    'metric': 'auc',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 7,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred_stack = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/{CASE}_oof_pred.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050872</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>0.041477</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059787</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.156954</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338206</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.362829</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.142816</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195282</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.278741</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.012095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.245784</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.304213</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.112828</td>\n",
       "      <td>0.161048</td>\n",
       "      <td>0.023946</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.162686</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>0.406733</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.077509</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.049291</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>0.430345</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.015905</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.154875</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.037409</td>\n",
       "      <td>0.010224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.445211</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.064876</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.154743</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.127770</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>0.158469</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.329731</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.140179</td>\n",
       "      <td>0.358181</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.044895</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.071135</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.094150</td>\n",
       "      <td>0.088935</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.021272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.030695</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.080671</td>\n",
       "      <td>0.239791</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.015185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.085648</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.051223</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.332015</td>\n",
       "      <td>0.036971</td>\n",
       "      <td>0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.019827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.108195</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.051741</td>\n",
       "      <td>0.172659</td>\n",
       "      <td>0.043973</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.010063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.091637</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>0.107695</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>0.033747</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.131068</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.013062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.079462</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.055269</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.267417</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.240096</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>0.092005</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.853982</td>\n",
       "      <td>0.034980</td>\n",
       "      <td>0.045572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.110523</td>\n",
       "      <td>0.012884</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>0.149248</td>\n",
       "      <td>0.055920</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.034374</td>\n",
       "      <td>0.031445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.132535</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>0.100878</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.056744</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.021901</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.013741</td>\n",
       "      <td>0.083898</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.044003</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.130349</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.053214</td>\n",
       "      <td>0.218680</td>\n",
       "      <td>0.050599</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.133364</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.065128</td>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.014802</td>\n",
       "      <td>0.083328</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.058762</td>\n",
       "      <td>0.014321</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.089071</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.089306</td>\n",
       "      <td>0.387907</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.010814</td>\n",
       "      <td>0.123888</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.010390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.047415</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.020364</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.152550</td>\n",
       "      <td>0.007913</td>\n",
       "      <td>0.070865</td>\n",
       "      <td>0.226752</td>\n",
       "      <td>0.270927</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.091375</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.114695</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>0.052021</td>\n",
       "      <td>0.039587</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.030713</td>\n",
       "      <td>0.007729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.129068</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.370652</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>0.010723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.046306</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.042095</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.056775</td>\n",
       "      <td>0.051704</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.026106</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.008813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.120030</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.132121</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.008611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.181262</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.044494</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.018458</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.426398</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.240869</td>\n",
       "      <td>0.403755</td>\n",
       "      <td>0.024503</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.045456</td>\n",
       "      <td>0.421024</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.084926</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.083490</td>\n",
       "      <td>0.168748</td>\n",
       "      <td>0.054903</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.037613</td>\n",
       "      <td>0.048948</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.063461</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.059310</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>0.084440</td>\n",
       "      <td>0.080559</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.004590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.097041</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.740598</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.228457</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.247445</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.056197</td>\n",
       "      <td>0.157943</td>\n",
       "      <td>0.091249</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>0.019713</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>0.237816</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.175676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.108536</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>0.132221</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.087336</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.027739</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.054712</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.119961</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.041846</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.011506</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.066380</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.004763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.041571</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.449107</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.117310</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.165995</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.048615</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>0.102090</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128326</th>\n",
       "      <td>0.182608</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.008779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128327</th>\n",
       "      <td>0.029616</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.018189</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.004079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128328</th>\n",
       "      <td>0.115443</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.215025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128329</th>\n",
       "      <td>0.361207</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>0.371227</td>\n",
       "      <td>0.019031</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.003976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128330</th>\n",
       "      <td>0.159749</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.140843</td>\n",
       "      <td>0.236245</td>\n",
       "      <td>0.172761</td>\n",
       "      <td>0.038495</td>\n",
       "      <td>0.048271</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.074024</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.044146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128331</th>\n",
       "      <td>0.031319</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.017135</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.072064</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128332</th>\n",
       "      <td>0.140209</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.175157</td>\n",
       "      <td>0.174959</td>\n",
       "      <td>0.081311</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.006518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128333</th>\n",
       "      <td>0.328703</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.587862</td>\n",
       "      <td>0.203847</td>\n",
       "      <td>0.048854</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.114464</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.062541</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.064723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128334</th>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.028952</td>\n",
       "      <td>0.096190</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128335</th>\n",
       "      <td>0.102942</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>0.063706</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128336</th>\n",
       "      <td>0.206052</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.209772</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128337</th>\n",
       "      <td>0.369452</td>\n",
       "      <td>0.019703</td>\n",
       "      <td>0.073867</td>\n",
       "      <td>0.346731</td>\n",
       "      <td>0.270392</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128338</th>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.826453</td>\n",
       "      <td>0.076340</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128339</th>\n",
       "      <td>0.193393</td>\n",
       "      <td>0.119514</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.091824</td>\n",
       "      <td>0.116056</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.070297</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128340</th>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.201104</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128341</th>\n",
       "      <td>0.177033</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.042360</td>\n",
       "      <td>0.554656</td>\n",
       "      <td>0.077438</td>\n",
       "      <td>0.052845</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.049452</td>\n",
       "      <td>0.032126</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.004820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128342</th>\n",
       "      <td>0.163941</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.085191</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128343</th>\n",
       "      <td>0.071646</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>0.038550</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128344</th>\n",
       "      <td>0.087220</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>0.101363</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.038577</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.008786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128345</th>\n",
       "      <td>0.081844</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.078404</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128346</th>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.060059</td>\n",
       "      <td>0.353954</td>\n",
       "      <td>0.026094</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.051760</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.049811</td>\n",
       "      <td>0.016941</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128347</th>\n",
       "      <td>0.027909</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.059094</td>\n",
       "      <td>0.043873</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128348</th>\n",
       "      <td>0.104168</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128349</th>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.038935</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.024107</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.006926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128350</th>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>0.098040</td>\n",
       "      <td>0.075941</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128351</th>\n",
       "      <td>0.091829</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.122711</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.098994</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128352</th>\n",
       "      <td>0.062712</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128353</th>\n",
       "      <td>0.315367</td>\n",
       "      <td>0.011899</td>\n",
       "      <td>0.087889</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.165185</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.007432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128354</th>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.080956</td>\n",
       "      <td>0.167820</td>\n",
       "      <td>0.070777</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.069604</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.339753</td>\n",
       "      <td>0.152753</td>\n",
       "      <td>0.029955</td>\n",
       "      <td>0.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128355</th>\n",
       "      <td>0.083121</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.057254</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.030409</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.009050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128356</th>\n",
       "      <td>0.131014</td>\n",
       "      <td>0.485598</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>0.064654</td>\n",
       "      <td>0.152783</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>0.095462</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.048703</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128357</th>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128358</th>\n",
       "      <td>0.474974</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.133402</td>\n",
       "      <td>0.316983</td>\n",
       "      <td>0.104647</td>\n",
       "      <td>0.166687</td>\n",
       "      <td>0.342469</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128359</th>\n",
       "      <td>0.064281</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.094157</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.113315</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128360</th>\n",
       "      <td>0.180414</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.253977</td>\n",
       "      <td>0.124917</td>\n",
       "      <td>0.415832</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.046937</td>\n",
       "      <td>0.216458</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128361</th>\n",
       "      <td>0.119209</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.035839</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128362</th>\n",
       "      <td>0.076027</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.108558</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.110573</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128363</th>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.032464</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.041289</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>0.003671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128364</th>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.029338</td>\n",
       "      <td>0.076565</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.490533</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128365</th>\n",
       "      <td>0.070959</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>0.105198</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.111429</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128366</th>\n",
       "      <td>0.131615</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>0.055775</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.060603</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128367</th>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>0.335020</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128368</th>\n",
       "      <td>0.143410</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0.161570</td>\n",
       "      <td>0.119190</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.069932</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128369</th>\n",
       "      <td>0.087045</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.037134</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128370</th>\n",
       "      <td>0.042068</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.094983</td>\n",
       "      <td>0.112789</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128371</th>\n",
       "      <td>0.062619</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.144918</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128372</th>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.018641</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.004024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128373</th>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.084490</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128374</th>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.029498</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128375</th>\n",
       "      <td>0.064535</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.030299</td>\n",
       "      <td>0.032823</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128376 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          130123    130125    130129    130131    140307    140313    140316  \\\n",
       "0       0.050872  0.017311  0.041477  0.073584  0.018275  0.003804  0.006644   \n",
       "1       0.059787  0.004534  0.056330  0.141299  0.011082  0.016181  0.022297   \n",
       "2       0.104315  0.007874  0.049998  0.156954  0.021688  0.008820  0.010605   \n",
       "3       0.338206  0.013345  0.362829  0.349630  0.142816  0.008066  0.013548   \n",
       "4       0.195282  0.007186  0.053891  0.278741  0.112796  0.014341  0.014919   \n",
       "5       0.245784  0.003997  0.055868  0.304213  0.046071  0.014985  0.003919   \n",
       "6       0.162686  0.008411  0.040557  0.406733  0.047992  0.037083  0.017448   \n",
       "7       0.077509  0.014484  0.049291  0.123494  0.430345  0.012691  0.012514   \n",
       "8       0.120237  0.005436  0.072606  0.154875  0.030249  0.014319  0.009184   \n",
       "9       0.445211  0.003174  0.064876  0.056398  0.005214  0.006889  0.014072   \n",
       "10      0.154743  0.008397  0.127770  0.273776  0.158469  0.015086  0.059640   \n",
       "11      0.329731  0.016022  0.140179  0.358181  0.201433  0.017832  0.024636   \n",
       "12      0.071135  0.005721  0.045026  0.094150  0.088935  0.015833  0.006330   \n",
       "13      0.030695  0.005168  0.062937  0.048715  0.032008  0.002569  0.004949   \n",
       "14      0.085648  0.011987  0.051223  0.100957  0.046434  0.021300  0.004069   \n",
       "15      0.026087  0.001593  0.022266  0.055308  0.030315  0.009086  0.081258   \n",
       "16      0.108195  0.012328  0.051741  0.172659  0.043973  0.012123  0.004089   \n",
       "17      0.091637  0.008215  0.036490  0.107695  0.040628  0.033747  0.002942   \n",
       "18      0.079462  0.013546  0.016775  0.055269  0.011804  0.267417  0.020180   \n",
       "19      0.052033  0.001521  0.036616  0.092005  0.003803  0.005296  0.002839   \n",
       "20      0.110523  0.012884  0.118443  0.149248  0.055920  0.091661  0.009356   \n",
       "21      0.132535  0.007117  0.057451  0.100878  0.012860  0.004993  0.005239   \n",
       "22      0.044064  0.004822  0.012261  0.052079  0.021901  0.006924  0.003857   \n",
       "23      0.049766  0.031195  0.013741  0.083898  0.022228  0.014562  0.007812   \n",
       "24      0.130349  0.005515  0.053214  0.218680  0.050599  0.012260  0.015862   \n",
       "25      0.041997  0.005737  0.014802  0.083328  0.007183  0.007258  0.003946   \n",
       "26      0.089071  0.002509  0.089306  0.387907  0.052013  0.012204  0.009384   \n",
       "27      0.058373  0.002151  0.015419  0.034828  0.047415  0.022432  0.025637   \n",
       "28      0.152550  0.007913  0.070865  0.226752  0.270927  0.015215  0.037757   \n",
       "29      0.114695  0.009462  0.052021  0.039587  0.007582  0.022228  0.004628   \n",
       "30      0.049930  0.002619  0.036736  0.072011  0.129068  0.008314  0.001692   \n",
       "31      0.023662  0.004232  0.010545  0.036549  0.046306  0.004882  0.006265   \n",
       "32      0.042095  0.004438  0.056775  0.051704  0.004362  0.005965  0.005667   \n",
       "33      0.120030  0.003876  0.053126  0.132121  0.023786  0.003879  0.004377   \n",
       "34      0.181262  0.007490  0.075766  0.088110  0.016376  0.007979  0.010141   \n",
       "35      0.044494  0.002565  0.018458  0.040985  0.024500  0.019401  0.007616   \n",
       "36      0.426398  0.003275  0.240869  0.403755  0.024503  0.011376  0.004787   \n",
       "37      0.055114  0.003451  0.076470  0.081784  0.029172  0.004335  0.002205   \n",
       "38      0.084926  0.008593  0.083490  0.168748  0.054903  0.056378  0.007930   \n",
       "39      0.063461  0.026459  0.059310  0.107529  0.084440  0.080559  0.007233   \n",
       "40      0.097041  0.004729  0.025560  0.093347  0.005136  0.009258  0.002307   \n",
       "41      0.247445  0.031406  0.056197  0.157943  0.091249  0.083432  0.026618   \n",
       "42      0.108536  0.003834  0.021009  0.132221  0.015957  0.006618  0.008846   \n",
       "43      0.065213  0.010614  0.020525  0.027739  0.006999  0.008105  0.012136   \n",
       "44      0.054712  0.001758  0.013869  0.006130  0.001627  0.011199  0.005505   \n",
       "45      0.119961  0.007446  0.025388  0.041846  0.016473  0.011506  0.012192   \n",
       "46      0.124697  0.002842  0.079790  0.113641  0.008151  0.007054  0.020935   \n",
       "47      0.041571  0.002497  0.016256  0.034763  0.008472  0.003298  0.003421   \n",
       "48      0.117310  0.010108  0.032292  0.165995  0.022044  0.013626  0.004680   \n",
       "49      0.038395  0.048615  0.019723  0.102090  0.006603  0.022624  0.012099   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "128326  0.182608  0.017210  0.040203  0.142071  0.018885  0.010811  0.004965   \n",
       "128327  0.029616  0.004978  0.018189  0.037605  0.020468  0.019271  0.017743   \n",
       "128328  0.115443  0.004083  0.009668  0.050897  0.018507  0.014775  0.004093   \n",
       "128329  0.361207  0.001568  0.055025  0.371227  0.019031  0.030463  0.002269   \n",
       "128330  0.159749  0.023554  0.061008  0.140843  0.236245  0.172761  0.038495   \n",
       "128331  0.031319  0.004626  0.018351  0.074596  0.038179  0.017135  0.003911   \n",
       "128332  0.140209  0.007649  0.175157  0.174959  0.081311  0.017088  0.002829   \n",
       "128333  0.328703  0.005382  0.150602  0.587862  0.203847  0.048854  0.029287   \n",
       "128334  0.048878  0.001515  0.028952  0.096190  0.018022  0.025441  0.001869   \n",
       "128335  0.102942  0.005178  0.024843  0.102086  0.047928  0.063706  0.005507   \n",
       "128336  0.206052  0.002510  0.053340  0.209772  0.018270  0.008711  0.002208   \n",
       "128337  0.369452  0.019703  0.073867  0.346731  0.270392  0.018005  0.014600   \n",
       "128338  0.012018  0.001678  0.019130  0.081300  0.826453  0.076340  0.012071   \n",
       "128339  0.193393  0.119514  0.035135  0.091824  0.116056  0.024126  0.006173   \n",
       "128340  0.107019  0.004268  0.201104  0.151916  0.027565  0.008575  0.003684   \n",
       "128341  0.177033  0.012142  0.042360  0.554656  0.077438  0.052845  0.008142   \n",
       "128342  0.163941  0.003438  0.085191  0.100509  0.010125  0.023560  0.004733   \n",
       "128343  0.071646  0.002274  0.020181  0.075824  0.038550  0.053979  0.029098   \n",
       "128344  0.087220  0.002877  0.031986  0.101363  0.069199  0.037081  0.009888   \n",
       "128345  0.081844  0.011432  0.040643  0.078404  0.196273  0.007174  0.001923   \n",
       "128346  0.115611  0.004014  0.060059  0.353954  0.026094  0.017191  0.051760   \n",
       "128347  0.027909  0.001712  0.059094  0.043873  0.030675  0.010720  0.027965   \n",
       "128348  0.104168  0.007730  0.027314  0.061237  0.026125  0.010212  0.001226   \n",
       "128349  0.040175  0.001964  0.022721  0.038935  0.040833  0.008081  0.003325   \n",
       "128350  0.081228  0.017107  0.098040  0.075941  0.021346  0.009887  0.007825   \n",
       "128351  0.091829  0.006132  0.122711  0.109221  0.038532  0.009236  0.005449   \n",
       "128352  0.062712  0.003011  0.041615  0.054622  0.041594  0.007723  0.003102   \n",
       "128353  0.315367  0.011899  0.087889  0.293517  0.145801  0.030960  0.009863   \n",
       "128354  0.194000  0.017859  0.080956  0.167820  0.070777  0.051768  0.132184   \n",
       "128355  0.083121  0.012090  0.044172  0.057254  0.027555  0.010988  0.000808   \n",
       "128356  0.131014  0.485598  0.058647  0.064654  0.152783  0.016301  0.004648   \n",
       "128357  0.038213  0.004747  0.064489  0.088256  0.017295  0.010257  0.003402   \n",
       "128358  0.474974  0.017180  0.133402  0.316983  0.104647  0.166687  0.342469   \n",
       "128359  0.064281  0.002975  0.019836  0.094157  0.019087  0.016226  0.113315   \n",
       "128360  0.180414  0.007823  0.253977  0.124917  0.415832  0.147365  0.010688   \n",
       "128361  0.119209  0.006496  0.035839  0.093653  0.030696  0.021488  0.001251   \n",
       "128362  0.076027  0.012308  0.062109  0.108558  0.176560  0.028433  0.012216   \n",
       "128363  0.037208  0.002406  0.032464  0.024261  0.023314  0.008460  0.004429   \n",
       "128364  0.072865  0.006671  0.029338  0.076565  0.033028  0.013242  0.004836   \n",
       "128365  0.070959  0.003065  0.026273  0.105198  0.020862  0.013709  0.003675   \n",
       "128366  0.131615  0.028443  0.072257  0.134024  0.055775  0.020725  0.017650   \n",
       "128367  0.347074  0.002480  0.060051  0.335020  0.018690  0.028963  0.004368   \n",
       "128368  0.143410  0.029159  0.149643  0.161570  0.119190  0.020112  0.002926   \n",
       "128369  0.087045  0.006209  0.037134  0.129775  0.040700  0.033808  0.014150   \n",
       "128370  0.042068  0.008239  0.040072  0.094983  0.112789  0.024363  0.012738   \n",
       "128371  0.062619  0.017836  0.026335  0.144918  0.061358  0.024308  0.039103   \n",
       "128372  0.053367  0.001135  0.019585  0.026083  0.018641  0.016951  0.006705   \n",
       "128373  0.046734  0.002995  0.056600  0.084490  0.129103  0.009543  0.027797   \n",
       "128374  0.020906  0.004887  0.012652  0.050600  0.029498  0.007358  0.003779   \n",
       "128375  0.064535  0.001056  0.035537  0.044920  0.015711  0.011092  0.016079   \n",
       "\n",
       "          140317    140321    140501    140505    140641    140691  \n",
       "0       0.004631  0.004888  0.003786  0.012156  0.004168  0.001069  \n",
       "1       0.007875  0.001164  0.004097  0.010667  0.007253  0.000882  \n",
       "2       0.009418  0.002276  0.006773  0.024176  0.009391  0.003056  \n",
       "3       0.008125  0.002093  0.009140  0.014985  0.019850  0.004192  \n",
       "4       0.006282  0.008948  0.024500  0.113041  0.017420  0.012095  \n",
       "5       0.003126  0.000989  0.112828  0.161048  0.023946  0.001189  \n",
       "6       0.002924  0.002124  0.152551  0.033947  0.023529  0.006612  \n",
       "7       0.005144  0.004673  0.001339  0.012398  0.015905  0.001981  \n",
       "8       0.009507  0.002865  0.022906  0.057588  0.037409  0.010224  \n",
       "9       0.022663  0.003887  0.010428  0.012758  0.078165  0.000301  \n",
       "10      0.007839  0.001831  0.004131  0.008221  0.022934  0.001229  \n",
       "11      0.009450  0.002068  0.007196  0.032124  0.044895  0.001860  \n",
       "12      0.014640  0.003199  0.004550  0.047354  0.010384  0.021272  \n",
       "13      0.003165  0.001414  0.080671  0.239791  0.017496  0.015185  \n",
       "14      0.003619  0.000872  0.009457  0.332015  0.036971  0.004794  \n",
       "15      0.019512  0.002669  0.026148  0.436384  0.011094  0.019827  \n",
       "16      0.011919  0.010014  0.034511  0.130225  0.021500  0.010063  \n",
       "17      0.005678  0.002415  0.064378  0.131068  0.017753  0.013062  \n",
       "18      0.004365  0.000976  0.007210  0.240096  0.006636  0.001009  \n",
       "19      0.004658  0.001590  0.007458  0.853982  0.034980  0.045572  \n",
       "20      0.010053  0.006384  0.007986  0.071076  0.034374  0.031445  \n",
       "21      0.002605  0.001398  0.006154  0.056744  0.004344  0.002047  \n",
       "22      0.003547  0.001080  0.003542  0.005310  0.011223  0.000395  \n",
       "23      0.005461  0.001777  0.022468  0.044003  0.006496  0.004714  \n",
       "24      0.007585  0.002302  0.133364  0.040397  0.065128  0.011496  \n",
       "25      0.004004  0.001511  0.058762  0.014321  0.003510  0.001922  \n",
       "26      0.007395  0.005364  0.010814  0.123888  0.030056  0.010390  \n",
       "27      0.156100  0.020364  0.005247  0.015820  0.034937  0.000826  \n",
       "28      0.003407  0.001243  0.060960  0.091375  0.005839  0.001076  \n",
       "29      0.010839  0.004243  0.003297  0.025901  0.030713  0.007729  \n",
       "30      0.005940  0.002667  0.019878  0.370652  0.184674  0.010723  \n",
       "31      0.007231  0.000940  0.017467  0.015783  0.035302  0.000397  \n",
       "32      0.003329  0.026106  0.006478  0.011927  0.009349  0.008813  \n",
       "33      0.006733  0.016208  0.008095  0.019914  0.007030  0.008611  \n",
       "34      0.013340  0.005402  0.005765  0.013418  0.325551  0.013237  \n",
       "35      0.009817  0.000760  0.001828  0.004227  0.006881  0.001942  \n",
       "36      0.002981  0.001053  0.016160  0.025630  0.010900  0.000418  \n",
       "37      0.003184  0.002003  0.045456  0.421024  0.024555  0.003808  \n",
       "38      0.014738  0.002375  0.007684  0.037613  0.048948  0.005508  \n",
       "39      0.005456  0.001182  0.013979  0.010209  0.032809  0.004590  \n",
       "40      0.006187  0.000632  0.740598  0.498759  0.228457  0.002571  \n",
       "41      0.019713  0.006345  0.197041  0.237816  0.044499  0.175676  \n",
       "42      0.004621  0.002328  0.004197  0.087336  0.014724  0.004115  \n",
       "43      0.007120  0.001411  0.002800  0.012232  0.017406  0.003304  \n",
       "44      0.093796  0.001330  0.000521  0.000803  0.002026  0.000755  \n",
       "45      0.006090  0.002686  0.010785  0.066380  0.028779  0.004763  \n",
       "46      0.004421  0.001251  0.002424  0.007500  0.016930  0.000940  \n",
       "47      0.003388  0.001936  0.006145  0.449107  0.003922  0.007653  \n",
       "48      0.004918  0.001613  0.001973  0.006076  0.005038  0.000577  \n",
       "49      0.002641  0.001108  0.001941  0.005182  0.002502  0.001098  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "128326  0.002831  0.008750  0.005382  0.054562  0.011925  0.008779  \n",
       "128327  0.000927  0.003359  0.004339  0.008718  0.002831  0.004079  \n",
       "128328  0.002652  0.000801  0.005647  0.013265  0.004359  0.215025  \n",
       "128329  0.001413  0.000426  0.002032  0.015847  0.003152  0.003976  \n",
       "128330  0.048271  0.004147  0.049274  0.074024  0.015709  0.044146  \n",
       "128331  0.008555  0.001532  0.008106  0.072064  0.006922  0.005568  \n",
       "128332  0.011686  0.026967  0.018713  0.100377  0.029920  0.006518  \n",
       "128333  0.114464  0.009552  0.017115  0.062541  0.016116  0.064723  \n",
       "128334  0.004293  0.001526  0.009177  0.007198  0.007036  0.001157  \n",
       "128335  0.010356  0.001244  0.014493  0.007074  0.001163  0.003044  \n",
       "128336  0.002318  0.002855  0.004610  0.012642  0.002174  0.001671  \n",
       "128337  0.009546  0.002139  0.006515  0.006562  0.003973  0.000612  \n",
       "128338  0.002413  0.002636  0.009468  0.021982  0.177396  0.001938  \n",
       "128339  0.007543  0.002935  0.012451  0.070297  0.006340  0.005438  \n",
       "128340  0.002131  0.001327  0.008145  0.023784  0.002128  0.006269  \n",
       "128341  0.022017  0.002954  0.049452  0.032126  0.012837  0.004820  \n",
       "128342  0.006186  0.006609  0.004445  0.010467  0.010489  0.000863  \n",
       "128343  0.002970  0.002910  0.007304  0.012620  0.002342  0.002811  \n",
       "128344  0.008944  0.001384  0.038577  0.040436  0.005771  0.008786  \n",
       "128345  0.055254  0.002870  0.013406  0.015612  0.004984  0.004386  \n",
       "128346  0.038437  0.001395  0.008744  0.049811  0.016941  0.002285  \n",
       "128347  0.014201  0.001461  0.002448  0.004171  0.001916  0.001022  \n",
       "128348  0.004078  0.003409  0.002708  0.017346  0.003463  0.001632  \n",
       "128349  0.003085  0.003084  0.024107  0.037300  0.003321  0.006926  \n",
       "128350  0.004662  0.003344  0.006390  0.013749  0.003901  0.001024  \n",
       "128351  0.005828  0.003093  0.015806  0.098994  0.008172  0.013121  \n",
       "128352  0.003693  0.001993  0.003651  0.007760  0.001530  0.006040  \n",
       "128353  0.008941  0.004285  0.009302  0.165185  0.011576  0.007432  \n",
       "128354  0.069604  0.012059  0.339753  0.152753  0.029955  0.008456  \n",
       "128355  0.001202  0.001206  0.010862  0.030409  0.009747  0.009050  \n",
       "128356  0.095462  0.002822  0.010128  0.048703  0.001470  0.001046  \n",
       "128357  0.034794  0.001544  0.004573  0.006151  0.001621  0.001261  \n",
       "128358  0.005899  0.012589  0.006583  0.156346  0.006832  0.005185  \n",
       "128359  0.005772  0.004142  0.005085  0.030021  0.011168  0.001554  \n",
       "128360  0.007195  0.003420  0.011587  0.046937  0.216458  0.001777  \n",
       "128361  0.005103  0.001148  0.025825  0.012788  0.006733  0.003034  \n",
       "128362  0.011303  0.007831  0.110573  0.135838  0.037125  0.007718  \n",
       "128363  0.004973  0.004629  0.041289  0.035399  0.017175  0.003671  \n",
       "128364  0.003087  0.004729  0.490533  0.009289  0.006422  0.002351  \n",
       "128365  0.005285  0.001644  0.111429  0.026332  0.017235  0.001615  \n",
       "128366  0.004399  0.006754  0.005754  0.060603  0.004414  0.002576  \n",
       "128367  0.004346  0.001693  0.004462  0.013002  0.002305  0.001448  \n",
       "128368  0.003202  0.010653  0.018301  0.069932  0.007339  0.002906  \n",
       "128369  0.020635  0.001783  0.010174  0.042982  0.003362  0.002097  \n",
       "128370  0.005836  0.001078  0.012200  0.021474  0.002125  0.003932  \n",
       "128371  0.002943  0.001366  0.004965  0.015353  0.005677  0.001092  \n",
       "128372  0.003702  0.001952  0.003940  0.022115  0.002498  0.004024  \n",
       "128373  0.003475  0.001196  0.001495  0.002571  0.001304  0.001387  \n",
       "128374  0.005034  0.003002  0.001882  0.008992  0.017845  0.001102  \n",
       "128375  0.002860  0.004647  0.030299  0.032823  0.015211  0.001270  \n",
       "\n",
       "[128376 rows x 13 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_pred_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred_stack = oof_pred_stack.rename(columns=lambda s: s+\"_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_meta = pd.merge(train,meta,on='purchase_id')\n",
    "# train_meta = pd.merge(train,meta,on='purchase_id')\n",
    "time = pd.read_pickle(f\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/tmp/FE_train_after_date_agg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train,time[[\"purchase_id\",\"months\"]],on=\"purchase_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FqBfZgvrWVNMsCqGmZMdv3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYE5JJ4y6zJBipkCKobwVg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tC5JqjsVxsKxQ8Ykk9S7fg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pigjc37smwP2E3Z4VtKinB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123  130125  130129  130131  140307  140313  \\\n",
       "0  njibeyLPrsnu4HCopjBihW       0       0       0       0       0       0   \n",
       "1  FqBfZgvrWVNMsCqGmZMdv3       0       0       1       0       0       0   \n",
       "2  KYE5JJ4y6zJBipkCKobwVg       0       0       0       0       0       0   \n",
       "3  tC5JqjsVxsKxQ8Ykk9S7fg       0       0       0       1       0       0   \n",
       "4  Pigjc37smwP2E3Z4VtKinB       0       0       0       0       0       0   \n",
       "\n",
       "   140316  140317  140321  140501  140505  140641  140691  months  \n",
       "0       0       0       0       0       0       0       0       1  \n",
       "1       0       0       0       0       0       0       0       1  \n",
       "2       0       0       0       0       0       0       0       1  \n",
       "3       0       0       0       0       0       0       0       1  \n",
       "4       0       0       0       0       1       0       0       1  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_meta.drop(\"mstr\",axis=1,inplace=True)\n",
    "# train_meta.drop(\"p_date\",axis=1,inplace=True)\n",
    "# train_meta.drop(\"p_time\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plus_oof_pred = pd.concat([train,oof_pred_stack],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "      <th>months</th>\n",
       "      <th>130123_pred</th>\n",
       "      <th>130125_pred</th>\n",
       "      <th>130129_pred</th>\n",
       "      <th>130131_pred</th>\n",
       "      <th>140307_pred</th>\n",
       "      <th>140313_pred</th>\n",
       "      <th>140316_pred</th>\n",
       "      <th>140317_pred</th>\n",
       "      <th>140321_pred</th>\n",
       "      <th>140501_pred</th>\n",
       "      <th>140505_pred</th>\n",
       "      <th>140641_pred</th>\n",
       "      <th>140691_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>njibeyLPrsnu4HCopjBihW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050872</td>\n",
       "      <td>0.017311</td>\n",
       "      <td>0.041477</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FqBfZgvrWVNMsCqGmZMdv3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059787</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYE5JJ4y6zJBipkCKobwVg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>0.156954</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tC5JqjsVxsKxQ8Ykk9S7fg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338206</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.362829</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>0.142816</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pigjc37smwP2E3Z4VtKinB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195282</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>0.278741</td>\n",
       "      <td>0.112796</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.012095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YCHTGgFS6shv3GCMB7sB5j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245784</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.304213</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.112828</td>\n",
       "      <td>0.161048</td>\n",
       "      <td>0.023946</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nQsjoHBDtiJvKNUxzUoR4d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162686</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>0.406733</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LXdStjW5USNHWpcXHd4E5j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077509</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.049291</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>0.430345</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.015905</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9qw6QFmtqjjbPS9pMrwi7S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.154875</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.022906</td>\n",
       "      <td>0.057588</td>\n",
       "      <td>0.037409</td>\n",
       "      <td>0.010224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e6qaQuMJ3xsZJ96QmgCnxN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445211</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.064876</td>\n",
       "      <td>0.056398</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HYFuxPUAEMCcj6LAb4QmER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.127770</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>0.158469</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JocGnYfx4qYadKzeaPctLc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.329731</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.140179</td>\n",
       "      <td>0.358181</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.044895</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGbyviQqFLKMXRxJtMoTy7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071135</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.094150</td>\n",
       "      <td>0.088935</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.021272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>62ubQAVp2p6UqUSA6Udxk2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030695</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.080671</td>\n",
       "      <td>0.239791</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.015185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pcpvb6nFijgNJ7a8qm6Wkh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085648</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.051223</td>\n",
       "      <td>0.100957</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.332015</td>\n",
       "      <td>0.036971</td>\n",
       "      <td>0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>uJT7J9ik4ofmhL82yhuPUj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>0.436384</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.019827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bSrGfvw9LivGMGDvwgNZdd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108195</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.051741</td>\n",
       "      <td>0.172659</td>\n",
       "      <td>0.043973</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.010063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54LjSZcKzsEgGJFZhzStDN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091637</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>0.107695</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>0.033747</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.131068</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.013062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BgXQUPyGMSJXcHDYyTq3rD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079462</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.055269</td>\n",
       "      <td>0.011804</td>\n",
       "      <td>0.267417</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.240096</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JbyVvLTSa9VXvC5ih9i8Sg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>0.092005</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.853982</td>\n",
       "      <td>0.034980</td>\n",
       "      <td>0.045572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qoPCLGyW9AuNuYey9VrDkk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110523</td>\n",
       "      <td>0.012884</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>0.149248</td>\n",
       "      <td>0.055920</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.034374</td>\n",
       "      <td>0.031445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RpRVwuyV3eG5qo3LudZwNk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132535</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>0.100878</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.056744</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xfUANe5qKkNHpDzgBkjtki</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.021901</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Xa6swkgZirn3xJ7dfxkPxc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.013741</td>\n",
       "      <td>0.083898</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.044003</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>v8ToYS27VqbMAEwjXSs3Eg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130349</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.053214</td>\n",
       "      <td>0.218680</td>\n",
       "      <td>0.050599</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.133364</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>0.065128</td>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>D9xHwctWqXg2cWtL5do8WM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041997</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.014802</td>\n",
       "      <td>0.083328</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.058762</td>\n",
       "      <td>0.014321</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HJw8j6CLqATfmUcfSGCj9m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089071</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.089306</td>\n",
       "      <td>0.387907</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.010814</td>\n",
       "      <td>0.123888</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.010390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwT85z8GdnRfhE7qxMLcbe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.047415</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.020364</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.015820</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KBKcEhnC4AKZk5MKbC55xf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152550</td>\n",
       "      <td>0.007913</td>\n",
       "      <td>0.070865</td>\n",
       "      <td>0.226752</td>\n",
       "      <td>0.270927</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.091375</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>R4CBpqHCVbGufzHwq3Mpxj</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114695</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>0.052021</td>\n",
       "      <td>0.039587</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.030713</td>\n",
       "      <td>0.007729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ftz5AVKzxe2bnqb6QxFtHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.129068</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.370652</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>0.010723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SwrNFka4nj9QnGhHQuPtZe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.046306</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>p5Q4FMMRzdfN5PnbXvLYPG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042095</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.056775</td>\n",
       "      <td>0.051704</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.026106</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.008813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>52yLTccEAEWmaKzumWxrEZ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120030</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.132121</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.019914</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.008611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>adzeEFtCXno47skKoGELRL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181262</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.075766</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DGHgXrMFi4uyhGx2C6LES7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044494</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.018458</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>aa7Lick7NBCEJSXRHMGZ8a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426398</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.240869</td>\n",
       "      <td>0.403755</td>\n",
       "      <td>0.024503</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>wtPXmSPAFD2Ha4aj5w37ET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.045456</td>\n",
       "      <td>0.421024</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pFEEnuyh54DfgB2uvnsfGm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084926</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.083490</td>\n",
       "      <td>0.168748</td>\n",
       "      <td>0.054903</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.037613</td>\n",
       "      <td>0.048948</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mrJF7AkeTvCWcnYJ7mAxni</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063461</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.059310</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>0.084440</td>\n",
       "      <td>0.080559</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.004590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RrXj94gsfmN6LgavYimqoe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097041</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.740598</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.228457</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TsRJJXmvg732DhDt8MVEki</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247445</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.056197</td>\n",
       "      <td>0.157943</td>\n",
       "      <td>0.091249</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>0.019713</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.197041</td>\n",
       "      <td>0.237816</td>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.175676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XZsFA273csK7yUndLcpWqg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108536</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>0.132221</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.087336</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.004115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>JE8t9HUBCBuUL2VMGQfb5Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.027739</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ZWcwhniND3ieECyM28rdVB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054712</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wmKXgFyCNevTdErXfxNwBB</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119961</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.041846</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.011506</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.066380</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.004763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>QMiYGb9aS6JtLojt6jBdCe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124697</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sM8Xnf5TG7Hd8VZemqqP5H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041571</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.449107</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>N2PnHCwkmyrHMA2njexPFD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.165995</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mgiLGai8RCgujnodCbrDuF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.048615</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>0.102090</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128326</th>\n",
       "      <td>P6d5W5vCLmg3BJ3RUPxgvF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.182608</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.008779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128327</th>\n",
       "      <td>KZVXqUevzF58MnwrsUAm54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.018189</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.004079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128328</th>\n",
       "      <td>CgGnPbozUGmdHjvZGVrbWK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115443</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.215025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128329</th>\n",
       "      <td>NdBUNcA6BJAB7qncqeiZQD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.361207</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>0.371227</td>\n",
       "      <td>0.019031</td>\n",
       "      <td>0.030463</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.003976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128330</th>\n",
       "      <td>m9THdhH5nDrAym2WEmZeN6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.159749</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.140843</td>\n",
       "      <td>0.236245</td>\n",
       "      <td>0.172761</td>\n",
       "      <td>0.038495</td>\n",
       "      <td>0.048271</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>0.074024</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.044146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128331</th>\n",
       "      <td>xEPpK5Fp3p5TpfznUFVLoM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031319</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>0.038179</td>\n",
       "      <td>0.017135</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.072064</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128332</th>\n",
       "      <td>3XkgPU82pKDq4ytu5RyZY7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.140209</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>0.175157</td>\n",
       "      <td>0.174959</td>\n",
       "      <td>0.081311</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.006518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128333</th>\n",
       "      <td>iKmzej9arWmuC6pHukcCJS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328703</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.587862</td>\n",
       "      <td>0.203847</td>\n",
       "      <td>0.048854</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.114464</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.062541</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.064723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128334</th>\n",
       "      <td>io83TZYwKeTguzvHQjhYr4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.028952</td>\n",
       "      <td>0.096190</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128335</th>\n",
       "      <td>KVkYXdAdtjnL6uBwAfuJZA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.102942</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.102086</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>0.063706</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128336</th>\n",
       "      <td>9dYFLGUKiVaagfXKjttyUb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206052</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.209772</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128337</th>\n",
       "      <td>EmAbc5unejku7YYbVUkRsn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.369452</td>\n",
       "      <td>0.019703</td>\n",
       "      <td>0.073867</td>\n",
       "      <td>0.346731</td>\n",
       "      <td>0.270392</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128338</th>\n",
       "      <td>T8Arwp9ytT9sArwF7cg6EK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.826453</td>\n",
       "      <td>0.076340</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128339</th>\n",
       "      <td>NsN2MRztpx37rMA7RyKTPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.193393</td>\n",
       "      <td>0.119514</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.091824</td>\n",
       "      <td>0.116056</td>\n",
       "      <td>0.024126</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.070297</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128340</th>\n",
       "      <td>ACayZrwYDxVL2JrKsXCPgY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.201104</td>\n",
       "      <td>0.151916</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128341</th>\n",
       "      <td>UnyX7S2X6swjoW4o3ddCrb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.177033</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.042360</td>\n",
       "      <td>0.554656</td>\n",
       "      <td>0.077438</td>\n",
       "      <td>0.052845</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.049452</td>\n",
       "      <td>0.032126</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.004820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128342</th>\n",
       "      <td>MFrwU5pNtgv5AaSQeLFFGd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.163941</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.085191</td>\n",
       "      <td>0.100509</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128343</th>\n",
       "      <td>BTJx6unCs8QrbmLuoKuJ8j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071646</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>0.038550</td>\n",
       "      <td>0.053979</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128344</th>\n",
       "      <td>zeJYa9K5s4CoNeRMnBLPkf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087220</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>0.101363</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>0.037081</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.038577</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.008786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128345</th>\n",
       "      <td>7FwAaHzrdjmewgMbDJ2oxJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081844</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.078404</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.055254</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128346</th>\n",
       "      <td>nLm7crXd2j92p5PsgUEvTN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.060059</td>\n",
       "      <td>0.353954</td>\n",
       "      <td>0.026094</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.051760</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.049811</td>\n",
       "      <td>0.016941</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128347</th>\n",
       "      <td>EwSAZfHevhAqVSoz75yfCJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027909</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.059094</td>\n",
       "      <td>0.043873</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128348</th>\n",
       "      <td>j4FrkAGD6oYjkzuWh7FQ6P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104168</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128349</th>\n",
       "      <td>t3muYok7ZTcNZSMQbeUcMT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.022721</td>\n",
       "      <td>0.038935</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.024107</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.006926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128350</th>\n",
       "      <td>T6NdUqAs9ChEcUejG5ruwG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>0.098040</td>\n",
       "      <td>0.075941</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128351</th>\n",
       "      <td>L4kSviAtCyZHX42b7a6Sbb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.091829</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.122711</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.098994</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128352</th>\n",
       "      <td>jP4Qph2kPCvaVhLQx6vr4M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062712</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128353</th>\n",
       "      <td>TejKW9EsYSBVTdb2vovWEW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.315367</td>\n",
       "      <td>0.011899</td>\n",
       "      <td>0.087889</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>0.145801</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.165185</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.007432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128354</th>\n",
       "      <td>wMUCjtf3qvLc5u5jd9GTX4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.080956</td>\n",
       "      <td>0.167820</td>\n",
       "      <td>0.070777</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.069604</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.339753</td>\n",
       "      <td>0.152753</td>\n",
       "      <td>0.029955</td>\n",
       "      <td>0.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128355</th>\n",
       "      <td>HSxTJNAzekBTnYFk5WQVZn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.083121</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.057254</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.030409</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.009050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128356</th>\n",
       "      <td>BbpVKPSJHSuw9DUoJn7MUY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131014</td>\n",
       "      <td>0.485598</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>0.064654</td>\n",
       "      <td>0.152783</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>0.095462</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.048703</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128357</th>\n",
       "      <td>45wA8Rf6QFhMwKB74SFuEa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128358</th>\n",
       "      <td>weyoiViCoVRKuAujoCUag6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.474974</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.133402</td>\n",
       "      <td>0.316983</td>\n",
       "      <td>0.104647</td>\n",
       "      <td>0.166687</td>\n",
       "      <td>0.342469</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128359</th>\n",
       "      <td>TW9rxBbrwfLmjAJeMkmKU8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064281</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.094157</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.113315</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128360</th>\n",
       "      <td>BPoAPggA9uEmyDLQcwEdAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.180414</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.253977</td>\n",
       "      <td>0.124917</td>\n",
       "      <td>0.415832</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.046937</td>\n",
       "      <td>0.216458</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128361</th>\n",
       "      <td>VrhCzPMS8aeyp6RXWxJhHk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.119209</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.035839</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128362</th>\n",
       "      <td>4nh2uQmYmFnedqCEZyXpBc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.076027</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.108558</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.110573</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128363</th>\n",
       "      <td>fbS5FS9c2YeuJ2YYRyqysn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.032464</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.041289</td>\n",
       "      <td>0.035399</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>0.003671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128364</th>\n",
       "      <td>WLExJDxwG93x6kwpRigAwV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.029338</td>\n",
       "      <td>0.076565</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.490533</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128365</th>\n",
       "      <td>hHE7iYk973MPjntF8U89g2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.070959</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>0.105198</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.111429</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128366</th>\n",
       "      <td>gfB3DfMhtUBn3KPiLMuevR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131615</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>0.055775</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.060603</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128367</th>\n",
       "      <td>BAMyNuKrFVB9hfbR7bSwmH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>0.335020</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128368</th>\n",
       "      <td>gbFpWzcp2hbG7a4YiR4XGN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.143410</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0.161570</td>\n",
       "      <td>0.119190</td>\n",
       "      <td>0.020112</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.069932</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128369</th>\n",
       "      <td>g4yifhFA4cW7ztsXFTqfo7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087045</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.037134</td>\n",
       "      <td>0.129775</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128370</th>\n",
       "      <td>HMtbm8GKkxsDSpzPLQeYkF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042068</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.094983</td>\n",
       "      <td>0.112789</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.021474</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128371</th>\n",
       "      <td>aJpMhZgCP3VWxjTkgCTxGK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062619</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.144918</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128372</th>\n",
       "      <td>KLqw7L7yeZdVjL63xpqNkS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.019585</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.018641</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.004024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128373</th>\n",
       "      <td>6GWrUUS54k6QVMBMT26LzF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.084490</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128374</th>\n",
       "      <td>LA3aFfzrdi6r2B6y9u2BkF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.029498</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128375</th>\n",
       "      <td>nN22TUE4fzGWE2i5Y4r6Qe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064535</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.030299</td>\n",
       "      <td>0.032823</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128376 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   purchase_id  130123  130125  130129  130131  140307  \\\n",
       "0       njibeyLPrsnu4HCopjBihW       0       0       0       0       0   \n",
       "1       FqBfZgvrWVNMsCqGmZMdv3       0       0       1       0       0   \n",
       "2       KYE5JJ4y6zJBipkCKobwVg       0       0       0       0       0   \n",
       "3       tC5JqjsVxsKxQ8Ykk9S7fg       0       0       0       1       0   \n",
       "4       Pigjc37smwP2E3Z4VtKinB       0       0       0       0       0   \n",
       "5       YCHTGgFS6shv3GCMB7sB5j       0       0       0       1       0   \n",
       "6       nQsjoHBDtiJvKNUxzUoR4d       0       0       0       0       0   \n",
       "7       LXdStjW5USNHWpcXHd4E5j       0       0       0       0       0   \n",
       "8       9qw6QFmtqjjbPS9pMrwi7S       0       0       1       0       0   \n",
       "9       e6qaQuMJ3xsZJ96QmgCnxN       0       0       0       0       0   \n",
       "10      HYFuxPUAEMCcj6LAb4QmER       1       0       1       0       0   \n",
       "11      JocGnYfx4qYadKzeaPctLc       0       0       0       1       0   \n",
       "12      HGbyviQqFLKMXRxJtMoTy7       0       0       0       0       0   \n",
       "13      62ubQAVp2p6UqUSA6Udxk2       1       0       0       1       1   \n",
       "14      pcpvb6nFijgNJ7a8qm6Wkh       0       0       0       0       0   \n",
       "15      uJT7J9ik4ofmhL82yhuPUj       0       0       0       0       0   \n",
       "16      bSrGfvw9LivGMGDvwgNZdd       0       0       0       0       0   \n",
       "17      54LjSZcKzsEgGJFZhzStDN       1       0       0       0       1   \n",
       "18      BgXQUPyGMSJXcHDYyTq3rD       0       0       0       0       0   \n",
       "19      JbyVvLTSa9VXvC5ih9i8Sg       0       0       1       0       0   \n",
       "20      qoPCLGyW9AuNuYey9VrDkk       0       0       0       0       0   \n",
       "21      RpRVwuyV3eG5qo3LudZwNk       0       0       0       0       0   \n",
       "22      xfUANe5qKkNHpDzgBkjtki       0       0       0       0       0   \n",
       "23      Xa6swkgZirn3xJ7dfxkPxc       0       0       0       1       0   \n",
       "24      v8ToYS27VqbMAEwjXSs3Eg       0       0       0       0       0   \n",
       "25      D9xHwctWqXg2cWtL5do8WM       1       0       1       0       0   \n",
       "26      HJw8j6CLqATfmUcfSGCj9m       0       0       0       0       0   \n",
       "27      qwT85z8GdnRfhE7qxMLcbe       0       0       0       0       0   \n",
       "28      KBKcEhnC4AKZk5MKbC55xf       0       0       0       0       0   \n",
       "29      R4CBpqHCVbGufzHwq3Mpxj       0       1       0       0       0   \n",
       "30      ftz5AVKzxe2bnqb6QxFtHA       0       0       0       0       0   \n",
       "31      SwrNFka4nj9QnGhHQuPtZe       0       0       0       0       0   \n",
       "32      p5Q4FMMRzdfN5PnbXvLYPG       0       0       0       0       0   \n",
       "33      52yLTccEAEWmaKzumWxrEZ       1       0       0       1       0   \n",
       "34      adzeEFtCXno47skKoGELRL       1       0       0       0       0   \n",
       "35      DGHgXrMFi4uyhGx2C6LES7       0       0       0       0       0   \n",
       "36      aa7Lick7NBCEJSXRHMGZ8a       0       0       0       0       0   \n",
       "37      wtPXmSPAFD2Ha4aj5w37ET       0       0       0       0       0   \n",
       "38      pFEEnuyh54DfgB2uvnsfGm       0       0       0       0       1   \n",
       "39      mrJF7AkeTvCWcnYJ7mAxni       0       0       0       0       0   \n",
       "40      RrXj94gsfmN6LgavYimqoe       0       0       0       0       0   \n",
       "41      TsRJJXmvg732DhDt8MVEki       0       0       0       0       0   \n",
       "42      XZsFA273csK7yUndLcpWqg       0       0       0       0       0   \n",
       "43      JE8t9HUBCBuUL2VMGQfb5Q       0       0       0       0       0   \n",
       "44      ZWcwhniND3ieECyM28rdVB       0       0       0       0       0   \n",
       "45      wmKXgFyCNevTdErXfxNwBB       1       0       0       1       0   \n",
       "46      QMiYGb9aS6JtLojt6jBdCe       0       0       0       0       0   \n",
       "47      sM8Xnf5TG7Hd8VZemqqP5H       0       0       0       0       1   \n",
       "48      N2PnHCwkmyrHMA2njexPFD       0       0       0       0       0   \n",
       "49      mgiLGai8RCgujnodCbrDuF       0       0       0       0       0   \n",
       "...                        ...     ...     ...     ...     ...     ...   \n",
       "128326  P6d5W5vCLmg3BJ3RUPxgvF       0       0       0       0       0   \n",
       "128327  KZVXqUevzF58MnwrsUAm54       0       0       0       0       1   \n",
       "128328  CgGnPbozUGmdHjvZGVrbWK       0       0       0       0       0   \n",
       "128329  NdBUNcA6BJAB7qncqeiZQD       0       0       0       0       0   \n",
       "128330  m9THdhH5nDrAym2WEmZeN6       0       0       0       0       0   \n",
       "128331  xEPpK5Fp3p5TpfznUFVLoM       1       0       0       0       0   \n",
       "128332  3XkgPU82pKDq4ytu5RyZY7       0       0       0       0       0   \n",
       "128333  iKmzej9arWmuC6pHukcCJS       0       0       0       0       0   \n",
       "128334  io83TZYwKeTguzvHQjhYr4       0       0       0       0       0   \n",
       "128335  KVkYXdAdtjnL6uBwAfuJZA       0       0       0       0       1   \n",
       "128336  9dYFLGUKiVaagfXKjttyUb       0       0       1       0       0   \n",
       "128337  EmAbc5unejku7YYbVUkRsn       0       0       0       0       0   \n",
       "128338  T8Arwp9ytT9sArwF7cg6EK       0       0       0       0       0   \n",
       "128339  NsN2MRztpx37rMA7RyKTPN       0       0       0       0       0   \n",
       "128340  ACayZrwYDxVL2JrKsXCPgY       0       0       0       0       0   \n",
       "128341  UnyX7S2X6swjoW4o3ddCrb       0       0       0       1       0   \n",
       "128342  MFrwU5pNtgv5AaSQeLFFGd       0       0       0       0       0   \n",
       "128343  BTJx6unCs8QrbmLuoKuJ8j       0       0       0       0       0   \n",
       "128344  zeJYa9K5s4CoNeRMnBLPkf       0       0       0       0       0   \n",
       "128345  7FwAaHzrdjmewgMbDJ2oxJ       0       0       0       1       0   \n",
       "128346  nLm7crXd2j92p5PsgUEvTN       0       0       0       0       0   \n",
       "128347  EwSAZfHevhAqVSoz75yfCJ       0       0       0       0       0   \n",
       "128348  j4FrkAGD6oYjkzuWh7FQ6P       0       0       0       0       0   \n",
       "128349  t3muYok7ZTcNZSMQbeUcMT       0       0       0       0       0   \n",
       "128350  T6NdUqAs9ChEcUejG5ruwG       0       0       0       0       0   \n",
       "128351  L4kSviAtCyZHX42b7a6Sbb       0       0       0       0       0   \n",
       "128352  jP4Qph2kPCvaVhLQx6vr4M       0       0       0       0       0   \n",
       "128353  TejKW9EsYSBVTdb2vovWEW       0       0       0       0       0   \n",
       "128354  wMUCjtf3qvLc5u5jd9GTX4       0       0       0       0       0   \n",
       "128355  HSxTJNAzekBTnYFk5WQVZn       0       0       0       0       0   \n",
       "128356  BbpVKPSJHSuw9DUoJn7MUY       0       0       0       0       1   \n",
       "128357  45wA8Rf6QFhMwKB74SFuEa       0       0       0       0       0   \n",
       "128358  weyoiViCoVRKuAujoCUag6       1       0       0       0       0   \n",
       "128359  TW9rxBbrwfLmjAJeMkmKU8       0       0       0       0       0   \n",
       "128360  BPoAPggA9uEmyDLQcwEdAK       0       0       0       0       0   \n",
       "128361  VrhCzPMS8aeyp6RXWxJhHk       0       0       0       1       0   \n",
       "128362  4nh2uQmYmFnedqCEZyXpBc       0       0       0       0       0   \n",
       "128363  fbS5FS9c2YeuJ2YYRyqysn       0       0       0       0       0   \n",
       "128364  WLExJDxwG93x6kwpRigAwV       0       0       0       0       0   \n",
       "128365  hHE7iYk973MPjntF8U89g2       0       0       0       0       0   \n",
       "128366  gfB3DfMhtUBn3KPiLMuevR       0       0       0       0       0   \n",
       "128367  BAMyNuKrFVB9hfbR7bSwmH       0       0       0       0       0   \n",
       "128368  gbFpWzcp2hbG7a4YiR4XGN       0       0       0       0       0   \n",
       "128369  g4yifhFA4cW7ztsXFTqfo7       0       0       0       0       0   \n",
       "128370  HMtbm8GKkxsDSpzPLQeYkF       0       0       0       0       0   \n",
       "128371  aJpMhZgCP3VWxjTkgCTxGK       0       0       0       0       0   \n",
       "128372  KLqw7L7yeZdVjL63xpqNkS       0       0       0       0       0   \n",
       "128373  6GWrUUS54k6QVMBMT26LzF       0       0       0       0       0   \n",
       "128374  LA3aFfzrdi6r2B6y9u2BkF       0       0       0       0       0   \n",
       "128375  nN22TUE4fzGWE2i5Y4r6Qe       0       0       0       0       0   \n",
       "\n",
       "        140313  140316  140317  140321  140501  140505  140641  140691  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       1       0       0   \n",
       "5            0       0       0       0       0       0       0       0   \n",
       "6            0       0       0       0       0       0       0       0   \n",
       "7            0       1       0       0       0       0       0       0   \n",
       "8            0       0       0       0       0       0       0       0   \n",
       "9            0       0       0       0       0       0       0       0   \n",
       "10           0       0       0       0       0       0       0       0   \n",
       "11           0       0       0       0       0       0       1       0   \n",
       "12           0       0       0       0       0       0       0       0   \n",
       "13           0       0       0       0       0       0       0       0   \n",
       "14           0       0       0       0       1       1       0       0   \n",
       "15           0       0       0       0       0       1       0       0   \n",
       "16           0       0       0       0       0       0       0       0   \n",
       "17           0       0       0       0       0       0       0       0   \n",
       "18           1       0       0       0       0       0       0       0   \n",
       "19           0       0       0       0       0       0       0       0   \n",
       "20           0       0       0       0       0       0       0       0   \n",
       "21           0       0       0       0       0       0       0       0   \n",
       "22           1       0       0       0       0       0       0       0   \n",
       "23           0       0       0       0       0       0       0       0   \n",
       "24           1       0       0       0       0       0       0       0   \n",
       "25           0       0       0       0       0       0       0       0   \n",
       "26           0       0       0       0       0       0       0       0   \n",
       "27           1       0       0       0       0       0       0       0   \n",
       "28           0       0       0       0       0       1       0       0   \n",
       "29           0       0       0       0       0       0       0       0   \n",
       "30           0       0       0       0       0       0       0       0   \n",
       "31           0       0       0       0       0       0       0       0   \n",
       "32           0       0       0       0       0       0       0       0   \n",
       "33           0       0       0       0       0       0       0       0   \n",
       "34           0       0       0       0       0       0       1       0   \n",
       "35           0       0       0       0       0       0       0       0   \n",
       "36           0       0       0       0       0       0       0       0   \n",
       "37           0       0       0       0       0       0       0       0   \n",
       "38           0       0       0       0       1       0       0       0   \n",
       "39           0       0       0       0       0       0       0       0   \n",
       "40           0       0       0       0       0       0       0       0   \n",
       "41           1       0       0       0       0       0       0       0   \n",
       "42           0       0       0       0       0       0       0       0   \n",
       "43           0       0       0       0       0       0       0       0   \n",
       "44           0       0       0       0       0       0       0       0   \n",
       "45           0       0       0       0       0       0       0       0   \n",
       "46           0       0       0       0       0       0       0       0   \n",
       "47           0       0       0       0       0       0       0       0   \n",
       "48           0       0       0       0       0       0       0       0   \n",
       "49           0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "128326       0       0       0       0       0       0       0       0   \n",
       "128327       0       1       0       0       0       0       0       0   \n",
       "128328       0       0       0       0       0       0       0       0   \n",
       "128329       0       0       0       0       0       0       0       0   \n",
       "128330       0       0       0       0       0       0       0       0   \n",
       "128331       0       0       0       0       0       0       0       0   \n",
       "128332       0       0       0       0       0       0       0       0   \n",
       "128333       0       0       0       0       0       0       0       0   \n",
       "128334       0       0       0       0       0       0       0       0   \n",
       "128335       0       0       0       0       0       0       0       0   \n",
       "128336       0       0       0       0       0       0       0       0   \n",
       "128337       0       0       0       0       0       0       0       0   \n",
       "128338       0       0       0       0       0       0       0       0   \n",
       "128339       0       0       0       0       0       0       0       0   \n",
       "128340       0       0       0       0       0       0       0       0   \n",
       "128341       0       0       0       0       0       0       0       0   \n",
       "128342       1       0       0       0       0       0       0       0   \n",
       "128343       0       0       0       0       0       0       0       0   \n",
       "128344       0       0       0       0       0       0       0       0   \n",
       "128345       0       0       0       0       0       0       0       0   \n",
       "128346       0       0       0       0       0       0       0       1   \n",
       "128347       0       0       0       0       0       0       0       0   \n",
       "128348       0       0       0       0       0       0       0       0   \n",
       "128349       1       0       0       0       0       0       0       0   \n",
       "128350       0       0       0       0       0       0       0       0   \n",
       "128351       0       0       0       0       0       0       0       0   \n",
       "128352       0       0       0       0       0       0       0       0   \n",
       "128353       0       0       0       0       0       0       0       0   \n",
       "128354       0       0       0       0       0       0       0       0   \n",
       "128355       0       0       0       0       0       0       0       0   \n",
       "128356       0       0       0       0       0       0       0       0   \n",
       "128357       0       0       0       0       0       1       0       0   \n",
       "128358       0       0       0       0       0       0       0       0   \n",
       "128359       0       0       0       0       0       0       0       0   \n",
       "128360       0       0       0       0       0       0       0       0   \n",
       "128361       0       0       0       0       0       0       0       0   \n",
       "128362       0       0       0       0       0       1       0       0   \n",
       "128363       0       0       0       0       0       0       0       0   \n",
       "128364       0       0       0       0       0       0       0       0   \n",
       "128365       0       0       0       0       0       0       0       0   \n",
       "128366       0       0       0       0       0       0       0       0   \n",
       "128367       0       0       0       0       0       0       0       0   \n",
       "128368       0       0       0       0       0       0       0       0   \n",
       "128369       0       0       0       0       0       0       0       0   \n",
       "128370       0       0       0       0       0       0       0       0   \n",
       "128371       1       0       0       0       0       0       0       0   \n",
       "128372       0       0       0       0       0       0       0       0   \n",
       "128373       0       0       0       0       0       0       0       0   \n",
       "128374       0       0       0       0       0       0       0       0   \n",
       "128375       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        months  130123_pred  130125_pred  130129_pred  130131_pred  \\\n",
       "0            1     0.050872     0.017311     0.041477     0.073584   \n",
       "1            1     0.059787     0.004534     0.056330     0.141299   \n",
       "2            1     0.104315     0.007874     0.049998     0.156954   \n",
       "3            1     0.338206     0.013345     0.362829     0.349630   \n",
       "4            1     0.195282     0.007186     0.053891     0.278741   \n",
       "5            1     0.245784     0.003997     0.055868     0.304213   \n",
       "6            1     0.162686     0.008411     0.040557     0.406733   \n",
       "7            1     0.077509     0.014484     0.049291     0.123494   \n",
       "8            1     0.120237     0.005436     0.072606     0.154875   \n",
       "9            1     0.445211     0.003174     0.064876     0.056398   \n",
       "10           1     0.154743     0.008397     0.127770     0.273776   \n",
       "11           1     0.329731     0.016022     0.140179     0.358181   \n",
       "12           1     0.071135     0.005721     0.045026     0.094150   \n",
       "13           1     0.030695     0.005168     0.062937     0.048715   \n",
       "14           1     0.085648     0.011987     0.051223     0.100957   \n",
       "15           1     0.026087     0.001593     0.022266     0.055308   \n",
       "16           1     0.108195     0.012328     0.051741     0.172659   \n",
       "17           1     0.091637     0.008215     0.036490     0.107695   \n",
       "18           1     0.079462     0.013546     0.016775     0.055269   \n",
       "19           1     0.052033     0.001521     0.036616     0.092005   \n",
       "20           1     0.110523     0.012884     0.118443     0.149248   \n",
       "21           1     0.132535     0.007117     0.057451     0.100878   \n",
       "22           1     0.044064     0.004822     0.012261     0.052079   \n",
       "23           1     0.049766     0.031195     0.013741     0.083898   \n",
       "24           1     0.130349     0.005515     0.053214     0.218680   \n",
       "25           1     0.041997     0.005737     0.014802     0.083328   \n",
       "26           1     0.089071     0.002509     0.089306     0.387907   \n",
       "27           1     0.058373     0.002151     0.015419     0.034828   \n",
       "28           1     0.152550     0.007913     0.070865     0.226752   \n",
       "29           1     0.114695     0.009462     0.052021     0.039587   \n",
       "30           1     0.049930     0.002619     0.036736     0.072011   \n",
       "31           1     0.023662     0.004232     0.010545     0.036549   \n",
       "32           1     0.042095     0.004438     0.056775     0.051704   \n",
       "33           1     0.120030     0.003876     0.053126     0.132121   \n",
       "34           1     0.181262     0.007490     0.075766     0.088110   \n",
       "35           1     0.044494     0.002565     0.018458     0.040985   \n",
       "36           1     0.426398     0.003275     0.240869     0.403755   \n",
       "37           1     0.055114     0.003451     0.076470     0.081784   \n",
       "38           1     0.084926     0.008593     0.083490     0.168748   \n",
       "39           1     0.063461     0.026459     0.059310     0.107529   \n",
       "40           1     0.097041     0.004729     0.025560     0.093347   \n",
       "41           1     0.247445     0.031406     0.056197     0.157943   \n",
       "42           1     0.108536     0.003834     0.021009     0.132221   \n",
       "43           1     0.065213     0.010614     0.020525     0.027739   \n",
       "44           1     0.054712     0.001758     0.013869     0.006130   \n",
       "45           1     0.119961     0.007446     0.025388     0.041846   \n",
       "46           1     0.124697     0.002842     0.079790     0.113641   \n",
       "47           1     0.041571     0.002497     0.016256     0.034763   \n",
       "48           1     0.117310     0.010108     0.032292     0.165995   \n",
       "49           1     0.038395     0.048615     0.019723     0.102090   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "128326       3     0.182608     0.017210     0.040203     0.142071   \n",
       "128327       3     0.029616     0.004978     0.018189     0.037605   \n",
       "128328       3     0.115443     0.004083     0.009668     0.050897   \n",
       "128329       3     0.361207     0.001568     0.055025     0.371227   \n",
       "128330       3     0.159749     0.023554     0.061008     0.140843   \n",
       "128331       3     0.031319     0.004626     0.018351     0.074596   \n",
       "128332       3     0.140209     0.007649     0.175157     0.174959   \n",
       "128333       3     0.328703     0.005382     0.150602     0.587862   \n",
       "128334       3     0.048878     0.001515     0.028952     0.096190   \n",
       "128335       3     0.102942     0.005178     0.024843     0.102086   \n",
       "128336       3     0.206052     0.002510     0.053340     0.209772   \n",
       "128337       3     0.369452     0.019703     0.073867     0.346731   \n",
       "128338       3     0.012018     0.001678     0.019130     0.081300   \n",
       "128339       3     0.193393     0.119514     0.035135     0.091824   \n",
       "128340       3     0.107019     0.004268     0.201104     0.151916   \n",
       "128341       3     0.177033     0.012142     0.042360     0.554656   \n",
       "128342       3     0.163941     0.003438     0.085191     0.100509   \n",
       "128343       3     0.071646     0.002274     0.020181     0.075824   \n",
       "128344       3     0.087220     0.002877     0.031986     0.101363   \n",
       "128345       3     0.081844     0.011432     0.040643     0.078404   \n",
       "128346       3     0.115611     0.004014     0.060059     0.353954   \n",
       "128347       3     0.027909     0.001712     0.059094     0.043873   \n",
       "128348       3     0.104168     0.007730     0.027314     0.061237   \n",
       "128349       3     0.040175     0.001964     0.022721     0.038935   \n",
       "128350       3     0.081228     0.017107     0.098040     0.075941   \n",
       "128351       3     0.091829     0.006132     0.122711     0.109221   \n",
       "128352       3     0.062712     0.003011     0.041615     0.054622   \n",
       "128353       3     0.315367     0.011899     0.087889     0.293517   \n",
       "128354       3     0.194000     0.017859     0.080956     0.167820   \n",
       "128355       3     0.083121     0.012090     0.044172     0.057254   \n",
       "128356       3     0.131014     0.485598     0.058647     0.064654   \n",
       "128357       3     0.038213     0.004747     0.064489     0.088256   \n",
       "128358       3     0.474974     0.017180     0.133402     0.316983   \n",
       "128359       3     0.064281     0.002975     0.019836     0.094157   \n",
       "128360       3     0.180414     0.007823     0.253977     0.124917   \n",
       "128361       3     0.119209     0.006496     0.035839     0.093653   \n",
       "128362       3     0.076027     0.012308     0.062109     0.108558   \n",
       "128363       3     0.037208     0.002406     0.032464     0.024261   \n",
       "128364       3     0.072865     0.006671     0.029338     0.076565   \n",
       "128365       3     0.070959     0.003065     0.026273     0.105198   \n",
       "128366       3     0.131615     0.028443     0.072257     0.134024   \n",
       "128367       3     0.347074     0.002480     0.060051     0.335020   \n",
       "128368       3     0.143410     0.029159     0.149643     0.161570   \n",
       "128369       3     0.087045     0.006209     0.037134     0.129775   \n",
       "128370       3     0.042068     0.008239     0.040072     0.094983   \n",
       "128371       3     0.062619     0.017836     0.026335     0.144918   \n",
       "128372       3     0.053367     0.001135     0.019585     0.026083   \n",
       "128373       3     0.046734     0.002995     0.056600     0.084490   \n",
       "128374       3     0.020906     0.004887     0.012652     0.050600   \n",
       "128375       3     0.064535     0.001056     0.035537     0.044920   \n",
       "\n",
       "        140307_pred  140313_pred  140316_pred  140317_pred  140321_pred  \\\n",
       "0          0.018275     0.003804     0.006644     0.004631     0.004888   \n",
       "1          0.011082     0.016181     0.022297     0.007875     0.001164   \n",
       "2          0.021688     0.008820     0.010605     0.009418     0.002276   \n",
       "3          0.142816     0.008066     0.013548     0.008125     0.002093   \n",
       "4          0.112796     0.014341     0.014919     0.006282     0.008948   \n",
       "5          0.046071     0.014985     0.003919     0.003126     0.000989   \n",
       "6          0.047992     0.037083     0.017448     0.002924     0.002124   \n",
       "7          0.430345     0.012691     0.012514     0.005144     0.004673   \n",
       "8          0.030249     0.014319     0.009184     0.009507     0.002865   \n",
       "9          0.005214     0.006889     0.014072     0.022663     0.003887   \n",
       "10         0.158469     0.015086     0.059640     0.007839     0.001831   \n",
       "11         0.201433     0.017832     0.024636     0.009450     0.002068   \n",
       "12         0.088935     0.015833     0.006330     0.014640     0.003199   \n",
       "13         0.032008     0.002569     0.004949     0.003165     0.001414   \n",
       "14         0.046434     0.021300     0.004069     0.003619     0.000872   \n",
       "15         0.030315     0.009086     0.081258     0.019512     0.002669   \n",
       "16         0.043973     0.012123     0.004089     0.011919     0.010014   \n",
       "17         0.040628     0.033747     0.002942     0.005678     0.002415   \n",
       "18         0.011804     0.267417     0.020180     0.004365     0.000976   \n",
       "19         0.003803     0.005296     0.002839     0.004658     0.001590   \n",
       "20         0.055920     0.091661     0.009356     0.010053     0.006384   \n",
       "21         0.012860     0.004993     0.005239     0.002605     0.001398   \n",
       "22         0.021901     0.006924     0.003857     0.003547     0.001080   \n",
       "23         0.022228     0.014562     0.007812     0.005461     0.001777   \n",
       "24         0.050599     0.012260     0.015862     0.007585     0.002302   \n",
       "25         0.007183     0.007258     0.003946     0.004004     0.001511   \n",
       "26         0.052013     0.012204     0.009384     0.007395     0.005364   \n",
       "27         0.047415     0.022432     0.025637     0.156100     0.020364   \n",
       "28         0.270927     0.015215     0.037757     0.003407     0.001243   \n",
       "29         0.007582     0.022228     0.004628     0.010839     0.004243   \n",
       "30         0.129068     0.008314     0.001692     0.005940     0.002667   \n",
       "31         0.046306     0.004882     0.006265     0.007231     0.000940   \n",
       "32         0.004362     0.005965     0.005667     0.003329     0.026106   \n",
       "33         0.023786     0.003879     0.004377     0.006733     0.016208   \n",
       "34         0.016376     0.007979     0.010141     0.013340     0.005402   \n",
       "35         0.024500     0.019401     0.007616     0.009817     0.000760   \n",
       "36         0.024503     0.011376     0.004787     0.002981     0.001053   \n",
       "37         0.029172     0.004335     0.002205     0.003184     0.002003   \n",
       "38         0.054903     0.056378     0.007930     0.014738     0.002375   \n",
       "39         0.084440     0.080559     0.007233     0.005456     0.001182   \n",
       "40         0.005136     0.009258     0.002307     0.006187     0.000632   \n",
       "41         0.091249     0.083432     0.026618     0.019713     0.006345   \n",
       "42         0.015957     0.006618     0.008846     0.004621     0.002328   \n",
       "43         0.006999     0.008105     0.012136     0.007120     0.001411   \n",
       "44         0.001627     0.011199     0.005505     0.093796     0.001330   \n",
       "45         0.016473     0.011506     0.012192     0.006090     0.002686   \n",
       "46         0.008151     0.007054     0.020935     0.004421     0.001251   \n",
       "47         0.008472     0.003298     0.003421     0.003388     0.001936   \n",
       "48         0.022044     0.013626     0.004680     0.004918     0.001613   \n",
       "49         0.006603     0.022624     0.012099     0.002641     0.001108   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "128326     0.018885     0.010811     0.004965     0.002831     0.008750   \n",
       "128327     0.020468     0.019271     0.017743     0.000927     0.003359   \n",
       "128328     0.018507     0.014775     0.004093     0.002652     0.000801   \n",
       "128329     0.019031     0.030463     0.002269     0.001413     0.000426   \n",
       "128330     0.236245     0.172761     0.038495     0.048271     0.004147   \n",
       "128331     0.038179     0.017135     0.003911     0.008555     0.001532   \n",
       "128332     0.081311     0.017088     0.002829     0.011686     0.026967   \n",
       "128333     0.203847     0.048854     0.029287     0.114464     0.009552   \n",
       "128334     0.018022     0.025441     0.001869     0.004293     0.001526   \n",
       "128335     0.047928     0.063706     0.005507     0.010356     0.001244   \n",
       "128336     0.018270     0.008711     0.002208     0.002318     0.002855   \n",
       "128337     0.270392     0.018005     0.014600     0.009546     0.002139   \n",
       "128338     0.826453     0.076340     0.012071     0.002413     0.002636   \n",
       "128339     0.116056     0.024126     0.006173     0.007543     0.002935   \n",
       "128340     0.027565     0.008575     0.003684     0.002131     0.001327   \n",
       "128341     0.077438     0.052845     0.008142     0.022017     0.002954   \n",
       "128342     0.010125     0.023560     0.004733     0.006186     0.006609   \n",
       "128343     0.038550     0.053979     0.029098     0.002970     0.002910   \n",
       "128344     0.069199     0.037081     0.009888     0.008944     0.001384   \n",
       "128345     0.196273     0.007174     0.001923     0.055254     0.002870   \n",
       "128346     0.026094     0.017191     0.051760     0.038437     0.001395   \n",
       "128347     0.030675     0.010720     0.027965     0.014201     0.001461   \n",
       "128348     0.026125     0.010212     0.001226     0.004078     0.003409   \n",
       "128349     0.040833     0.008081     0.003325     0.003085     0.003084   \n",
       "128350     0.021346     0.009887     0.007825     0.004662     0.003344   \n",
       "128351     0.038532     0.009236     0.005449     0.005828     0.003093   \n",
       "128352     0.041594     0.007723     0.003102     0.003693     0.001993   \n",
       "128353     0.145801     0.030960     0.009863     0.008941     0.004285   \n",
       "128354     0.070777     0.051768     0.132184     0.069604     0.012059   \n",
       "128355     0.027555     0.010988     0.000808     0.001202     0.001206   \n",
       "128356     0.152783     0.016301     0.004648     0.095462     0.002822   \n",
       "128357     0.017295     0.010257     0.003402     0.034794     0.001544   \n",
       "128358     0.104647     0.166687     0.342469     0.005899     0.012589   \n",
       "128359     0.019087     0.016226     0.113315     0.005772     0.004142   \n",
       "128360     0.415832     0.147365     0.010688     0.007195     0.003420   \n",
       "128361     0.030696     0.021488     0.001251     0.005103     0.001148   \n",
       "128362     0.176560     0.028433     0.012216     0.011303     0.007831   \n",
       "128363     0.023314     0.008460     0.004429     0.004973     0.004629   \n",
       "128364     0.033028     0.013242     0.004836     0.003087     0.004729   \n",
       "128365     0.020862     0.013709     0.003675     0.005285     0.001644   \n",
       "128366     0.055775     0.020725     0.017650     0.004399     0.006754   \n",
       "128367     0.018690     0.028963     0.004368     0.004346     0.001693   \n",
       "128368     0.119190     0.020112     0.002926     0.003202     0.010653   \n",
       "128369     0.040700     0.033808     0.014150     0.020635     0.001783   \n",
       "128370     0.112789     0.024363     0.012738     0.005836     0.001078   \n",
       "128371     0.061358     0.024308     0.039103     0.002943     0.001366   \n",
       "128372     0.018641     0.016951     0.006705     0.003702     0.001952   \n",
       "128373     0.129103     0.009543     0.027797     0.003475     0.001196   \n",
       "128374     0.029498     0.007358     0.003779     0.005034     0.003002   \n",
       "128375     0.015711     0.011092     0.016079     0.002860     0.004647   \n",
       "\n",
       "        140501_pred  140505_pred  140641_pred  140691_pred  \n",
       "0          0.003786     0.012156     0.004168     0.001069  \n",
       "1          0.004097     0.010667     0.007253     0.000882  \n",
       "2          0.006773     0.024176     0.009391     0.003056  \n",
       "3          0.009140     0.014985     0.019850     0.004192  \n",
       "4          0.024500     0.113041     0.017420     0.012095  \n",
       "5          0.112828     0.161048     0.023946     0.001189  \n",
       "6          0.152551     0.033947     0.023529     0.006612  \n",
       "7          0.001339     0.012398     0.015905     0.001981  \n",
       "8          0.022906     0.057588     0.037409     0.010224  \n",
       "9          0.010428     0.012758     0.078165     0.000301  \n",
       "10         0.004131     0.008221     0.022934     0.001229  \n",
       "11         0.007196     0.032124     0.044895     0.001860  \n",
       "12         0.004550     0.047354     0.010384     0.021272  \n",
       "13         0.080671     0.239791     0.017496     0.015185  \n",
       "14         0.009457     0.332015     0.036971     0.004794  \n",
       "15         0.026148     0.436384     0.011094     0.019827  \n",
       "16         0.034511     0.130225     0.021500     0.010063  \n",
       "17         0.064378     0.131068     0.017753     0.013062  \n",
       "18         0.007210     0.240096     0.006636     0.001009  \n",
       "19         0.007458     0.853982     0.034980     0.045572  \n",
       "20         0.007986     0.071076     0.034374     0.031445  \n",
       "21         0.006154     0.056744     0.004344     0.002047  \n",
       "22         0.003542     0.005310     0.011223     0.000395  \n",
       "23         0.022468     0.044003     0.006496     0.004714  \n",
       "24         0.133364     0.040397     0.065128     0.011496  \n",
       "25         0.058762     0.014321     0.003510     0.001922  \n",
       "26         0.010814     0.123888     0.030056     0.010390  \n",
       "27         0.005247     0.015820     0.034937     0.000826  \n",
       "28         0.060960     0.091375     0.005839     0.001076  \n",
       "29         0.003297     0.025901     0.030713     0.007729  \n",
       "30         0.019878     0.370652     0.184674     0.010723  \n",
       "31         0.017467     0.015783     0.035302     0.000397  \n",
       "32         0.006478     0.011927     0.009349     0.008813  \n",
       "33         0.008095     0.019914     0.007030     0.008611  \n",
       "34         0.005765     0.013418     0.325551     0.013237  \n",
       "35         0.001828     0.004227     0.006881     0.001942  \n",
       "36         0.016160     0.025630     0.010900     0.000418  \n",
       "37         0.045456     0.421024     0.024555     0.003808  \n",
       "38         0.007684     0.037613     0.048948     0.005508  \n",
       "39         0.013979     0.010209     0.032809     0.004590  \n",
       "40         0.740598     0.498759     0.228457     0.002571  \n",
       "41         0.197041     0.237816     0.044499     0.175676  \n",
       "42         0.004197     0.087336     0.014724     0.004115  \n",
       "43         0.002800     0.012232     0.017406     0.003304  \n",
       "44         0.000521     0.000803     0.002026     0.000755  \n",
       "45         0.010785     0.066380     0.028779     0.004763  \n",
       "46         0.002424     0.007500     0.016930     0.000940  \n",
       "47         0.006145     0.449107     0.003922     0.007653  \n",
       "48         0.001973     0.006076     0.005038     0.000577  \n",
       "49         0.001941     0.005182     0.002502     0.001098  \n",
       "...             ...          ...          ...          ...  \n",
       "128326     0.005382     0.054562     0.011925     0.008779  \n",
       "128327     0.004339     0.008718     0.002831     0.004079  \n",
       "128328     0.005647     0.013265     0.004359     0.215025  \n",
       "128329     0.002032     0.015847     0.003152     0.003976  \n",
       "128330     0.049274     0.074024     0.015709     0.044146  \n",
       "128331     0.008106     0.072064     0.006922     0.005568  \n",
       "128332     0.018713     0.100377     0.029920     0.006518  \n",
       "128333     0.017115     0.062541     0.016116     0.064723  \n",
       "128334     0.009177     0.007198     0.007036     0.001157  \n",
       "128335     0.014493     0.007074     0.001163     0.003044  \n",
       "128336     0.004610     0.012642     0.002174     0.001671  \n",
       "128337     0.006515     0.006562     0.003973     0.000612  \n",
       "128338     0.009468     0.021982     0.177396     0.001938  \n",
       "128339     0.012451     0.070297     0.006340     0.005438  \n",
       "128340     0.008145     0.023784     0.002128     0.006269  \n",
       "128341     0.049452     0.032126     0.012837     0.004820  \n",
       "128342     0.004445     0.010467     0.010489     0.000863  \n",
       "128343     0.007304     0.012620     0.002342     0.002811  \n",
       "128344     0.038577     0.040436     0.005771     0.008786  \n",
       "128345     0.013406     0.015612     0.004984     0.004386  \n",
       "128346     0.008744     0.049811     0.016941     0.002285  \n",
       "128347     0.002448     0.004171     0.001916     0.001022  \n",
       "128348     0.002708     0.017346     0.003463     0.001632  \n",
       "128349     0.024107     0.037300     0.003321     0.006926  \n",
       "128350     0.006390     0.013749     0.003901     0.001024  \n",
       "128351     0.015806     0.098994     0.008172     0.013121  \n",
       "128352     0.003651     0.007760     0.001530     0.006040  \n",
       "128353     0.009302     0.165185     0.011576     0.007432  \n",
       "128354     0.339753     0.152753     0.029955     0.008456  \n",
       "128355     0.010862     0.030409     0.009747     0.009050  \n",
       "128356     0.010128     0.048703     0.001470     0.001046  \n",
       "128357     0.004573     0.006151     0.001621     0.001261  \n",
       "128358     0.006583     0.156346     0.006832     0.005185  \n",
       "128359     0.005085     0.030021     0.011168     0.001554  \n",
       "128360     0.011587     0.046937     0.216458     0.001777  \n",
       "128361     0.025825     0.012788     0.006733     0.003034  \n",
       "128362     0.110573     0.135838     0.037125     0.007718  \n",
       "128363     0.041289     0.035399     0.017175     0.003671  \n",
       "128364     0.490533     0.009289     0.006422     0.002351  \n",
       "128365     0.111429     0.026332     0.017235     0.001615  \n",
       "128366     0.005754     0.060603     0.004414     0.002576  \n",
       "128367     0.004462     0.013002     0.002305     0.001448  \n",
       "128368     0.018301     0.069932     0.007339     0.002906  \n",
       "128369     0.010174     0.042982     0.003362     0.002097  \n",
       "128370     0.012200     0.021474     0.002125     0.003932  \n",
       "128371     0.004965     0.015353     0.005677     0.001092  \n",
       "128372     0.003940     0.022115     0.002498     0.004024  \n",
       "128373     0.001495     0.002571     0.001304     0.001387  \n",
       "128374     0.001882     0.008992     0.017845     0.001102  \n",
       "128375     0.030299     0.032823     0.015211     0.001270  \n",
       "\n",
       "[128376 rows x 28 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_plus_oof_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3rcdjjRyw9qSh6NcZMKSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y56uzwqQzynHYZ4bDfLPp5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xDMdFERmC7CD9yFvyvKJnh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzZENdjz7SvUQkGZV45afF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zFWkhHbLYJ9Fh5kUvCrx4g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Z9668Qr6T63NGv2vshFZ22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iibUNHJdKdwir3YoN23fYB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mRUYb9nmdychPJVDTmTuEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Svsd4RkZcFTcnnhHTrtto4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2EvrkYaUPmeQxnk6RiVQb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5tZuLssiSvTz6parm5st3Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HxC7Jz66uEfzDp3FmmJfkY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UhScGN7ZDDutGeT5T4EsVo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FY4jDHwCJNoBnGHVUeGgy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PmaB926DFLPNkGKjQJVieJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iXoHx4Afpa6KwFVzeRoTwP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xMwVHN4T8LCDYoeN2by55A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qo5QysbFHDfJReD5VrC3NQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HovNFU3nwArY28rUvBd3SJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TyUa69smDm5AVp2yWnzyUJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8xwyY6xyqtyLmowe475MW6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M6ouG87EQRkw9hFJoSMdRV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XjegnSPJLErpCkVUiqJxSU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XKy5emoTL2TNFvDDtBzKjj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Z2Eksv2hZkn2n9KANkBYtX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>w6S4dFJWKLNazv5rMjY5f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MZagg4orrhSw4jhazzqtLQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hGA9WhRvr8SUqSLE3pq27c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>iZu7zUExZtxuPawmKVxvB6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gfPaZCYs39PzLEBWqAvBtf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nEGeLzfBNL2pzCSrJncSjA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ZJDrCt4Xz6EUEoSB5a9iJB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nnj7tfbSJra8yPBFu6TDi5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KhXWitDjjAFkop36jz9sAd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>J2hWRtYBCat69QF6pn54hR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wwBo844JEkiwK2MDBKJvnD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>V4yVh9axGqpxioM33KL5vV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KXSXNxMbAZDJYb8PuePY2h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>WyeD4MgTQr9Jw3BLN8Kpfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>985Cz7UZBvH8MmuC4VEx8S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>raeKhHCqEs5t4pRouomkcT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FHYjLx7xtjFWHbhqBAMyqD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>V8CTXLWUFUKZv5PSGXBKqJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6BCFWRhSTezTuvZHa2CmDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>96yYKks6EdyM4T7qDPFXEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2QpRAe5oKeX4ChkNpv2MvB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>qdfoF36hUUeg9DZX9UbAeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ew9UHoRPy6B76qgk4uKbe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RjBBBvToqCw8VVHMspweWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>msddw6HzRYiWtrLXvzrrA7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96455</th>\n",
       "      <td>ygxW6s2AC3mScTZXoiZKic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96456</th>\n",
       "      <td>jCoT9mfdjf5X3VKeqc3erG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96457</th>\n",
       "      <td>ugqMGK2FtSSzhy4J539M7j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96458</th>\n",
       "      <td>6fWbyQ4cCfbkg4APanPk4V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96459</th>\n",
       "      <td>yaSityeYfqPHpi82sM7hFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96460</th>\n",
       "      <td>ejVQUZ2V2ytdcWZXR4BWBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96461</th>\n",
       "      <td>Kz5rJMqd6CMRDiLwkmMQXd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96462</th>\n",
       "      <td>YaZ43yPa5q8efHgTFMEfRc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96463</th>\n",
       "      <td>4VfXynqT2jT5qD6kgNHJxH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96464</th>\n",
       "      <td>yLkE3GMnrRiXDSCdXThcZk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96465</th>\n",
       "      <td>R4yoM2YHpbZYk9MpwHKsYg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96466</th>\n",
       "      <td>9j5PLZQaiojdkX3Wk3UTfk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96467</th>\n",
       "      <td>B8m9eqJBN9MPwYvuyjzVPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96468</th>\n",
       "      <td>DQDkJQBaiUaKMeRx6w6qCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96469</th>\n",
       "      <td>ThZdTheWpWZMUhRQJytRB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96470</th>\n",
       "      <td>jkBHJPbcZbxVgVcS2wexJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96471</th>\n",
       "      <td>J8cc5bwf3NqE2mMbwNRHCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96472</th>\n",
       "      <td>bh2YcrMY5JoNA3UhefUD9U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96473</th>\n",
       "      <td>XDhQ3MobNJRjwij5rrBEuJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96474</th>\n",
       "      <td>iKRY2NiD9oD4WLUoD3vbq2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96475</th>\n",
       "      <td>wcDZSBvuX2Y3G5KEkacBGU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96476</th>\n",
       "      <td>UDQqnguFReLfJNsKbJG94Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96477</th>\n",
       "      <td>AoAAKaxQFVdWtyCFrNNZS8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96478</th>\n",
       "      <td>vr4EKfTUrNRGNhyAvNTPJb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96479</th>\n",
       "      <td>XjyPKEeKFFmPmytCM35Nxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96480</th>\n",
       "      <td>SeyEuYcCra5dHdk7oZjU6F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96481</th>\n",
       "      <td>WHu2NhBNu3Pdcr7C8n8VN9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96482</th>\n",
       "      <td>TP8evPxviYBDkd78yVyzS6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96483</th>\n",
       "      <td>VsE8YBTWC5LZN2WcrVdTWo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96484</th>\n",
       "      <td>XKwDTAwNLG4CRBgbkrTaWH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96485</th>\n",
       "      <td>qb47GGmKMWUSgMcAaqLiyF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96486</th>\n",
       "      <td>rDAsqctcYNNd2H6KpDsLha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96487</th>\n",
       "      <td>ch9dwK78Pudohwf2NxDnFk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96488</th>\n",
       "      <td>PDEVpknCprxxZpc959D6yB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96489</th>\n",
       "      <td>qRGYb3tBXgoUE6p6BgVrdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96490</th>\n",
       "      <td>KQ4BNJnvahptZu9hS8VQJ7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96491</th>\n",
       "      <td>BBshmju8bQqtXjPcKSFyQE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96492</th>\n",
       "      <td>FHEoJBL6Na93eUHow6mMx5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96493</th>\n",
       "      <td>RUFbfqJFFVHmt6b7ajizCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96494</th>\n",
       "      <td>ZQfwhQaURx5vJBpdLJgaz8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96495</th>\n",
       "      <td>M6srBckskjzzu6TfJM9rAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96496</th>\n",
       "      <td>29aVtMnjVNJ77iLGBe3jq6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96497</th>\n",
       "      <td>7sWVKTdKQh8itKEKdV82m8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96498</th>\n",
       "      <td>z48CbjWJGHmEvUXo22GL4H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499</th>\n",
       "      <td>8TszNXCs79zaK5X3f9Psvm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96500</th>\n",
       "      <td>PMDTVvzExc6nMHnS8y5UV8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96501</th>\n",
       "      <td>djcxSQDVYtDZrFYJLteAwS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96502</th>\n",
       "      <td>XbGdy3cKdHS2i2Shr2Tcze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96503</th>\n",
       "      <td>ZtMf5Wd6itWKuoL5hu4vjh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96504</th>\n",
       "      <td>9MRdDyT4E8H9ZznRkdMXVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  purchase_id\n",
       "0      C3rcdjjRyw9qSh6NcZMKSX\n",
       "1      Y56uzwqQzynHYZ4bDfLPp5\n",
       "2      xDMdFERmC7CD9yFvyvKJnh\n",
       "3      zzZENdjz7SvUQkGZV45afF\n",
       "4      zFWkhHbLYJ9Fh5kUvCrx4g\n",
       "5      Z9668Qr6T63NGv2vshFZ22\n",
       "6      iibUNHJdKdwir3YoN23fYB\n",
       "7      mRUYb9nmdychPJVDTmTuEM\n",
       "8      Svsd4RkZcFTcnnhHTrtto4\n",
       "9      2EvrkYaUPmeQxnk6RiVQb7\n",
       "10     5tZuLssiSvTz6parm5st3Z\n",
       "11     HxC7Jz66uEfzDp3FmmJfkY\n",
       "12     UhScGN7ZDDutGeT5T4EsVo\n",
       "13     FY4jDHwCJNoBnGHVUeGgy2\n",
       "14     PmaB926DFLPNkGKjQJVieJ\n",
       "15     iXoHx4Afpa6KwFVzeRoTwP\n",
       "16     xMwVHN4T8LCDYoeN2by55A\n",
       "17     qo5QysbFHDfJReD5VrC3NQ\n",
       "18     HovNFU3nwArY28rUvBd3SJ\n",
       "19     TyUa69smDm5AVp2yWnzyUJ\n",
       "20     8xwyY6xyqtyLmowe475MW6\n",
       "21     M6ouG87EQRkw9hFJoSMdRV\n",
       "22     XjegnSPJLErpCkVUiqJxSU\n",
       "23     XKy5emoTL2TNFvDDtBzKjj\n",
       "24     Z2Eksv2hZkn2n9KANkBYtX\n",
       "25     w6S4dFJWKLNazv5rMjY5f9\n",
       "26     MZagg4orrhSw4jhazzqtLQ\n",
       "27     hGA9WhRvr8SUqSLE3pq27c\n",
       "28     iZu7zUExZtxuPawmKVxvB6\n",
       "29     gfPaZCYs39PzLEBWqAvBtf\n",
       "30     nEGeLzfBNL2pzCSrJncSjA\n",
       "31     ZJDrCt4Xz6EUEoSB5a9iJB\n",
       "32     Nnj7tfbSJra8yPBFu6TDi5\n",
       "33     KhXWitDjjAFkop36jz9sAd\n",
       "34     J2hWRtYBCat69QF6pn54hR\n",
       "35     wwBo844JEkiwK2MDBKJvnD\n",
       "36     V4yVh9axGqpxioM33KL5vV\n",
       "37     KXSXNxMbAZDJYb8PuePY2h\n",
       "38     WyeD4MgTQr9Jw3BLN8Kpfc\n",
       "39     985Cz7UZBvH8MmuC4VEx8S\n",
       "40     raeKhHCqEs5t4pRouomkcT\n",
       "41     FHYjLx7xtjFWHbhqBAMyqD\n",
       "42     V8CTXLWUFUKZv5PSGXBKqJ\n",
       "43     6BCFWRhSTezTuvZHa2CmDV\n",
       "44     96yYKks6EdyM4T7qDPFXEX\n",
       "45     2QpRAe5oKeX4ChkNpv2MvB\n",
       "46     qdfoF36hUUeg9DZX9UbAeA\n",
       "47     ew9UHoRPy6B76qgk4uKbe7\n",
       "48     RjBBBvToqCw8VVHMspweWY\n",
       "49     msddw6HzRYiWtrLXvzrrA7\n",
       "...                       ...\n",
       "96455  ygxW6s2AC3mScTZXoiZKic\n",
       "96456  jCoT9mfdjf5X3VKeqc3erG\n",
       "96457  ugqMGK2FtSSzhy4J539M7j\n",
       "96458  6fWbyQ4cCfbkg4APanPk4V\n",
       "96459  yaSityeYfqPHpi82sM7hFB\n",
       "96460  ejVQUZ2V2ytdcWZXR4BWBD\n",
       "96461  Kz5rJMqd6CMRDiLwkmMQXd\n",
       "96462  YaZ43yPa5q8efHgTFMEfRc\n",
       "96463  4VfXynqT2jT5qD6kgNHJxH\n",
       "96464  yLkE3GMnrRiXDSCdXThcZk\n",
       "96465  R4yoM2YHpbZYk9MpwHKsYg\n",
       "96466  9j5PLZQaiojdkX3Wk3UTfk\n",
       "96467  B8m9eqJBN9MPwYvuyjzVPY\n",
       "96468  DQDkJQBaiUaKMeRx6w6qCX\n",
       "96469  ThZdTheWpWZMUhRQJytRB7\n",
       "96470  jkBHJPbcZbxVgVcS2wexJA\n",
       "96471  J8cc5bwf3NqE2mMbwNRHCN\n",
       "96472  bh2YcrMY5JoNA3UhefUD9U\n",
       "96473  XDhQ3MobNJRjwij5rrBEuJ\n",
       "96474  iKRY2NiD9oD4WLUoD3vbq2\n",
       "96475  wcDZSBvuX2Y3G5KEkacBGU\n",
       "96476  UDQqnguFReLfJNsKbJG94Z\n",
       "96477  AoAAKaxQFVdWtyCFrNNZS8\n",
       "96478  vr4EKfTUrNRGNhyAvNTPJb\n",
       "96479  XjyPKEeKFFmPmytCM35Nxi\n",
       "96480  SeyEuYcCra5dHdk7oZjU6F\n",
       "96481  WHu2NhBNu3Pdcr7C8n8VN9\n",
       "96482  TP8evPxviYBDkd78yVyzS6\n",
       "96483  VsE8YBTWC5LZN2WcrVdTWo\n",
       "96484  XKwDTAwNLG4CRBgbkrTaWH\n",
       "96485  qb47GGmKMWUSgMcAaqLiyF\n",
       "96486  rDAsqctcYNNd2H6KpDsLha\n",
       "96487  ch9dwK78Pudohwf2NxDnFk\n",
       "96488  PDEVpknCprxxZpc959D6yB\n",
       "96489  qRGYb3tBXgoUE6p6BgVrdc\n",
       "96490  KQ4BNJnvahptZu9hS8VQJ7\n",
       "96491  BBshmju8bQqtXjPcKSFyQE\n",
       "96492  FHEoJBL6Na93eUHow6mMx5\n",
       "96493  RUFbfqJFFVHmt6b7ajizCT\n",
       "96494  ZQfwhQaURx5vJBpdLJgaz8\n",
       "96495  M6srBckskjzzu6TfJM9rAX\n",
       "96496  29aVtMnjVNJ77iLGBe3jq6\n",
       "96497  7sWVKTdKQh8itKEKdV82m8\n",
       "96498  z48CbjWJGHmEvUXo22GL4H\n",
       "96499  8TszNXCs79zaK5X3f9Psvm\n",
       "96500  PMDTVvzExc6nMHnS8y5UV8\n",
       "96501  djcxSQDVYtDZrFYJLteAwS\n",
       "96502  XbGdy3cKdHS2i2Shr2Tcze\n",
       "96503  ZtMf5Wd6itWKuoL5hu4vjh\n",
       "96504  9MRdDyT4E8H9ZznRkdMXVC\n",
       "\n",
       "[96505 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(f\"{SAME_PATH}\"+f\"Users/td017/kaggle-pipeline/submission/sub_{CASE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>130123</th>\n",
       "      <th>130125</th>\n",
       "      <th>130129</th>\n",
       "      <th>130131</th>\n",
       "      <th>140307</th>\n",
       "      <th>140313</th>\n",
       "      <th>140316</th>\n",
       "      <th>140317</th>\n",
       "      <th>140321</th>\n",
       "      <th>140501</th>\n",
       "      <th>140505</th>\n",
       "      <th>140641</th>\n",
       "      <th>140691</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042795</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.075538</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.020369</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.005576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090819</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.047350</td>\n",
       "      <td>0.117525</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>0.187257</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.017875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.323705</td>\n",
       "      <td>0.046366</td>\n",
       "      <td>0.103646</td>\n",
       "      <td>0.229480</td>\n",
       "      <td>0.220127</td>\n",
       "      <td>0.066207</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.057368</td>\n",
       "      <td>0.040954</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.010490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167181</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.095341</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>0.033731</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.007215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.126402</td>\n",
       "      <td>0.132267</td>\n",
       "      <td>0.101276</td>\n",
       "      <td>0.017438</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.042825</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.006055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.099262</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.041137</td>\n",
       "      <td>0.057723</td>\n",
       "      <td>0.058732</td>\n",
       "      <td>0.035834</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.002456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.128487</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.059742</td>\n",
       "      <td>0.206327</td>\n",
       "      <td>0.222545</td>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.057281</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.136914</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.171049</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>0.075294</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.013710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.080668</td>\n",
       "      <td>0.151837</td>\n",
       "      <td>0.184028</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.073517</td>\n",
       "      <td>0.305394</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>0.031630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.054721</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>0.049302</td>\n",
       "      <td>0.015119</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.016027</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.004423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.104564</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.028988</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.055763</td>\n",
       "      <td>0.031622</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100817</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>0.121846</td>\n",
       "      <td>0.081556</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.056620</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.050131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.166577</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>0.090241</td>\n",
       "      <td>0.053072</td>\n",
       "      <td>0.030469</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.002411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.099918</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.048849</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.029974</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.030679</td>\n",
       "      <td>0.052266</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>0.012611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>0.045735</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.055540</td>\n",
       "      <td>0.011446</td>\n",
       "      <td>0.003106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.211806</td>\n",
       "      <td>0.117204</td>\n",
       "      <td>0.039339</td>\n",
       "      <td>0.029495</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.086002</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.052599</td>\n",
       "      <td>0.263279</td>\n",
       "      <td>0.086932</td>\n",
       "      <td>0.048720</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.352919</td>\n",
       "      <td>0.019525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.106451</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.130015</td>\n",
       "      <td>0.111383</td>\n",
       "      <td>0.132098</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.206090</td>\n",
       "      <td>0.068446</td>\n",
       "      <td>0.055211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.048756</td>\n",
       "      <td>0.086164</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.193947</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>0.047476</td>\n",
       "      <td>0.165175</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.220515</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.171663</td>\n",
       "      <td>0.064231</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>0.002147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.129146</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.066558</td>\n",
       "      <td>0.132913</td>\n",
       "      <td>0.240456</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.042819</td>\n",
       "      <td>0.068861</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>0.031518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.038429</td>\n",
       "      <td>0.015273</td>\n",
       "      <td>0.031004</td>\n",
       "      <td>0.075735</td>\n",
       "      <td>0.024663</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>0.031209</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.063870</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.019856</td>\n",
       "      <td>0.052308</td>\n",
       "      <td>0.109252</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.297949</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>0.162950</td>\n",
       "      <td>0.059002</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.023262</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.002849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.080038</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.057516</td>\n",
       "      <td>0.133254</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.211740</td>\n",
       "      <td>0.057676</td>\n",
       "      <td>0.094327</td>\n",
       "      <td>0.352710</td>\n",
       "      <td>0.254839</td>\n",
       "      <td>0.068237</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>0.028492</td>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.271748</td>\n",
       "      <td>0.017655</td>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.130166</td>\n",
       "      <td>0.032445</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.186307</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.001528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.042717</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.014487</td>\n",
       "      <td>0.020695</td>\n",
       "      <td>0.014446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.050932</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.034623</td>\n",
       "      <td>0.056688</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.012239</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>0.002127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.069331</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.017184</td>\n",
       "      <td>0.063075</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.015764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.171444</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.095231</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.315381</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.127972</td>\n",
       "      <td>0.159178</td>\n",
       "      <td>0.095756</td>\n",
       "      <td>0.113951</td>\n",
       "      <td>0.131232</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>0.036524</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.080181</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>0.072204</td>\n",
       "      <td>0.082253</td>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>0.017122</td>\n",
       "      <td>0.050558</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.007827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.340343</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.153294</td>\n",
       "      <td>0.303341</td>\n",
       "      <td>0.116820</td>\n",
       "      <td>0.043779</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.084678</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.020676</td>\n",
       "      <td>0.058480</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.014538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.034522</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.016242</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.011581</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.211377</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.125497</td>\n",
       "      <td>0.110332</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.077918</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>0.387138</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.296963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.312432</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.019188</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>0.105022</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.035837</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.004416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.347512</td>\n",
       "      <td>0.039918</td>\n",
       "      <td>0.151503</td>\n",
       "      <td>0.306107</td>\n",
       "      <td>0.102454</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.040137</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>0.002840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.063998</td>\n",
       "      <td>0.051933</td>\n",
       "      <td>0.041987</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.011097</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.005558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.042360</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.050202</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.024304</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.027682</td>\n",
       "      <td>0.057889</td>\n",
       "      <td>0.015155</td>\n",
       "      <td>0.007786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.188998</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>0.077542</td>\n",
       "      <td>0.112193</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.067130</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.024907</td>\n",
       "      <td>0.012101</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.120306</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.051322</td>\n",
       "      <td>0.082386</td>\n",
       "      <td>0.907024</td>\n",
       "      <td>0.067375</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.026376</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.173862</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.081952</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.034959</td>\n",
       "      <td>0.078212</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>0.061869</td>\n",
       "      <td>0.149525</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.005477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.136113</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.054892</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.172530</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>0.071316</td>\n",
       "      <td>0.130528</td>\n",
       "      <td>0.080916</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>0.029051</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.048695</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.003498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.150634</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.087646</td>\n",
       "      <td>0.164952</td>\n",
       "      <td>0.172276</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>0.020615</td>\n",
       "      <td>0.402472</td>\n",
       "      <td>0.097202</td>\n",
       "      <td>0.004550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.096884</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.019612</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96455</th>\n",
       "      <td>0.048557</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.038923</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.486664</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96456</th>\n",
       "      <td>0.073521</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.062306</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>0.014802</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.054077</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.005089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96457</th>\n",
       "      <td>0.180438</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.099394</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>0.038796</td>\n",
       "      <td>0.104951</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.036477</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.098094</td>\n",
       "      <td>0.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96458</th>\n",
       "      <td>0.069591</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.034488</td>\n",
       "      <td>0.114734</td>\n",
       "      <td>0.040147</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>0.062619</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96459</th>\n",
       "      <td>0.197073</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.091353</td>\n",
       "      <td>0.117473</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96460</th>\n",
       "      <td>0.230945</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.131467</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.016431</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.042207</td>\n",
       "      <td>0.021612</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.000821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96461</th>\n",
       "      <td>0.037174</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>0.004590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96462</th>\n",
       "      <td>0.062664</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>0.128607</td>\n",
       "      <td>0.120344</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.041684</td>\n",
       "      <td>0.182906</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>0.018144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96463</th>\n",
       "      <td>0.237771</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.274614</td>\n",
       "      <td>0.248228</td>\n",
       "      <td>0.059554</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.052666</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.234921</td>\n",
       "      <td>0.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96464</th>\n",
       "      <td>0.314319</td>\n",
       "      <td>0.165319</td>\n",
       "      <td>0.098928</td>\n",
       "      <td>0.166561</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96465</th>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.129039</td>\n",
       "      <td>0.152873</td>\n",
       "      <td>0.094006</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.013231</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96466</th>\n",
       "      <td>0.173668</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.145612</td>\n",
       "      <td>0.237075</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.066376</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.004392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96467</th>\n",
       "      <td>0.027145</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.037224</td>\n",
       "      <td>0.116273</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96468</th>\n",
       "      <td>0.105471</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.078794</td>\n",
       "      <td>0.162988</td>\n",
       "      <td>0.114305</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.086578</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.010963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96469</th>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.049019</td>\n",
       "      <td>0.114242</td>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.039377</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.002450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96470</th>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.054091</td>\n",
       "      <td>0.300184</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>0.038776</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96471</th>\n",
       "      <td>0.232121</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.167839</td>\n",
       "      <td>0.437563</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.095916</td>\n",
       "      <td>0.100115</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.055575</td>\n",
       "      <td>0.337808</td>\n",
       "      <td>0.121013</td>\n",
       "      <td>0.020068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96472</th>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>0.055399</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.009821</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.020958</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96473</th>\n",
       "      <td>0.097538</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.047984</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.081957</td>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.060134</td>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.014137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96474</th>\n",
       "      <td>0.119445</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>0.108478</td>\n",
       "      <td>0.198050</td>\n",
       "      <td>0.090230</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.014922</td>\n",
       "      <td>0.138151</td>\n",
       "      <td>0.044857</td>\n",
       "      <td>0.020791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96475</th>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.042814</td>\n",
       "      <td>0.027517</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.004782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96476</th>\n",
       "      <td>0.274183</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.150763</td>\n",
       "      <td>0.459550</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>0.043801</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.015813</td>\n",
       "      <td>0.038325</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.277086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96477</th>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.034740</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.345968</td>\n",
       "      <td>0.168639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96478</th>\n",
       "      <td>0.072587</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.065332</td>\n",
       "      <td>0.066110</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96479</th>\n",
       "      <td>0.058927</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.047253</td>\n",
       "      <td>0.122417</td>\n",
       "      <td>0.045284</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96480</th>\n",
       "      <td>0.147239</td>\n",
       "      <td>0.080359</td>\n",
       "      <td>0.104638</td>\n",
       "      <td>0.125924</td>\n",
       "      <td>0.200528</td>\n",
       "      <td>0.064555</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>0.031964</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96481</th>\n",
       "      <td>0.165993</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.052431</td>\n",
       "      <td>0.224482</td>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.014445</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.038557</td>\n",
       "      <td>0.036175</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96482</th>\n",
       "      <td>0.107379</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>0.231032</td>\n",
       "      <td>0.015776</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.078389</td>\n",
       "      <td>0.105467</td>\n",
       "      <td>0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96483</th>\n",
       "      <td>0.118548</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.105996</td>\n",
       "      <td>0.131018</td>\n",
       "      <td>0.058172</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96484</th>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.015772</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.035536</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.006176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96485</th>\n",
       "      <td>0.123758</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.098742</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.033687</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.012159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96486</th>\n",
       "      <td>0.030832</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.173563</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96487</th>\n",
       "      <td>0.185066</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>0.106758</td>\n",
       "      <td>0.195566</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>0.037331</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96488</th>\n",
       "      <td>0.201313</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>0.184395</td>\n",
       "      <td>0.232245</td>\n",
       "      <td>0.040329</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96489</th>\n",
       "      <td>0.107793</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.062329</td>\n",
       "      <td>0.101897</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96490</th>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.029627</td>\n",
       "      <td>0.063595</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.017947</td>\n",
       "      <td>0.038978</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96491</th>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.056967</td>\n",
       "      <td>0.102131</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96492</th>\n",
       "      <td>0.121778</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.077420</td>\n",
       "      <td>0.118110</td>\n",
       "      <td>0.403086</td>\n",
       "      <td>0.054635</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96493</th>\n",
       "      <td>0.078087</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>0.011949</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.040788</td>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.131084</td>\n",
       "      <td>0.013319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96494</th>\n",
       "      <td>0.049527</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.026931</td>\n",
       "      <td>0.046606</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96495</th>\n",
       "      <td>0.117563</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.045058</td>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>0.033412</td>\n",
       "      <td>0.011022</td>\n",
       "      <td>0.010649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96496</th>\n",
       "      <td>0.175513</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0.109947</td>\n",
       "      <td>0.070705</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96497</th>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.068717</td>\n",
       "      <td>0.024459</td>\n",
       "      <td>0.002569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96498</th>\n",
       "      <td>0.107952</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.161857</td>\n",
       "      <td>0.030994</td>\n",
       "      <td>0.070742</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.020501</td>\n",
       "      <td>0.063058</td>\n",
       "      <td>0.040538</td>\n",
       "      <td>0.008043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96499</th>\n",
       "      <td>0.043992</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.004923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96500</th>\n",
       "      <td>0.053508</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.030783</td>\n",
       "      <td>0.103432</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.032688</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.005879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96501</th>\n",
       "      <td>0.106243</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.248910</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.030781</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.423565</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96502</th>\n",
       "      <td>0.049293</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.088189</td>\n",
       "      <td>0.070838</td>\n",
       "      <td>0.042045</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.025107</td>\n",
       "      <td>0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96503</th>\n",
       "      <td>0.059383</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.010303</td>\n",
       "      <td>0.022335</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96504</th>\n",
       "      <td>0.070795</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.049920</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.053212</td>\n",
       "      <td>0.045778</td>\n",
       "      <td>0.006550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96505 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         130123    130125    130129    130131    140307    140313    140316  \\\n",
       "0      0.042795  0.008072  0.044920  0.075538  0.029594  0.005687  0.004447   \n",
       "1      0.090819  0.003865  0.047350  0.117525  0.028424  0.011816  0.006330   \n",
       "2      0.323705  0.046366  0.103646  0.229480  0.220127  0.066207  0.008966   \n",
       "3      0.167181  0.017403  0.028166  0.095341  0.034591  0.030649  0.006882   \n",
       "4      0.105407  0.008992  0.044733  0.126402  0.132267  0.101276  0.017438   \n",
       "5      0.099262  0.019071  0.041137  0.057723  0.058732  0.035834  0.004104   \n",
       "6      0.128487  0.005663  0.059742  0.206327  0.222545  0.026293  0.013037   \n",
       "7      0.136914  0.009147  0.057692  0.171049  0.062655  0.012230  0.008691   \n",
       "8      0.033420  0.006795  0.080668  0.151837  0.184028  0.035436  0.005460   \n",
       "9      0.054721  0.017734  0.026444  0.049302  0.015119  0.011112  0.003171   \n",
       "10     0.104564  0.009744  0.015389  0.028988  0.016226  0.014917  0.004731   \n",
       "11     0.100817  0.006253  0.064425  0.121846  0.081556  0.027382  0.005772   \n",
       "12     0.166577  0.017197  0.064161  0.090241  0.053072  0.030469  0.004940   \n",
       "13     0.099918  0.009172  0.035082  0.048849  0.034978  0.029974  0.003013   \n",
       "14     0.182753  0.015151  0.047518  0.108445  0.059056  0.045735  0.013443   \n",
       "15     0.211806  0.117204  0.039339  0.029495  0.039553  0.038394  0.004586   \n",
       "16     0.086002  0.014392  0.052599  0.263279  0.086932  0.048720  0.021252   \n",
       "17     0.106451  0.006438  0.056373  0.130015  0.111383  0.132098  0.005058   \n",
       "18     0.048756  0.086164  0.018527  0.025565  0.012538  0.010257  0.006331   \n",
       "19     0.193947  0.006386  0.040310  0.047476  0.165175  0.012711  0.007377   \n",
       "20     0.220515  0.009234  0.071343  0.171663  0.064231  0.062447  0.012722   \n",
       "21     0.129146  0.012970  0.066558  0.132913  0.240456  0.061353  0.012823   \n",
       "22     0.038429  0.015273  0.031004  0.075735  0.024663  0.013716  0.002814   \n",
       "23     0.063870  0.003382  0.019856  0.052308  0.109252  0.040317  0.008281   \n",
       "24     0.297949  0.014682  0.131278  0.162950  0.059002  0.016053  0.014128   \n",
       "25     0.080038  0.009393  0.057516  0.133254  0.031374  0.018267  0.013521   \n",
       "26     0.211740  0.057676  0.094327  0.352710  0.254839  0.068237  0.036123   \n",
       "27     0.271748  0.017655  0.056752  0.130166  0.032445  0.043603  0.008456   \n",
       "28     0.042717  0.005244  0.018603  0.024985  0.008840  0.008775  0.003461   \n",
       "29     0.050932  0.004948  0.034623  0.056688  0.027683  0.011929  0.002823   \n",
       "30     0.101355  0.006145  0.031855  0.069331  0.040973  0.033139  0.009732   \n",
       "31     0.171444  0.016787  0.056106  0.095231  0.071130  0.019790  0.010381   \n",
       "32     0.315381  0.008926  0.127972  0.159178  0.095756  0.113951  0.131232   \n",
       "33     0.080181  0.016179  0.026985  0.072204  0.082253  0.042775  0.010262   \n",
       "34     0.340343  0.010060  0.153294  0.303341  0.116820  0.043779  0.033930   \n",
       "35     0.084678  0.008109  0.020676  0.058480  0.085006  0.010218  0.003936   \n",
       "36     0.034522  0.002452  0.009310  0.017205  0.016242  0.021392  0.002012   \n",
       "37     0.211377  0.011907  0.125497  0.110332  0.054976  0.032165  0.005934   \n",
       "38     0.061174  0.004070  0.019102  0.077918  0.036114  0.005850  0.001513   \n",
       "39     0.312432  0.010949  0.019188  0.071015  0.105022  0.028424  0.035837   \n",
       "40     0.347512  0.039918  0.151503  0.306107  0.102454  0.043200  0.015561   \n",
       "41     0.066426  0.005070  0.063998  0.051933  0.041987  0.021338  0.009866   \n",
       "42     0.042360  0.006657  0.027601  0.050202  0.039053  0.024304  0.003156   \n",
       "43     0.188998  0.014519  0.077542  0.112193  0.040506  0.067130  0.015556   \n",
       "44     0.120306  0.014608  0.051322  0.082386  0.907024  0.067375  0.009788   \n",
       "45     0.081952  0.003992  0.034959  0.078212  0.078947  0.032229  0.006191   \n",
       "46     0.136113  0.006796  0.065740  0.073047  0.054892  0.017307  0.006371   \n",
       "47     0.172530  0.006572  0.071316  0.130528  0.080916  0.031367  0.029051   \n",
       "48     0.150634  0.012285  0.087646  0.164952  0.172276  0.029260  0.012828   \n",
       "49     0.096884  0.007174  0.040727  0.100200  0.036134  0.023025  0.006957   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "96455  0.048557  0.003892  0.038923  0.071558  0.486664  0.009955  0.003459   \n",
       "96456  0.073521  0.004278  0.021330  0.062306  0.044584  0.014802  0.004820   \n",
       "96457  0.180438  0.003737  0.099394  0.126359  0.038796  0.104951  0.041513   \n",
       "96458  0.069591  0.012016  0.034488  0.114734  0.040147  0.012374  0.016897   \n",
       "96459  0.197073  0.005102  0.091353  0.117473  0.009526  0.008718  0.002558   \n",
       "96460  0.230945  0.020204  0.125874  0.131467  0.032719  0.032472  0.016431   \n",
       "96461  0.037174  0.005949  0.033917  0.021935  0.014531  0.012787  0.004814   \n",
       "96462  0.062664  0.002968  0.024903  0.128607  0.120344  0.027786  0.009366   \n",
       "96463  0.237771  0.015701  0.274614  0.248228  0.059554  0.073954  0.011304   \n",
       "96464  0.314319  0.165319  0.098928  0.166561  0.057668  0.106491  0.012338   \n",
       "96465  0.388519  0.029385  0.129039  0.152873  0.094006  0.017425  0.003014   \n",
       "96466  0.173668  0.030600  0.145612  0.237075  0.037988  0.066376  0.003188   \n",
       "96467  0.027145  0.002060  0.037224  0.116273  0.136141  0.020291  0.008576   \n",
       "96468  0.105471  0.005804  0.078794  0.162988  0.114305  0.024240  0.010474   \n",
       "96469  0.067677  0.002586  0.049019  0.114242  0.024445  0.011863  0.008150   \n",
       "96470  0.071086  0.001748  0.054091  0.300184  0.011856  0.038776  0.001878   \n",
       "96471  0.232121  0.022676  0.167839  0.437563  0.089041  0.095916  0.100115   \n",
       "96472  0.084001  0.008610  0.055399  0.083286  0.063478  0.034427  0.005972   \n",
       "96473  0.097538  0.009461  0.047984  0.200250  0.081957  0.040105  0.008384   \n",
       "96474  0.119445  0.044293  0.108478  0.198050  0.090230  0.019824  0.006790   \n",
       "96475  0.025564  0.002587  0.023036  0.042814  0.027517  0.031627  0.007205   \n",
       "96476  0.274183  0.030063  0.150763  0.459550  0.029106  0.043801  0.006762   \n",
       "96477  0.032663  0.026347  0.017576  0.034740  0.024386  0.004045  0.001540   \n",
       "96478  0.072587  0.005975  0.065332  0.066110  0.009860  0.011236  0.011295   \n",
       "96479  0.058927  0.003662  0.047253  0.122417  0.045284  0.025163  0.005646   \n",
       "96480  0.147239  0.080359  0.104638  0.125924  0.200528  0.064555  0.010790   \n",
       "96481  0.165993  0.010411  0.052431  0.224482  0.052678  0.014445  0.002959   \n",
       "96482  0.107379  0.003277  0.091503  0.231032  0.015776  0.011669  0.004791   \n",
       "96483  0.118548  0.005229  0.105996  0.131018  0.058172  0.015859  0.007352   \n",
       "96484  0.014739  0.001644  0.015772  0.024835  0.016701  0.035536  0.007389   \n",
       "96485  0.123758  0.008521  0.098742  0.140079  0.140159  0.019775  0.004331   \n",
       "96486  0.030832  0.003710  0.015016  0.173563  0.007352  0.041096  0.009900   \n",
       "96487  0.185066  0.019624  0.106758  0.195566  0.042986  0.037331  0.004407   \n",
       "96488  0.201313  0.004288  0.051835  0.184395  0.232245  0.040329  0.008025   \n",
       "96489  0.107793  0.006653  0.062329  0.101897  0.015767  0.004670  0.006021   \n",
       "96490  0.036511  0.002109  0.029627  0.063595  0.020191  0.010482  0.003101   \n",
       "96491  0.077590  0.002903  0.056967  0.102131  0.037591  0.013894  0.003793   \n",
       "96492  0.121778  0.006796  0.077420  0.118110  0.403086  0.054635  0.004684   \n",
       "96493  0.078087  0.003100  0.038195  0.053085  0.009594  0.011949  0.001975   \n",
       "96494  0.049527  0.002249  0.026931  0.046606  0.025993  0.023008  0.003331   \n",
       "96495  0.117563  0.004487  0.046986  0.149927  0.045058  0.031166  0.003887   \n",
       "96496  0.175513  0.003965  0.063738  0.109947  0.070705  0.020006  0.008573   \n",
       "96497  0.022654  0.002016  0.011848  0.020725  0.007041  0.008433  0.001944   \n",
       "96498  0.107952  0.003194  0.068601  0.161857  0.030994  0.070742  0.005233   \n",
       "96499  0.043992  0.003827  0.011752  0.035322  0.005502  0.006697  0.001441   \n",
       "96500  0.053508  0.002792  0.030783  0.103432  0.033406  0.032688  0.009080   \n",
       "96501  0.106243  0.003257  0.034115  0.248910  0.051528  0.030781  0.002298   \n",
       "96502  0.049293  0.002070  0.035655  0.088189  0.070838  0.042045  0.006071   \n",
       "96503  0.059383  0.004016  0.024632  0.072763  0.016293  0.013684  0.003121   \n",
       "96504  0.070795  0.006616  0.049920  0.073618  0.028349  0.013171  0.001936   \n",
       "\n",
       "         140317    140321    140501    140505    140641    140691  \n",
       "0      0.002987  0.002774  0.012397  0.020369  0.008170  0.005576  \n",
       "1      0.004481  0.007744  0.436611  0.187257  0.022193  0.017875  \n",
       "2      0.004073  0.009962  0.057368  0.040954  0.013544  0.010490  \n",
       "3      0.017626  0.008788  0.016519  0.033731  0.031762  0.007215  \n",
       "4      0.008195  0.002917  0.012300  0.042825  0.021837  0.006055  \n",
       "5      0.002495  0.020174  0.025337  0.015087  0.035804  0.002456  \n",
       "6      0.002189  0.002710  0.008197  0.057281  0.021603  0.001783  \n",
       "7      0.007490  0.010347  0.046487  0.075294  0.016096  0.013710  \n",
       "8      0.004728  0.007447  0.073517  0.305394  0.083369  0.031630  \n",
       "9      0.006107  0.007654  0.007373  0.016027  0.015609  0.004423  \n",
       "10     0.005997  0.004336  0.055763  0.031622  0.017697  0.006706  \n",
       "11     0.005319  0.007165  0.056620  0.123320  0.005470  0.050131  \n",
       "12     0.003965  0.004068  0.003637  0.011601  0.005946  0.002411  \n",
       "13     0.006661  0.005341  0.030679  0.052266  0.041487  0.012611  \n",
       "14     0.006837  0.004656  0.059339  0.055540  0.011446  0.003106  \n",
       "15     0.004019  0.005571  0.002612  0.002576  0.002311  0.000708  \n",
       "16     0.003493  0.005477  0.014093  0.030430  0.352919  0.019525  \n",
       "17     0.014084  0.030162  0.066541  0.206090  0.068446  0.055211  \n",
       "18     0.003422  0.005070  0.008914  0.008316  0.003527  0.001923  \n",
       "19     0.002152  0.002788  0.002837  0.006713  0.005745  0.001747  \n",
       "20     0.014134  0.002906  0.005910  0.045648  0.012734  0.002147  \n",
       "21     0.004060  0.042819  0.068861  0.189152  0.026263  0.031518  \n",
       "22     0.002487  0.012776  0.094459  0.031209  0.028882  0.008500  \n",
       "23     0.004986  0.004009  0.006602  0.010880  0.004314  0.001709  \n",
       "24     0.011195  0.012897  0.011600  0.023262  0.008880  0.002849  \n",
       "25     0.015111  0.008979  0.006714  0.041667  0.022177  0.004410  \n",
       "26     0.015164  0.011849  0.017771  0.037768  0.028492  0.006710  \n",
       "27     0.002693  0.014567  0.006956  0.186307  0.017714  0.001528  \n",
       "28     0.006649  0.006527  0.005637  0.014487  0.020695  0.014446  \n",
       "29     0.008833  0.012239  0.006519  0.006416  0.014217  0.002127  \n",
       "30     0.011870  0.005436  0.017184  0.063075  0.092369  0.015764  \n",
       "31     0.008410  0.004532  0.005102  0.014592  0.011570  0.001636  \n",
       "32     0.009928  0.003966  0.008921  0.036524  0.005668  0.002099  \n",
       "33     0.005190  0.012832  0.017122  0.050558  0.013498  0.007827  \n",
       "34     0.027520  0.003806  0.001781  0.010361  0.006815  0.000973  \n",
       "35     0.003473  0.006103  0.050441  0.016606  0.016915  0.014538  \n",
       "36     0.011581  0.003651  0.004988  0.013624  0.004475  0.001633  \n",
       "37     0.017803  0.005607  0.010049  0.019070  0.020377  0.003868  \n",
       "38     0.002803  0.019681  0.387138  0.013206  0.007729  0.296963  \n",
       "39     0.004597  0.009102  0.009177  0.007645  0.014726  0.004416  \n",
       "40     0.009448  0.040137  0.006256  0.034100  0.027420  0.002840  \n",
       "41     0.009011  0.008111  0.003617  0.011097  0.014421  0.005558  \n",
       "42     0.004949  0.024171  0.027682  0.057889  0.015155  0.007786  \n",
       "43     0.012210  0.007711  0.016600  0.024907  0.012101  0.000946  \n",
       "44     0.026376  0.003838  0.008643  0.173862  0.009284  0.001172  \n",
       "45     0.005654  0.026220  0.061869  0.149525  0.024889  0.005477  \n",
       "46     0.008741  0.009296  0.006887  0.048403  0.012409  0.003565  \n",
       "47     0.008983  0.004664  0.019373  0.048695  0.008047  0.003498  \n",
       "48     0.004336  0.006052  0.020615  0.402472  0.097202  0.004550  \n",
       "49     0.004628  0.005999  0.019612  0.007653  0.008630  0.004073  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "96455  0.001786  0.001088  0.001963  0.004168  0.001897  0.000871  \n",
       "96456  0.002981  0.002455  0.006884  0.054077  0.004210  0.005089  \n",
       "96457  0.036477  0.003025  0.002506  0.042426  0.098094  0.001039  \n",
       "96458  0.015045  0.010170  0.010207  0.057556  0.062619  0.001857  \n",
       "96459  0.002757  0.002880  0.001814  0.003853  0.006234  0.000820  \n",
       "96460  0.005748  0.003725  0.042207  0.021612  0.006803  0.000821  \n",
       "96461  0.003879  0.006010  0.004262  0.008662  0.046771  0.004590  \n",
       "96462  0.011735  0.018104  0.041684  0.182906  0.044488  0.018144  \n",
       "96463  0.009642  0.016911  0.052666  0.062792  0.234921  0.018600  \n",
       "96464  0.010524  0.002905  0.004622  0.012086  0.016555  0.006411  \n",
       "96465  0.014849  0.003190  0.002615  0.007158  0.013231  0.001694  \n",
       "96466  0.002635  0.002883  0.004304  0.026811  0.005748  0.004392  \n",
       "96467  0.002628  0.001280  0.003090  0.953240  0.006170  0.001712  \n",
       "96468  0.021741  0.008220  0.009976  0.086578  0.012030  0.010963  \n",
       "96469  0.004736  0.002238  0.008767  0.039377  0.016673  0.002450  \n",
       "96470  0.003618  0.000861  0.010664  0.010613  0.048704  0.000817  \n",
       "96471  0.012197  0.012701  0.055575  0.337808  0.121013  0.020068  \n",
       "96472  0.009821  0.001907  0.020958  0.039924  0.026658  0.003077  \n",
       "96473  0.004017  0.005921  0.029033  0.060134  0.077657  0.014137  \n",
       "96474  0.004291  0.004682  0.014922  0.138151  0.044857  0.020791  \n",
       "96475  0.003979  0.003674  0.011757  0.009401  0.041927  0.004782  \n",
       "96476  0.003860  0.005456  0.015813  0.038325  0.010482  0.277086  \n",
       "96477  0.005143  0.008163  0.002713  0.003767  0.345968  0.168639  \n",
       "96478  0.002894  0.003162  0.015010  0.028625  0.099770  0.000987  \n",
       "96479  0.008370  0.001759  0.002549  0.009719  0.005467  0.000553  \n",
       "96480  0.006692  0.003955  0.016560  0.043459  0.031964  0.002857  \n",
       "96481  0.004345  0.008266  0.009296  0.038557  0.036175  0.003077  \n",
       "96482  0.002311  0.005168  0.023933  0.078389  0.105467  0.005373  \n",
       "96483  0.004901  0.004162  0.002225  0.006550  0.004834  0.000863  \n",
       "96484  0.007111  0.000985  0.009794  0.019182  0.016634  0.006176  \n",
       "96485  0.004884  0.003975  0.033687  0.021400  0.017037  0.012159  \n",
       "96486  0.003613  0.002424  0.001245  0.021113  0.009741  0.001053  \n",
       "96487  0.003377  0.004868  0.004686  0.007759  0.013070  0.002277  \n",
       "96488  0.027527  0.001225  0.005386  0.026897  0.006126  0.007700  \n",
       "96489  0.010831  0.002751  0.004817  0.013200  0.011113  0.003319  \n",
       "96490  0.011149  0.003214  0.009726  0.017947  0.038978  0.003241  \n",
       "96491  0.005743  0.004094  0.007534  0.007065  0.011745  0.000841  \n",
       "96492  0.013912  0.001787  0.006157  0.020433  0.005006  0.001087  \n",
       "96493  0.004205  0.005073  0.040788  0.024673  0.131084  0.013319  \n",
       "96494  0.003984  0.002075  0.010201  0.038500  0.010117  0.004148  \n",
       "96495  0.005943  0.003162  0.012039  0.033412  0.011022  0.010649  \n",
       "96496  0.006747  0.002428  0.007870  0.011486  0.009107  0.001316  \n",
       "96497  0.004874  0.002114  0.005868  0.068717  0.024459  0.002569  \n",
       "96498  0.003917  0.005266  0.020501  0.063058  0.040538  0.008043  \n",
       "96499  0.001986  0.003230  0.009044  0.004629  0.006862  0.004923  \n",
       "96500  0.003669  0.001624  0.009790  0.010309  0.010714  0.005879  \n",
       "96501  0.002159  0.001063  0.008414  0.423565  0.002607  0.001302  \n",
       "96502  0.006986  0.003528  0.009249  0.039410  0.025107  0.002371  \n",
       "96503  0.003392  0.002532  0.010303  0.022335  0.004986  0.002314  \n",
       "96504  0.003954  0.002891  0.014301  0.053212  0.045778  0.006550  \n",
       "\n",
       "[96505 rows x 13 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.rename(columns=lambda s: s+\"_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plus_pred = pd.concat([test,y_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_id</th>\n",
       "      <th>130123_pred</th>\n",
       "      <th>130125_pred</th>\n",
       "      <th>130129_pred</th>\n",
       "      <th>130131_pred</th>\n",
       "      <th>140307_pred</th>\n",
       "      <th>140313_pred</th>\n",
       "      <th>140316_pred</th>\n",
       "      <th>140317_pred</th>\n",
       "      <th>140321_pred</th>\n",
       "      <th>140501_pred</th>\n",
       "      <th>140505_pred</th>\n",
       "      <th>140641_pred</th>\n",
       "      <th>140691_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3rcdjjRyw9qSh6NcZMKSX</td>\n",
       "      <td>0.042795</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0.075538</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.020369</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.005576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y56uzwqQzynHYZ4bDfLPp5</td>\n",
       "      <td>0.090819</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.047350</td>\n",
       "      <td>0.117525</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>0.187257</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.017875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xDMdFERmC7CD9yFvyvKJnh</td>\n",
       "      <td>0.323705</td>\n",
       "      <td>0.046366</td>\n",
       "      <td>0.103646</td>\n",
       "      <td>0.229480</td>\n",
       "      <td>0.220127</td>\n",
       "      <td>0.066207</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.057368</td>\n",
       "      <td>0.040954</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.010490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzZENdjz7SvUQkGZV45afF</td>\n",
       "      <td>0.167181</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.095341</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>0.033731</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.007215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zFWkhHbLYJ9Fh5kUvCrx4g</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.126402</td>\n",
       "      <td>0.132267</td>\n",
       "      <td>0.101276</td>\n",
       "      <td>0.017438</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.042825</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.006055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              purchase_id  130123_pred  130125_pred  130129_pred  130131_pred  \\\n",
       "0  C3rcdjjRyw9qSh6NcZMKSX     0.042795     0.008072     0.044920     0.075538   \n",
       "1  Y56uzwqQzynHYZ4bDfLPp5     0.090819     0.003865     0.047350     0.117525   \n",
       "2  xDMdFERmC7CD9yFvyvKJnh     0.323705     0.046366     0.103646     0.229480   \n",
       "3  zzZENdjz7SvUQkGZV45afF     0.167181     0.017403     0.028166     0.095341   \n",
       "4  zFWkhHbLYJ9Fh5kUvCrx4g     0.105407     0.008992     0.044733     0.126402   \n",
       "\n",
       "   140307_pred  140313_pred  140316_pred  140317_pred  140321_pred  \\\n",
       "0     0.029594     0.005687     0.004447     0.002987     0.002774   \n",
       "1     0.028424     0.011816     0.006330     0.004481     0.007744   \n",
       "2     0.220127     0.066207     0.008966     0.004073     0.009962   \n",
       "3     0.034591     0.030649     0.006882     0.017626     0.008788   \n",
       "4     0.132267     0.101276     0.017438     0.008195     0.002917   \n",
       "\n",
       "   140501_pred  140505_pred  140641_pred  140691_pred  \n",
       "0     0.012397     0.020369     0.008170     0.005576  \n",
       "1     0.436611     0.187257     0.022193     0.017875  \n",
       "2     0.057368     0.040954     0.013544     0.010490  \n",
       "3     0.016519     0.033731     0.031762     0.007215  \n",
       "4     0.012300     0.042825     0.021837     0.006055  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_plus_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_plus_oof_pred.columns.tolist()\n",
    "\n",
    "for i in target_list:\n",
    "    features.remove(i)\n",
    "    \n",
    "features.remove('purchase_id')\n",
    "features.remove('months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['130123_pred',\n",
       " '130125_pred',\n",
       " '130129_pred',\n",
       " '130131_pred',\n",
       " '140307_pred',\n",
       " '140313_pred',\n",
       " '140316_pred',\n",
       " '140317_pred',\n",
       " '140321_pred',\n",
       " '140501_pred',\n",
       " '140505_pred',\n",
       " '140641_pred',\n",
       " '140691_pred']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### 1 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.873793\n",
      "1    0.126207\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.866931\n",
      "1    0.133069\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.70749\tvalid_1's auc: 0.509238\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.645007\tvalid_1's auc: 0.510955\n",
      "Partial score of fold 0 is: 0.5109546971236177\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.875437\n",
      "1    0.124563\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.860169\n",
      "1    0.139831\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.709787\tvalid_1's auc: 0.495581\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.534854\tvalid_1's auc: 0.501805\n",
      "Partial score of fold 1 is: 0.501804666861606\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.880546\n",
      "1    0.119454\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.837457\n",
      "1    0.162543\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.710991\tvalid_1's auc: 0.502002\n",
      "[200]\ttraining's auc: 0.775862\tvalid_1's auc: 0.50346\n",
      "[300]\ttraining's auc: 0.818501\tvalid_1's auc: 0.504871\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's auc: 0.815528\tvalid_1's auc: 0.505436\n",
      "Partial score of fold 2 is: 0.5054357109650743\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.867128\n",
      "1    0.132872\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.892627\n",
      "1    0.107373\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.711046\tvalid_1's auc: 0.497786\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.67383\tvalid_1's auc: 0.503094\n",
      "Partial score of fold 3 is: 0.5030939024246427\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.864933\n",
      "1    0.135067\n",
      "Name: 130123, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.901669\n",
      "1    0.098331\n",
      "Name: 130123, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.707203\tvalid_1's auc: 0.498753\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.593468\tvalid_1's auc: 0.505763\n",
      "Partial score of fold 4 is: 0.5057629521354142\n",
      "AUC score is:  0.47607800951246254\n",
      "################### 2 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981708\n",
      "1    0.018292\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.98105\n",
      "1    0.01895\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893162\tvalid_1's auc: 0.509693\n",
      "[200]\ttraining's auc: 0.947532\tvalid_1's auc: 0.500069\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's auc: 0.914702\tvalid_1's auc: 0.511939\n",
      "Partial score of fold 0 is: 0.5119387716659567\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981434\n",
      "1    0.018566\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982158\n",
      "1    0.017842\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.898935\tvalid_1's auc: 0.474129\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.559224\tvalid_1's auc: 0.496892\n",
      "Partial score of fold 1 is: 0.4968917699091777\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981179\n",
      "1    0.018821\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983244\n",
      "1    0.016756\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891223\tvalid_1's auc: 0.474683\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.670764\tvalid_1's auc: 0.504885\n",
      "Partial score of fold 2 is: 0.5048845843294334\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.982171\n",
      "1    0.017829\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.979282\n",
      "1    0.020718\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.895218\tvalid_1's auc: 0.505972\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.721028\tvalid_1's auc: 0.510583\n",
      "Partial score of fold 3 is: 0.5105833313462731\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.981402\n",
      "1    0.018598\n",
      "Name: 130125, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982257\n",
      "1    0.017743\n",
      "Name: 130125, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896291\tvalid_1's auc: 0.478119\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.559674\tvalid_1's auc: 0.496487\n",
      "Partial score of fold 4 is: 0.496486758553029\n",
      "AUC score is:  0.4990452190966985\n",
      "################### 3 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.936164\n",
      "1    0.063836\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931381\n",
      "1    0.068619\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.773713\tvalid_1's auc: 0.496612\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.702587\tvalid_1's auc: 0.497894\n",
      "Partial score of fold 0 is: 0.49789405390510116\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.93549\n",
      "1    0.06451\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.934139\n",
      "1    0.065861\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.774851\tvalid_1's auc: 0.503132\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.541884\tvalid_1's auc: 0.509239\n",
      "Partial score of fold 1 is: 0.5092385258134902\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.934328\n",
      "1    0.065672\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.938661\n",
      "1    0.061339\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.775825\tvalid_1's auc: 0.507662\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.664956\tvalid_1's auc: 0.513586\n",
      "Partial score of fold 2 is: 0.5135856734924943\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.933981\n",
      "1    0.066019\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.93998\n",
      "1    0.06002\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.767782\tvalid_1's auc: 0.503143\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.537847\tvalid_1's auc: 0.503668\n",
      "Partial score of fold 3 is: 0.5036684086956109\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.936113\n",
      "1    0.063887\n",
      "Name: 130129, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931453\n",
      "1    0.068547\n",
      "Name: 130129, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.778005\tvalid_1's auc: 0.505526\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.594404\tvalid_1's auc: 0.514642\n",
      "Partial score of fold 4 is: 0.5146418686900824\n",
      "AUC score is:  0.4995668456656713\n",
      "################### 4 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.848349\n",
      "1    0.151651\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.844265\n",
      "1    0.155735\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.69405\tvalid_1's auc: 0.493497\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5327\tvalid_1's auc: 0.499732\n",
      "Partial score of fold 0 is: 0.4997320260774935\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.849224\n",
      "1    0.150776\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.840709\n",
      "1    0.159291\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.704357\tvalid_1's auc: 0.507286\n",
      "[200]\ttraining's auc: 0.765467\tvalid_1's auc: 0.509008\n",
      "[300]\ttraining's auc: 0.806924\tvalid_1's auc: 0.509086\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's auc: 0.778927\tvalid_1's auc: 0.509811\n",
      "Partial score of fold 1 is: 0.5098114283047548\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846808\n",
      "1    0.153192\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.85062\n",
      "1    0.14938\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.700426\tvalid_1's auc: 0.496934\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.529881\tvalid_1's auc: 0.502743\n",
      "Partial score of fold 2 is: 0.5027429609051083\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846371\n",
      "1    0.153629\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.851993\n",
      "1    0.148007\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.696877\tvalid_1's auc: 0.498978\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.575338\tvalid_1's auc: 0.500462\n",
      "Partial score of fold 3 is: 0.5004622269450406\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.846908\n",
      "1    0.153092\n",
      "Name: 130131, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.849964\n",
      "1    0.150036\n",
      "Name: 130131, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.701383\tvalid_1's auc: 0.497796\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.605347\tvalid_1's auc: 0.508151\n",
      "Partial score of fold 4 is: 0.5081514076723233\n",
      "AUC score is:  0.5030407128556735\n",
      "################### 5 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.910698\n",
      "1    0.089302\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.90939\n",
      "1    0.09061\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.720469\tvalid_1's auc: 0.509381\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's auc: 0.696198\tvalid_1's auc: 0.511384\n",
      "Partial score of fold 0 is: 0.5113836547572054\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.906117\n",
      "1    0.093883\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.928431\n",
      "1    0.071569\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.727854\tvalid_1's auc: 0.499997\n",
      "[200]\ttraining's auc: 0.78813\tvalid_1's auc: 0.505515\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's auc: 0.787284\tvalid_1's auc: 0.505944\n",
      "Partial score of fold 1 is: 0.5059436126738223\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.916028\n",
      "1    0.083972\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.889039\n",
      "1    0.110961\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.734199\tvalid_1's auc: 0.505779\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.663217\tvalid_1's auc: 0.51429\n",
      "Partial score of fold 2 is: 0.5142902526448315\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.908803\n",
      "1    0.091197\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.917141\n",
      "1    0.082859\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.730256\tvalid_1's auc: 0.520329\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.613096\tvalid_1's auc: 0.525671\n",
      "Partial score of fold 3 is: 0.5256714976691179\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.910624\n",
      "1    0.089376\n",
      "Name: 140307, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.909689\n",
      "1    0.090311\n",
      "Name: 140307, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.725676\tvalid_1's auc: 0.506683\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.566579\tvalid_1's auc: 0.511277\n",
      "Partial score of fold 4 is: 0.5112769971113316\n",
      "AUC score is:  0.4992154298402703\n",
      "################### 6 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953892\n",
      "1    0.046108\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956306\n",
      "1    0.043694\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.793497\tvalid_1's auc: 0.511564\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.746567\tvalid_1's auc: 0.513434\n",
      "Partial score of fold 0 is: 0.5134336409989206\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954374\n",
      "1    0.045626\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.954346\n",
      "1    0.045654\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803145\tvalid_1's auc: 0.507699\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.672755\tvalid_1's auc: 0.518331\n",
      "Partial score of fold 1 is: 0.5183314435178252\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.95223\n",
      "1    0.04777\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.963406\n",
      "1    0.036594\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79228\tvalid_1's auc: 0.508049\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.7044\tvalid_1's auc: 0.522462\n",
      "Partial score of fold 2 is: 0.5224622620706199\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.955878\n",
      "1    0.044122\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.948557\n",
      "1    0.051443\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79586\tvalid_1's auc: 0.496237\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.725269\tvalid_1's auc: 0.505375\n",
      "Partial score of fold 3 is: 0.5053748445999604\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.955516\n",
      "1    0.044484\n",
      "Name: 140313, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.949993\n",
      "1    0.050007\n",
      "Name: 140313, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800835\tvalid_1's auc: 0.505009\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.72726\tvalid_1's auc: 0.510998\n",
      "Partial score of fold 4 is: 0.5109978995586257\n",
      "AUC score is:  0.5044101977705092\n",
      "################### 7 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983029\n",
      "1    0.016971\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.98575\n",
      "1    0.01425\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888555\tvalid_1's auc: 0.487976\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.635439\tvalid_1's auc: 0.506024\n",
      "Partial score of fold 0 is: 0.5060236211714881\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983313\n",
      "1    0.016687\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.984619\n",
      "1    0.015381\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.898066\tvalid_1's auc: 0.504044\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.632503\tvalid_1's auc: 0.514605\n",
      "Partial score of fold 1 is: 0.5146049804173611\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98394\n",
      "1    0.01606\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982137\n",
      "1    0.017863\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.900395\tvalid_1's auc: 0.497353\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.619925\tvalid_1's auc: 0.524621\n",
      "Partial score of fold 2 is: 0.5246209247597775\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.984094\n",
      "1    0.015906\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.981387\n",
      "1    0.018613\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896839\tvalid_1's auc: 0.496113\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.861849\tvalid_1's auc: 0.508199\n",
      "Partial score of fold 3 is: 0.5081991484922981\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98348\n",
      "1    0.01652\n",
      "Name: 140316, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983927\n",
      "1    0.016073\n",
      "Name: 140316, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89901\tvalid_1's auc: 0.518516\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.606265\tvalid_1's auc: 0.534511\n",
      "Partial score of fold 4 is: 0.5345109843033126\n",
      "AUC score is:  0.49742471851073794\n",
      "################### 8 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.98377\n",
      "1    0.01623\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983832\n",
      "1    0.016168\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.902375\tvalid_1's auc: 0.508148\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.839153\tvalid_1's auc: 0.515179\n",
      "Partial score of fold 0 is: 0.5151792802199306\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983944\n",
      "1    0.016056\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983104\n",
      "1    0.016896\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89427\tvalid_1's auc: 0.500571\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.579977\tvalid_1's auc: 0.527538\n",
      "Partial score of fold 1 is: 0.5275375371259748\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.984141\n",
      "1    0.015859\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.982387\n",
      "1    0.017613\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.906248\tvalid_1's auc: 0.511759\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.845397\tvalid_1's auc: 0.521078\n",
      "Partial score of fold 2 is: 0.5210776353505102\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983165\n",
      "1    0.016835\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.986258\n",
      "1    0.013742\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.901454\tvalid_1's auc: 0.493952\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.622837\tvalid_1's auc: 0.50287\n",
      "Partial score of fold 3 is: 0.5028695858313961\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.983892\n",
      "1    0.016108\n",
      "Name: 140317, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.983357\n",
      "1    0.016643\n",
      "Name: 140317, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.902592\tvalid_1's auc: 0.524883\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.795804\tvalid_1's auc: 0.534853\n",
      "Partial score of fold 4 is: 0.5348530361415172\n",
      "AUC score is:  0.5108462194558852\n",
      "################### 9 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989412\n",
      "1    0.010588\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.991567\n",
      "1    0.008433\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.937872\tvalid_1's auc: 0.511317\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.649384\tvalid_1's auc: 0.51686\n",
      "Partial score of fold 0 is: 0.5168599233535449\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989856\n",
      "1    0.010144\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.989786\n",
      "1    0.010214\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.933559\tvalid_1's auc: 0.468917\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.591161\tvalid_1's auc: 0.505106\n",
      "Partial score of fold 1 is: 0.505106111843432\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989747\n",
      "1    0.010253\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.990242\n",
      "1    0.009758\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.943893\tvalid_1's auc: 0.516578\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.892739\tvalid_1's auc: 0.533379\n",
      "Partial score of fold 2 is: 0.5333792488852886\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.990352\n",
      "1    0.009648\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.987865\n",
      "1    0.012135\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.949604\tvalid_1's auc: 0.494283\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.583952\tvalid_1's auc: 0.498781\n",
      "Partial score of fold 3 is: 0.49878075161713376\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.989849\n",
      "1    0.010151\n",
      "Name: 140321, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.989817\n",
      "1    0.010183\n",
      "Name: 140321, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.93953\tvalid_1's auc: 0.49744\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.754447\tvalid_1's auc: 0.514637\n",
      "Partial score of fold 4 is: 0.5146369639327355\n",
      "AUC score is:  0.49391250146769605\n",
      "################### 10 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954864\n",
      "1    0.045136\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.951977\n",
      "1    0.048023\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799748\tvalid_1's auc: 0.498797\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.758028\tvalid_1's auc: 0.504226\n",
      "Partial score of fold 0 is: 0.5042255943068512\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953718\n",
      "1    0.046282\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956611\n",
      "1    0.043389\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.797149\tvalid_1's auc: 0.509644\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.561574\tvalid_1's auc: 0.517413\n",
      "Partial score of fold 1 is: 0.5174131261838363\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954608\n",
      "1    0.045392\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.952962\n",
      "1    0.047038\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79657\tvalid_1's auc: 0.484571\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.55417\tvalid_1's auc: 0.499392\n",
      "Partial score of fold 2 is: 0.49939170063786703\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.953812\n",
      "1    0.046188\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.956134\n",
      "1    0.043866\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.80011\tvalid_1's auc: 0.497211\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.668578\tvalid_1's auc: 0.512285\n",
      "Partial score of fold 3 is: 0.512285215810462\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.954446\n",
      "1    0.045554\n",
      "Name: 140501, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.953687\n",
      "1    0.046313\n",
      "Name: 140501, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792993\tvalid_1's auc: 0.500529\n",
      "[200]\ttraining's auc: 0.86581\tvalid_1's auc: 0.50046\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.825097\tvalid_1's auc: 0.50439\n",
      "Partial score of fold 4 is: 0.5043896870270724\n",
      "AUC score is:  0.503027918781048\n",
      "################### 11 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.921689\n",
      "1    0.078311\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.931208\n",
      "1    0.068792\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.754862\tvalid_1's auc: 0.507901\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.697932\tvalid_1's auc: 0.511044\n",
      "Partial score of fold 0 is: 0.5110444815148648\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923346\n",
      "1    0.076654\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.924375\n",
      "1    0.075625\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.753877\tvalid_1's auc: 0.501882\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.551857\tvalid_1's auc: 0.5058\n",
      "Partial score of fold 1 is: 0.5057999958116122\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.924851\n",
      "1    0.075149\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.918363\n",
      "1    0.081637\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.755295\tvalid_1's auc: 0.49269\n",
      "[200]\ttraining's auc: 0.824312\tvalid_1's auc: 0.496068\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's auc: 0.794309\tvalid_1's auc: 0.49925\n",
      "Partial score of fold 2 is: 0.4992500642933245\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923954\n",
      "1    0.076046\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.921962\n",
      "1    0.078038\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.749266\tvalid_1's auc: 0.499553\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.543334\tvalid_1's auc: 0.509031\n",
      "Partial score of fold 3 is: 0.5090307981237713\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.923905\n",
      "1    0.076095\n",
      "Name: 140505, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.922152\n",
      "1    0.077848\n",
      "Name: 140505, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.765235\tvalid_1's auc: 0.495316\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.535219\tvalid_1's auc: 0.510972\n",
      "Partial score of fold 4 is: 0.5109719394393889\n",
      "AUC score is:  0.4996847538041327\n",
      "################### 12 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.97321\n",
      "1    0.02679\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.972047\n",
      "1    0.027953\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841138\tvalid_1's auc: 0.50441\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.684931\tvalid_1's auc: 0.514289\n",
      "Partial score of fold 0 is: 0.5142893340022825\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.972132\n",
      "1    0.027868\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.976408\n",
      "1    0.023592\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.841679\tvalid_1's auc: 0.503405\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.604466\tvalid_1's auc: 0.521129\n",
      "Partial score of fold 1 is: 0.5211287566055564\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.972695\n",
      "1    0.027305\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.974159\n",
      "1    0.025841\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.852253\tvalid_1's auc: 0.505512\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.761368\tvalid_1's auc: 0.518772\n",
      "Partial score of fold 2 is: 0.5187720836614581\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.973298\n",
      "1    0.026702\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.971735\n",
      "1    0.028265\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.851052\tvalid_1's auc: 0.507598\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.55904\tvalid_1's auc: 0.520668\n",
      "Partial score of fold 3 is: 0.5206684773514069\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.973564\n",
      "1    0.026436\n",
      "Name: 140641, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.970704\n",
      "1    0.029296\n",
      "Name: 140641, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.842282\tvalid_1's auc: 0.494191\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.602686\tvalid_1's auc: 0.512523\n",
      "Partial score of fold 4 is: 0.5125228610200766\n",
      "AUC score is:  0.4999945384560694\n",
      "################### 13 ###################\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.974319\n",
      "1    0.025681\n",
      "Name: 140691, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.974545\n",
      "1    0.025455\n",
      "Name: 140691, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845426\tvalid_1's auc: 0.494262\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.760097\tvalid_1's auc: 0.506664\n",
      "Partial score of fold 0 is: 0.5066636870865802\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.974367\n",
      "1    0.025633\n",
      "Name: 140691, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.974352\n",
      "1    0.025648\n",
      "Name: 140691, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.846853\tvalid_1's auc: 0.500616\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.652204\tvalid_1's auc: 0.517931\n",
      "Partial score of fold 1 is: 0.5179308652439336\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.974172\n",
      "1    0.025828\n",
      "Name: 140691, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.975169\n",
      "1    0.024831\n",
      "Name: 140691, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "10\n",
      "len(check_dup_diff)\n",
      "10\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.84826\tvalid_1's auc: 0.495491\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's auc: 0.665559\tvalid_1's auc: 0.501326\n",
      "Partial score of fold 2 is: 0.5013259182359959\n",
      "Check Stratified k-fold\n",
      "y_train.value_counts(normalize=True)\n",
      "0    0.974579\n",
      "1    0.025421\n",
      "Name: 140691, dtype: float64\n",
      "y_val.value_counts(normalize=True)\n",
      "0    0.97353\n",
      "1    0.02647\n",
      "Name: 140691, dtype: float64\n",
      "\n",
      "Check Group k-fold\n",
      "len(check_dup_tr)\n",
      "9\n",
      "len(check_dup_diff)\n",
      "9\n",
      "Check SAME Number!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "train_lgb = train_plus_oof_pred.copy()\n",
    "test_lgb = test_plus_pred.copy()\n",
    "\n",
    "print(\"################### 1 ###################\")\n",
    "lgb_model_130123 = Lgb_Model_Second(train_lgb, test_lgb, features, '130123')\n",
    "print(\"################### 2 ###################\")\n",
    "lgb_model_130125 = Lgb_Model_Second(train_lgb, test_lgb, features, '130125')\n",
    "print(\"################### 3 ###################\")\n",
    "lgb_model_130129 = Lgb_Model_Second(train_lgb, test_lgb, features, '130129')\n",
    "print(\"################### 4 ###################\")\n",
    "lgb_model_130131 = Lgb_Model_Second(train_lgb, test_lgb, features, '130131')\n",
    "print(\"################### 5 ###################\")\n",
    "lgb_model_140307 = Lgb_Model_Second(train_lgb, test_lgb, features, '140307')\n",
    "print(\"################### 6 ###################\")\n",
    "lgb_model_140313 = Lgb_Model_Second(train_lgb, test_lgb, features, '140313')\n",
    "print(\"################### 7 ###################\")\n",
    "lgb_model_140316 = Lgb_Model_Second(train_lgb, test_lgb, features, '140316')\n",
    "print(\"################### 8 ###################\")\n",
    "lgb_model_140317 = Lgb_Model_Second(train_lgb, test_lgb, features, '140317')\n",
    "print(\"################### 9 ###################\")\n",
    "lgb_model_140321 = Lgb_Model_Second(train_lgb, test_lgb, features, '140321')\n",
    "print(\"################### 10 ###################\")\n",
    "lgb_model_140501 = Lgb_Model_Second(train_lgb, test_lgb, features, '140501')\n",
    "print(\"################### 11 ###################\")\n",
    "lgb_model_140505 = Lgb_Model_Second(train_lgb, test_lgb, features, '140505')\n",
    "print(\"################### 12 ###################\")\n",
    "lgb_model_140641 = Lgb_Model_Second(train_lgb, test_lgb, features, '140641')\n",
    "print(\"################### 13 ###################\")\n",
    "lgb_model_140691 = Lgb_Model_Second(train_lgb, test_lgb, features, '140691')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"130123_AUC: {lgb_model_130123.score}\")\n",
    "# print(f\"130125_AUC: {lgb_model_130125.score}\")\n",
    "# print(f\"130129_AUC: {lgb_model_130129.score}\")\n",
    "# print(f\"130131_AUC: {lgb_model_130131.score}\")\n",
    "# print(f\"140307_AUC: {lgb_model_140307.score}\")\n",
    "# print(f\"140313_AUC: {lgb_model_140313.score}\")\n",
    "# print(f\"140316_AUC: {lgb_model_140316.score}\")\n",
    "# print(f\"140317_AUC: {lgb_model_140317.score}\")\n",
    "# print(f\"140321_AUC: {lgb_model_140321.score}\")\n",
    "# print(f\"140501_AUC: {lgb_model_140501.score}\")\n",
    "# print(f\"140505_AUC: {lgb_model_140505.score}\")\n",
    "# print(f\"140641_AUC: {lgb_model_140641.score}\")\n",
    "# print(f\"140691_AUC: {lgb_model_140691.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_w = f'/mnt/batch/tasks/shared/LS_root/mounts/clusters/sinchir02/code/Users/td017/kaggle-pipeline/model/{CASE}_lgb_score_second.txt'\n",
    "\n",
    "s1 = f\"チョコレート_AUC: {lgb_model_130123.score}\"\n",
    "s2 = f\"チューインガム_AUC: {lgb_model_130125.score}\"\n",
    "s3 = f\"米菓_AUC: {lgb_model_130129.score}\"\n",
    "s4 = f\"スナック_AUC: {lgb_model_130131.score}\"\n",
    "s5 = f\"コーヒードリンク_AUC: {lgb_model_140307.score}\"\n",
    "s6 = f\"日本茶・麦茶ドリンク_AUC: {lgb_model_140313.score}\"\n",
    "s7 = f\"その他茶ドリンク_AUC: {lgb_model_140316.score}\"\n",
    "s8 = f\"水_AUC: {lgb_model_140317.score}\"\n",
    "s9 = f\"炭酸水_AUC: {lgb_model_140321.score}\"\n",
    "s10 = f\"新ジャンル_AUC: {lgb_model_140501.score}\"\n",
    "s11 = f\"RTD_AUC: {lgb_model_140505.score}\"\n",
    "s12 = f\"ビール_AUC: {lgb_model_140641.score}\"\n",
    "s13 = f\"発泡酒_AUC: {lgb_model_140691.score}\"\n",
    "\n",
    "with open(path_w, mode='w') as f:\n",
    "    f.write(s1+\"\\n\")\n",
    "    f.write(s2+\"\\n\")\n",
    "    f.write(s3+\"\\n\")\n",
    "    f.write(s4+\"\\n\")\n",
    "    f.write(s5+\"\\n\")\n",
    "    f.write(s6+\"\\n\")\n",
    "    f.write(s7+\"\\n\")\n",
    "    f.write(s8+\"\\n\")\n",
    "    f.write(s9+\"\\n\")\n",
    "    f.write(s10+\"\\n\")\n",
    "    f.write(s11+\"\\n\")\n",
    "    f.write(s12+\"\\n\")\n",
    "    f.write(s13+\"\\n\")\n",
    "\n",
    "with open(path_w) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"130123\"] = lgb_model_130123.y_pred\n",
    "sample_submission[\"130125\"] = lgb_model_130125.y_pred\n",
    "sample_submission[\"130129\"] = lgb_model_130129.y_pred\n",
    "sample_submission[\"130131\"] = lgb_model_130131.y_pred\n",
    "sample_submission[\"140307\"] = lgb_model_140307.y_pred\n",
    "sample_submission[\"140313\"] = lgb_model_140313.y_pred\n",
    "sample_submission[\"140316\"] = lgb_model_140316.y_pred\n",
    "sample_submission[\"140317\"] = lgb_model_140317.y_pred\n",
    "sample_submission[\"140321\"] = lgb_model_140321.y_pred\n",
    "sample_submission[\"140501\"] = lgb_model_140501.y_pred\n",
    "sample_submission[\"140505\"] = lgb_model_140505.y_pred\n",
    "sample_submission[\"140641\"] = lgb_model_140641.y_pred\n",
    "sample_submission[\"140691\"] = lgb_model_140691.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f\"{SAME_PATH}\" + \"/Users/td017/kaggle-pipeline/submission/sub_\" + f\"{CASE}\"+\"_second.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack_df = pd.DataFrame({\n",
    "#   \"130123\" :  lgb_model_130123.oof_pred,\n",
    "#   \"130125\" :  lgb_model_130125.oof_pred,\n",
    "#   \"130129\" :  lgb_model_130129.oof_pred,\n",
    "#   \"130131\" :  lgb_model_130131.oof_pred,\n",
    "#   \"140307\" :  lgb_model_140307.oof_pred,\n",
    "#   \"140313\" :  lgb_model_140313.oof_pred,\n",
    "#   \"140316\" :  lgb_model_140316.oof_pred,\n",
    "#   \"140317\" :  lgb_model_140317.oof_pred,\n",
    "#   \"140321\" :  lgb_model_140321.oof_pred,\n",
    "#   \"140501\" :  lgb_model_140501.oof_pred,\n",
    "#   \"140505\" :  lgb_model_140505.oof_pred,\n",
    "#   \"140641\" :  lgb_model_140641.oof_pred,\n",
    "#   \"140691\" :  lgb_model_140691.oof_pred,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1_oof_pred = pd.read_csv(f\"{SAME_PATH}\" + \"Users/td017/kaggle-pipeline/submission/sub_case1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
